{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "866ac723",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T01:58:51.193460Z",
     "start_time": "2024-10-22T01:58:49.403817Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from utils.timefeatures import time_features\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f84e436",
   "metadata": {},
   "source": [
    "# 데이터로더 내 일부 클래스 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53c62410",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T01:58:53.013693Z",
     "start_time": "2024-10-22T01:58:52.993694Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset_ETT_minute(Dataset):\n",
    "    def __init__(self, root_path, flag='train', size=None,\n",
    "                 features='S', data_path='ETTm1.csv',\n",
    "                 target='OT', scale=True, timeenc=0, freq='t'):\n",
    "        # size [seq_len, label_len, pred_len]\n",
    "        # info\n",
    "        if size == None:\n",
    "            self.seq_len = 24 * 4 * 4\n",
    "            self.label_len = 24 * 4\n",
    "            self.pred_len = 24 * 4\n",
    "        else:\n",
    "            self.seq_len = size[0]\n",
    "            self.label_len = size[1]\n",
    "            self.pred_len = size[2]\n",
    "        # init\n",
    "        assert flag in ['train', 'test', 'val']\n",
    "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
    "        self.set_type = type_map[flag]\n",
    "\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.scale = scale\n",
    "        self.timeenc = timeenc\n",
    "        self.freq = freq\n",
    "\n",
    "        self.root_path = root_path\n",
    "        self.data_path = data_path\n",
    "        self.__read_data__()\n",
    "\n",
    "    def __read_data__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
    "                                          self.data_path))\n",
    "\n",
    "        border1s = [0, 12 * 30 * 24 * 4 - self.seq_len, 12 * 30 * 24 * 4 + 4 * 30 * 24 * 4 - self.seq_len]\n",
    "        border2s = [12 * 30 * 24 * 4, 12 * 30 * 24 * 4 + 4 * 30 * 24 * 4, 12 * 30 * 24 * 4 + 8 * 30 * 24 * 4]\n",
    "        border1 = border1s[self.set_type]\n",
    "        border2 = border2s[self.set_type]\n",
    "\n",
    "        if self.features == 'M' or self.features == 'MS':\n",
    "            cols_data = df_raw.columns[1:]\n",
    "            df_data = df_raw[cols_data]\n",
    "        elif self.features == 'S':\n",
    "            df_data = df_raw[[self.target]]\n",
    "\n",
    "        if self.scale:\n",
    "            train_data = df_data[border1s[0]:border2s[0]]\n",
    "            self.scaler.fit(train_data.values)\n",
    "            data = self.scaler.transform(df_data.values)\n",
    "        else:\n",
    "            data = df_data.values\n",
    "\n",
    "        df_stamp = df_raw[['date']][border1:border2]\n",
    "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
    "        if self.timeenc == 0:\n",
    "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
    "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
    "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
    "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
    "            df_stamp['minute'] = df_stamp.date.apply(lambda row: row.minute, 1)\n",
    "            df_stamp['minute'] = df_stamp.minute.map(lambda x: x // 15)\n",
    "            data_stamp = df_stamp.drop(['date'], 1).values\n",
    "        elif self.timeenc == 1:\n",
    "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
    "            data_stamp = data_stamp.transpose(1, 0)\n",
    "\n",
    "        self.data_x = data[border1:border2]\n",
    "        self.data_y = data[border1:border2]\n",
    "        self.data_stamp = data_stamp\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end - self.label_len\n",
    "        r_end = r_begin + self.label_len + self.pred_len\n",
    "\n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        seq_y = self.data_y[r_begin:r_end]\n",
    "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
    "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
    "\n",
    "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return self.scaler.inverse_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6cee5e",
   "metadata": {},
   "source": [
    "# 클래스 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9764fc85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T01:52:19.532829Z",
     "start_time": "2024-10-22T01:52:19.518911Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터 경로 설정\n",
    "root_path = './ETT-small'\n",
    "data_path = 'ETTm1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98db181",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T01:52:20.468420Z",
     "start_time": "2024-10-22T01:52:20.402010Z"
    }
   },
   "outputs": [],
   "source": [
    "# 원본 데이터 확인\n",
    "df = pd.read_csv(os.path.join(root_path, data_path))\n",
    "print(\"원본 데이터 shape:\", df.shape)\n",
    "print(\"\\n첫 5행 데이터:\")\n",
    "print(df.head())\n",
    "print(\"\\n컬럼명:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ffbdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T01:52:21.505076Z",
     "start_time": "2024-10-22T01:52:20.913552Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset 인스턴스 생성 (train, val, test 각각)\n",
    "train_dataset = Dataset_ETT_minute(\n",
    "    root_path=root_path,\n",
    "    data_path=data_path,\n",
    "    flag='train',    \n",
    "    size=[96, 48, 48],  # [seq_len, label_len, pred_len]\n",
    "    features='M',  # 다변량 데이터 사용\n",
    "    target='OT'  # 목표변수\n",
    ")\n",
    "\n",
    "val_dataset = Dataset_ETT_minute(\n",
    "    root_path=root_path,\n",
    "    data_path=data_path,\n",
    "    flag='val',\n",
    "    scale='False',\n",
    "    size=[96, 48, 48],\n",
    "    features='M',\n",
    "    target='OT'\n",
    ")\n",
    "\n",
    "test_dataset = Dataset_ETT_minute(\n",
    "    root_path=root_path,\n",
    "    data_path=data_path,\n",
    "    flag='test',\n",
    "    scale='False',\n",
    "    size=[96, 48, 48],\n",
    "    features='M',\n",
    "    target='OT'\n",
    ")\n",
    "\n",
    "# 데이터셋 크기 확인\n",
    "print(\"\\n데이터셋 크기:\")\n",
    "print(f\"Train: {len(train_dataset)}\")\n",
    "print(f\"Validation: {len(val_dataset)}\")\n",
    "print(f\"Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f387f31c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T01:52:43.499811Z",
     "start_time": "2024-10-22T01:52:43.487814Z"
    }
   },
   "outputs": [],
   "source": [
    "# 첫 번째 배치 데이터 확인\n",
    "first_batch = train_dataset[0]\n",
    "seq_x, seq_y, seq_x_mark, seq_y_mark = first_batch\n",
    "\n",
    "print(\"\\n첫 번째 배치 데이터 shape:\")\n",
    "print(f\"seq_x shape: {seq_x.shape}\")  # 입력 시퀀스\n",
    "print(f\"seq_y shape: {seq_y.shape}\")  # 타겟 시퀀스\n",
    "print(f\"seq_x_mark shape: {seq_x_mark.shape}\")  # 입력 시퀀스의 시간 특성\n",
    "print(f\"seq_y_mark shape: {seq_y_mark.shape}\")  # 타겟 시퀀스의 시간 특성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1f70ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T01:52:44.762750Z",
     "start_time": "2024-10-22T01:52:44.746748Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaee002",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T01:41:25.556267Z",
     "start_time": "2024-10-22T01:41:25.545511Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603ecdc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T01:41:44.794414Z",
     "start_time": "2024-10-22T01:41:44.781416Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq_x_mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9316cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T01:43:05.426115Z",
     "start_time": "2024-10-22T01:43:05.411118Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq_y_mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2665368",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T01:44:14.817262Z",
     "start_time": "2024-10-22T01:44:14.791257Z"
    }
   },
   "outputs": [],
   "source": [
    "# DataLoader를 사용한 배치 데이터 생성\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "# 첫 번째 배치 확인\n",
    "for batch in train_loader:\n",
    "    batch_x, batch_y, batch_x_mark, batch_y_mark = batch\n",
    "    print(\"\\nDataLoader의 첫 번째 배치 shape:\")\n",
    "    print(f\"batch_x shape: {batch_x.shape}\")\n",
    "    print(f\"batch_y shape: {batch_y.shape}\")\n",
    "    print(f\"batch_x_mark shape: {batch_x_mark.shape}\")\n",
    "    print(f\"batch_y_mark shape: {batch_y_mark.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f6e629",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T01:53:48.163319Z",
     "start_time": "2024-10-22T01:53:47.784723Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 데이터 경로 설정\n",
    "root_path = './ETT-small'\n",
    "data_path = 'ETTm1.csv'\n",
    "\n",
    "# 원본 데이터 확인\n",
    "df = pd.read_csv(os.path.join(root_path, data_path))\n",
    "print(\"원본 데이터 shape:\", df.shape)\n",
    "print(\"\\n첫 5행 데이터:\")\n",
    "print(df.head())\n",
    "print(\"\\n컬럼명:\", df.columns.tolist())\n",
    "\n",
    "# Dataset 인스턴스 생성 (scale=False로 설정)\n",
    "train_dataset = Dataset_ETT_minute(\n",
    "    root_path=root_path,\n",
    "    data_path=data_path,\n",
    "    flag='train',\n",
    "    size=[96, 48, 48],  \n",
    "    features='MS',  \n",
    "    target='OT',\n",
    "    scale=False  # StandardScaler 적용하지 않음\n",
    ")\n",
    "\n",
    "# 첫 번째 배치 데이터 확인\n",
    "first_batch = train_dataset[0]\n",
    "seq_x, seq_y, seq_x_mark, seq_y_mark = first_batch\n",
    "\n",
    "print(\"\\n첫 번째 배치 데이터:\")\n",
    "print(\"입력 시퀀스(seq_x) 첫 5행:\")\n",
    "print(seq_x[:5])\n",
    "print(\"\\n타겟 시퀀스(seq_y) 첫 5행:\")\n",
    "print(seq_y[:5])\n",
    "\n",
    "# 시간 특성 확인\n",
    "print(\"\\n시간 특성(seq_x_mark) 첫 5행:\")\n",
    "print(seq_x_mark[:5])\n",
    "print(\"\\n시간 특성 컬럼:\", ['month', 'day', 'weekday', 'hour', 'minute'])\n",
    "\n",
    "# 데이터 범위 확인\n",
    "print(\"\\n데이터 범위:\")\n",
    "print(\"seq_x 범위:\", np.min(seq_x), \"~\", np.max(seq_x))\n",
    "print(\"seq_y 범위:\", np.min(seq_y), \"~\", np.max(seq_y))\n",
    "\n",
    "# 각 변수별 통계량 확인\n",
    "print(\"\\n입력 시퀀스 기술통계:\")\n",
    "seq_x_df = pd.DataFrame(seq_x)\n",
    "print(seq_x_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6fd99e",
   "metadata": {},
   "source": [
    "# val, test set의 시작시점 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07f89ea9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T01:58:55.077738Z",
     "start_time": "2024-10-22T01:58:54.332506Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_26276\\2425535225.py:62: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data_stamp = df_stamp.drop(['date'], 1).values\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_26276\\2425535225.py:62: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data_stamp = df_stamp.drop(['date'], 1).values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN 데이터셋:\n",
      "시작 인덱스: 0\n",
      "시작 날짜: 2016-07-01 00:00:00\n",
      "시간 특성 첫 5행 (month, day, weekday, hour, minute):\n",
      "[[7 1 4 0 0]\n",
      " [7 1 4 0 1]\n",
      " [7 1 4 0 2]\n",
      " [7 1 4 0 3]\n",
      " [7 1 4 1 0]]\n",
      "\n",
      "TRAIN 첫 번째 데이터 시점:\n",
      "월: 7, 일: 1, 요일: 4, 시: 0, 15분단위: 0\n",
      "\n",
      "VAL 데이터셋:\n",
      "시작 인덱스: 34176\n",
      "시작 날짜: 2017-06-22 00:00:00\n",
      "시간 특성 첫 5행 (month, day, weekday, hour, minute):\n",
      "[[ 6 22  3  0  0]\n",
      " [ 6 22  3  0  1]\n",
      " [ 6 22  3  0  2]\n",
      " [ 6 22  3  0  3]\n",
      " [ 6 22  3  1  0]]\n",
      "\n",
      "VAL 첫 번째 데이터 시점:\n",
      "월: 6, 일: 22, 요일: 3, 시: 0, 15분단위: 0\n",
      "\n",
      "TEST 데이터셋:\n",
      "시작 인덱스: 45696\n",
      "시작 날짜: 2017-10-20 00:00:00\n",
      "시간 특성 첫 5행 (month, day, weekday, hour, minute):\n",
      "[[10 20  4  0  0]\n",
      " [10 20  4  0  1]\n",
      " [10 20  4  0  2]\n",
      " [10 20  4  0  3]\n",
      " [10 20  4  1  0]]\n",
      "\n",
      "TEST 첫 번째 데이터 시점:\n",
      "월: 10, 일: 20, 요일: 4, 시: 0, 15분단위: 0\n",
      "\n",
      "전체 데이터 길이: 69680\n",
      "각 데이터셋 길이:\n",
      "train: 34081\n",
      "val: 11425\n",
      "test: 11425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_26276\\2425535225.py:62: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data_stamp = df_stamp.drop(['date'], 1).values\n"
     ]
    }
   ],
   "source": [
    "# 데이터 경로 설정\n",
    "root_path = './ETT-small'\n",
    "data_path = 'ETTm1.csv'\n",
    "\n",
    "# train, validation, test 데이터셋 생성\n",
    "datasets = {\n",
    "    'train': Dataset_ETT_minute(\n",
    "        root_path=root_path,\n",
    "        data_path=data_path,\n",
    "        flag='train',\n",
    "        size=None,\n",
    "        features='M',\n",
    "        scale=False\n",
    "    ),\n",
    "    'val': Dataset_ETT_minute(\n",
    "        root_path=root_path,\n",
    "        data_path=data_path,\n",
    "        flag='val',\n",
    "        size=None,\n",
    "        features='M',\n",
    "        scale=False\n",
    "    ),\n",
    "    'test': Dataset_ETT_minute(\n",
    "        root_path=root_path,\n",
    "        data_path=data_path,\n",
    "        flag='test',\n",
    "        size=None,\n",
    "        features='M',\n",
    "        scale=False\n",
    "    )\n",
    "}\n",
    "\n",
    "# 각 데이터셋의 시작 시점 확인\n",
    "for name, dataset in datasets.items():\n",
    "    first_batch = dataset[0]\n",
    "    _, _, seq_x_mark, _ = first_batch\n",
    "    \n",
    "    # 원본 데이터에서 시간 정보 가져오기\n",
    "    df_raw = pd.read_csv(os.path.join(root_path, data_path))\n",
    "    \n",
    "    # border1 계산\n",
    "    if name == 'train':\n",
    "        border1 = 0\n",
    "    elif name == 'val':\n",
    "        border1 = 12 * 30 * 24 * 4 - dataset.seq_len\n",
    "    else:  # test\n",
    "        border1 = 12 * 30 * 24 * 4 + 4 * 30 * 24 * 4 - dataset.seq_len\n",
    "    \n",
    "    # 해당 시점의 실제 날짜 확인\n",
    "    start_date = pd.to_datetime(df_raw['date'].iloc[border1])\n",
    "    \n",
    "    print(f\"\\n{name.upper()} 데이터셋:\")\n",
    "    print(f\"시작 인덱스: {border1}\")\n",
    "    print(f\"시작 날짜: {start_date}\")\n",
    "    print(\"시간 특성 첫 5행 (month, day, weekday, hour, minute):\")\n",
    "    print(seq_x_mark[:5])\n",
    "    \n",
    "    # 시작과 끝 시점의 전체 정보\n",
    "    print(f\"\\n{name.upper()} 첫 번째 데이터 시점:\")\n",
    "    first_mark = seq_x_mark[0]\n",
    "    print(f\"월: {int(first_mark[0])}, 일: {int(first_mark[1])}, \"\n",
    "          f\"요일: {int(first_mark[2])}, 시: {int(first_mark[3])}, \"\n",
    "          f\"15분단위: {int(first_mark[4])}\")\n",
    "\n",
    "# 전체 데이터 길이 확인\n",
    "print(\"\\n전체 데이터 길이:\", len(df_raw))\n",
    "print(\"각 데이터셋 길이:\")\n",
    "for name, dataset in datasets.items():\n",
    "    print(f\"{name}: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fefc98c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T02:00:05.431399Z",
     "start_time": "2024-10-22T02:00:04.746284Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 크기: 69680\n",
      "\n",
      "각 분할의 경계값:\n",
      "\n",
      "train:\n",
      "시작 인덱스 (border1): 0\n",
      "종료 인덱스 (border2): 34560\n",
      "데이터 길이: 34560\n",
      "\n",
      "validation:\n",
      "시작 인덱스 (border1): 34176\n",
      "종료 인덱스 (border2): 46080\n",
      "데이터 길이: 11904\n",
      "\n",
      "test:\n",
      "시작 인덱스 (border1): 45696\n",
      "종료 인덱스 (border2): 57600\n",
      "데이터 길이: 11904\n",
      "\n",
      "이론적인 분할:\n",
      "1년: 34560\n",
      "4개월: 11520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_26276\\2425535225.py:62: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data_stamp = df_stamp.drop(['date'], 1).values\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_26276\\2425535225.py:62: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data_stamp = df_stamp.drop(['date'], 1).values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "실제 데이터셋 크기:\n",
      "train: 34081\n",
      "val: 11425\n",
      "test: 11425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_26276\\2425535225.py:62: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data_stamp = df_stamp.drop(['date'], 1).values\n"
     ]
    }
   ],
   "source": [
    "# 데이터 경로 설정\n",
    "root_path = './ETT-small'\n",
    "data_path = 'ETTm1.csv'\n",
    "\n",
    "# 원본 데이터 크기 확인\n",
    "df = pd.read_csv(os.path.join(root_path, data_path))\n",
    "print(\"전체 데이터 크기:\", len(df))\n",
    "\n",
    "# 경계값 계산\n",
    "seq_len = 24 * 4 * 4    # 384\n",
    "label_len = 24 * 4      # 96\n",
    "pred_len = 24 * 4       # 96\n",
    "\n",
    "border1s = [0, 12 * 30 * 24 * 4 - seq_len, 12 * 30 * 24 * 4 + 4 * 30 * 24 * 4 - seq_len]\n",
    "border2s = [12 * 30 * 24 * 4, 12 * 30 * 24 * 4 + 4 * 30 * 24 * 4, 12 * 30 * 24 * 4 + 8 * 30 * 24 * 4]\n",
    "\n",
    "print(\"\\n각 분할의 경계값:\")\n",
    "splits = ['train', 'validation', 'test']\n",
    "for i, split in enumerate(splits):\n",
    "    print(f\"\\n{split}:\")\n",
    "    print(f\"시작 인덱스 (border1): {border1s[i]}\")\n",
    "    print(f\"종료 인덱스 (border2): {border2s[i]}\")\n",
    "    print(f\"데이터 길이: {border2s[i] - border1s[i]}\")\n",
    "\n",
    "# 이론적인 분할 크기\n",
    "print(\"\\n이론적인 분할:\")\n",
    "total_minutes = 12 * 30 * 24 * 4  # 1년치\n",
    "print(f\"1년: {total_minutes}\")\n",
    "print(f\"4개월: {4 * 30 * 24 * 4}\")\n",
    "\n",
    "# 실제 데이터셋 크기\n",
    "datasets = {\n",
    "    'train': Dataset_ETT_minute(\n",
    "        root_path=root_path,\n",
    "        data_path=data_path,\n",
    "        flag='train',\n",
    "        size=None,\n",
    "        features='M',\n",
    "        scale=False\n",
    "    ),\n",
    "    'val': Dataset_ETT_minute(\n",
    "        root_path=root_path,\n",
    "        data_path=data_path,\n",
    "        flag='val',\n",
    "        size=None,\n",
    "        features='M',\n",
    "        scale=False\n",
    "    ),\n",
    "    'test': Dataset_ETT_minute(\n",
    "        root_path=root_path,\n",
    "        data_path=data_path,\n",
    "        flag='test',\n",
    "        size=None,\n",
    "        features='M',\n",
    "        scale=False\n",
    "    )\n",
    "}\n",
    "\n",
    "print(\"\\n실제 데이터셋 크기:\")\n",
    "for name, dataset in datasets.items():\n",
    "    print(f\"{name}: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce1f6a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
