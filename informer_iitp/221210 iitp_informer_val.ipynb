{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce219914",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:45.344091Z",
     "start_time": "2022-12-13T12:12:42.496857Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymssql\n",
    "import pyodbc\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "from dateutil.parser import parse\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import sys\n",
    "import openpyxl as opx\n",
    "import xlrd\n",
    "import time\n",
    "import math\n",
    "import seaborn as sns\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib import font_manager, rc\n",
    "# matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "# font_path = \"C:/Windows/Fonts/malgun.TTF\"\n",
    "# font = font_manager.FontProperties(fname=font_path).get_name()\n",
    "# rc('font', family=font)\n",
    "# %matplotlib inline\n",
    "# plt.rc(\"font\", family = \"Malgun Gothic\")\n",
    "from copy import deepcopy\n",
    "from pytimekr import pytimekr\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "# import torchvision.transforms as transforms\n",
    "# import torchvision\n",
    "import torch\n",
    "\n",
    "from utils.tools import StandardScaler, adjust_learning_rate\n",
    "from utils.timefeatures import time_features\n",
    "from models.model import Informer, InformerStack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712b2550",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "663491a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:45.486226Z",
     "start_time": "2022-12-13T12:12:45.471266Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./data/ETTm1.csv', parse_dates = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c00120b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:45.642832Z",
     "start_time": "2022-12-13T12:12:45.613400Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/elec_demand_10min.csv', parse_dates = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "094b6341",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:45.785963Z",
     "start_time": "2022-12-13T12:12:45.771003Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>562_elec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-18 00:00:00</td>\n",
       "      <td>67.784160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-18 00:10:00</td>\n",
       "      <td>61.867367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-18 00:20:00</td>\n",
       "      <td>61.887110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-18 00:30:00</td>\n",
       "      <td>58.967857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-18 00:40:00</td>\n",
       "      <td>56.801160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19665</th>\n",
       "      <td>2022-12-01 13:30:00</td>\n",
       "      <td>45.453293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19666</th>\n",
       "      <td>2022-12-01 13:40:00</td>\n",
       "      <td>37.218613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19667</th>\n",
       "      <td>2022-12-01 13:50:00</td>\n",
       "      <td>39.823902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19668</th>\n",
       "      <td>2022-12-01 14:00:00</td>\n",
       "      <td>39.997955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19669</th>\n",
       "      <td>2022-12-01 14:10:00</td>\n",
       "      <td>41.629654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19670 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date   562_elec\n",
       "0      2022-07-18 00:00:00  67.784160\n",
       "1      2022-07-18 00:10:00  61.867367\n",
       "2      2022-07-18 00:20:00  61.887110\n",
       "3      2022-07-18 00:30:00  58.967857\n",
       "4      2022-07-18 00:40:00  56.801160\n",
       "...                    ...        ...\n",
       "19665  2022-12-01 13:30:00  45.453293\n",
       "19666  2022-12-01 13:40:00  37.218613\n",
       "19667  2022-12-01 13:50:00  39.823902\n",
       "19668  2022-12-01 14:00:00  39.997955\n",
       "19669  2022-12-01 14:10:00  41.629654\n",
       "\n",
       "[19670 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76a5f562",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:45.928607Z",
     "start_time": "2022-12-13T12:12:45.914135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159.68045 57.24784824914896\n"
     ]
    }
   ],
   "source": [
    "elec_max = np.max(df['562_elec'])\n",
    "elec_mean = np.mean(df['562_elec'])\n",
    "print(elec_max, elec_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "175d14ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:46.070741Z",
     "start_time": "2022-12-13T12:12:46.055782Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset_Custom(Dataset):\n",
    "    def __init__(self, flag='train', size=None, \n",
    "                 features='S', dataframe=None, \n",
    "                 target='562_elec', scale=True, inverse=False, timeenc=0, freq='t', cols=None):\n",
    "        # size [seq_len, label_len, pred_len] \n",
    "        # info\n",
    "        if size == None:\n",
    "            self.seq_len = 24*4*4\n",
    "            self.label_len = 24*4\n",
    "            self.pred_len = 24*4\n",
    "        else:\n",
    "            self.seq_len = size[0]\n",
    "            self.label_len = size[1]\n",
    "            self.pred_len = size[2]\n",
    "        # init\n",
    "        assert flag in ['train', 'test', 'val']\n",
    "        type_map = {'train':0, 'val':1, 'test':2}\n",
    "        self.set_type = type_map[flag]\n",
    "        \n",
    "        self.features = features # 'S' : Univariate, 'M': Multivariate, 'MS': Multivariate single point\n",
    "        self.target = target\n",
    "        self.scale = scale\n",
    "        self.inverse = inverse\n",
    "        self.timeenc = timeenc\n",
    "        self.freq = freq\n",
    "        self.cols=cols\n",
    "        self.dataframe = df\n",
    "        self.__read_data__()\n",
    "\n",
    "    def __read_data__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        df_raw = self.dataframe\n",
    "        '''\n",
    "        df_raw.columns: ['date', ...(other features), target feature]\n",
    "        '''\n",
    "        # cols = list(df_raw.columns); \n",
    "        if self.cols:\n",
    "            cols=self.cols.copy()\n",
    "            cols.remove(self.target)\n",
    "        else:\n",
    "            cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')\n",
    "        df_raw = df_raw[['date']+cols+[self.target]]\n",
    "\n",
    "        num_train = int(len(df_raw)*0.7)\n",
    "        num_test = int(len(df_raw)*0.1)\n",
    "        num_vali = len(df_raw) - num_train - num_test\n",
    "        border1s = [0, num_train-self.seq_len, len(df_raw)-num_test-self.seq_len]\n",
    "        border2s = [num_train, num_train+num_vali, len(df_raw)]\n",
    "        border1 = border1s[self.set_type]\n",
    "        border2 = border2s[self.set_type]\n",
    "        \n",
    "        if self.features=='M' or self.features=='MS':\n",
    "            cols_data = df_raw.columns[1:]\n",
    "            df_data = df_raw[cols_data]\n",
    "        elif self.features=='S':\n",
    "            df_data = df_raw[[self.target]]\n",
    "\n",
    "        if self.scale:\n",
    "            train_data = df_data[border1s[0]:border2s[0]]\n",
    "            self.scaler.fit(train_data.values)\n",
    "            data = self.scaler.transform(df_data.values)\n",
    "        else:\n",
    "            data = df_data.values\n",
    "            \n",
    "        df_stamp = df_raw[['date']][border1:border2]\n",
    "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
    "        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n",
    "\n",
    "        self.data_x = data[border1:border2]\n",
    "        if self.inverse:\n",
    "            self.data_y = df_data.values[border1:border2]\n",
    "        else:\n",
    "            self.data_y = data[border1:border2]\n",
    "        self.data_stamp = data_stamp\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end - self.label_len \n",
    "        r_end = r_begin + self.label_len + self.pred_len\n",
    "\n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        if self.inverse:\n",
    "            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n",
    "        else:\n",
    "            seq_y = self.data_y[r_begin:r_end]\n",
    "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
    "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
    "\n",
    "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_x) - self.seq_len- self.pred_len + 1\n",
    " \n",
    "    def inverse_transform(self, data):\n",
    "        return self.scaler.inverse_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f57bcf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:46.213872Z",
     "start_time": "2022-12-13T12:12:46.198911Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_set = Dataset_Custom(flag='train', size=[24*6,24*3,24*6], features='S', dataframe= df)\n",
    "# val_set = Dataset_Custom(flag='val', size=[24*6,24*3,24*6], features='S', dataframe= df)\n",
    "# test_set = Dataset_Custom(flag='test', size=[24*6,24*3,24*6], features='S', dataframe= df)\n",
    "# partition = {'train':train_set, 'val':val_set, 'test':test_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f050163a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:46.354520Z",
     "start_time": "2022-12-13T12:12:46.339560Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e75fe6b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:46.497650Z",
     "start_time": "2022-12-13T12:12:46.482690Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9123b36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:46.638301Z",
     "start_time": "2022-12-13T12:12:46.624826Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for batch, data in enumerate(train_loader,0 ):\n",
    "#     seq_x, seq_y, seq_x_mark, seq_y_mark = data\n",
    "#     print(batch, seq_x, seq_y, seq_x_mark, seq_y_mark)\n",
    "#     print(batch, seq_x.shape, seq_y.shape, seq_x_mark.shape, seq_y_mark.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5118e993",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a57e117",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:46.811351Z",
     "start_time": "2022-12-13T12:12:46.792402Z"
    }
   },
   "outputs": [],
   "source": [
    " def metric(y_pred, y_true): # metric으로 Cv_rmse 사용 (향후 multivariate에서 사용)\n",
    "#     y_pred = np.squeeze(y_pred, axis=1)\n",
    "#     y_true = np.squeeze(y_true, axis=1)    \n",
    "#     y_pred = scaler.inverse_transform(y_pred.cpu().detach().numpy())\n",
    "#     y_true = scaler.inverse_transform(y_true.cpu().detach().numpy())\n",
    "\n",
    "    y_pred = train_set.scaler.inverse_transform(y_pred.cpu().detach().numpy())\n",
    "    y_true = train_set.scaler.inverse_transform(y_true.cpu().detach().numpy())\n",
    "\n",
    "#     y_pred = y_pred.cpu().detach().numpy()\n",
    "#     y_true = y_true.cpu().detach().numpy()\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = y_pred.reshape(-1, y_pred.shape[-2], y_pred.shape[-1])\n",
    "    y_true = y_true.reshape(-1, y_true.shape[-2], y_true.shape[-1])\n",
    "\n",
    "    mae = np.mean(np.abs(y_pred-y_true))\n",
    "    mse = np.mean((y_pred-y_true)**2)\n",
    "    rmse = np.sqrt(mse)    \n",
    "    Cv_rmse = rmse/(np.mean(y_true))*100\n",
    "    \n",
    "    return Cv_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d70cb47-3621-41a7-8c95-3518ff19a6fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:47.000874Z",
     "start_time": "2022-12-13T12:12:46.986911Z"
    }
   },
   "outputs": [],
   "source": [
    "def RSE(pred, true):\n",
    "    return np.sqrt(np.sum((true-pred)**2)) / np.sqrt(np.sum((true-true.mean())**2))\n",
    "\n",
    "def CORR(pred, true):\n",
    "    u = ((true-true.mean(0))*(pred-pred.mean(0))).sum(0) \n",
    "    d = np.sqrt(((true-true.mean(0))**2*(pred-pred.mean(0))**2).sum(0))\n",
    "    return (u/d).mean(-1)\n",
    "\n",
    "def MAE(pred, true):\n",
    "    return np.mean(np.abs(pred-true))\n",
    "\n",
    "def MSE(pred, true):\n",
    "    return np.mean((pred-true)**2)\n",
    "\n",
    "def RMSE(pred, true):\n",
    "    return np.sqrt(MSE(pred, true))\n",
    "\n",
    "def Cv_RMSE(pred, true):\n",
    "    return np.sqrt(MSE(pred, true))/np.mean(true)*100\n",
    "\n",
    "def MAPE(pred, true):\n",
    "    return np.mean(np.abs((pred - true) / true))\n",
    "\n",
    "def MSPE(pred, true):\n",
    "    return np.mean(np.square((pred - true) / true))\n",
    "\n",
    "def KR_ERROR_MAXCAP(pred, true):\n",
    "    return np.mean(np.abs(pred-true)/elec_max)*100\n",
    "\n",
    "def KR_ERROR_AVGCAP(pred, true):\n",
    "    return np.mean(np.abs(pred-true)/elec_mean)*100\n",
    "\n",
    "def test_metric(pred, true):\n",
    "    mae = MAE(pred, true)\n",
    "    mse = MSE(pred, true)\n",
    "    Cv_rmse = Cv_RMSE(pred, true)\n",
    "    mape = MAPE(pred, true)\n",
    "    mspe = MSPE(pred, true)\n",
    "    kr_error_maxcap = KR_ERROR_MAXCAP(pred, true)\n",
    "    kr_error_avgcap = KR_ERROR_AVGCAP(pred, true)\n",
    "    \n",
    "    return mae,mse,Cv_rmse,mape,mspe, kr_error_maxcap, kr_error_avgcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff83004f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:47.158479Z",
     "start_time": "2022-12-13T12:12:47.144517Z"
    }
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation metric decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation metric decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6240565f",
   "metadata": {},
   "source": [
    "# Function block of train, validation, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "244297c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:47.506086Z",
     "start_time": "2022-12-13T12:12:47.487136Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_one_batch(model, dataset_object, batch_x, batch_y, batch_x_mark, batch_y_mark, args):\n",
    "    batch_x = batch_x.float().to(device)\n",
    "    batch_y = batch_y.float()\n",
    "\n",
    "    batch_x_mark = batch_x_mark.float().to(device)\n",
    "    batch_y_mark = batch_y_mark.float().to(device)\n",
    "\n",
    "    # decoder input\n",
    "    if args.padding==0:\n",
    "        dec_inp = torch.zeros([batch_y.shape[0], args.pred_len, batch_y.shape[-1]]).float()\n",
    "    elif args.padding==1:\n",
    "        dec_inp = torch.ones([batch_y.shape[0], args.pred_len, batch_y.shape[-1]]).float()\n",
    "    dec_inp = torch.cat([batch_y[:,:args.label_len,:], dec_inp], dim=1).float().to(device)\n",
    "    # encoder - decoder\n",
    "    if args.use_amp:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            if args.output_attention:\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "            else:\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "    else:\n",
    "        if args.output_attention:\n",
    "            outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "        else:\n",
    "            outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "    if args.inverse:\n",
    "        outputs = dataset_object.inverse_transform(outputs)\n",
    "    f_dim = -1 if args.features=='MS' else 0\n",
    "    batch_y = batch_y[:,-args.pred_len:,f_dim:].to(device)\n",
    "\n",
    "    return outputs, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b573cd06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:47.679646Z",
     "start_time": "2022-12-13T12:12:47.664686Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, partition, optimizer, criterion, args):\n",
    "    train_data = partition['train']\n",
    "    train_loader = DataLoader(train_data, batch_size=args.batch_size, shuffle=True, num_workers=0, drop_last = True)\n",
    "    \n",
    "    model.train() # Turn on the evaluation mode    \n",
    "    train_loss = 0.0\n",
    "    train_metric = 0.0    \n",
    "    \n",
    "    if args.use_amp:\n",
    "        amp_scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    for batch, data in enumerate(train_loader, 0):        \n",
    "        optimizer.zero_grad()      \n",
    "        batch_x, batch_y, batch_x_mark, batch_y_mark = data\n",
    "        y_pred, y_true = process_one_batch(model, train_data, batch_x, batch_y, batch_x_mark, batch_y_mark, args)\n",
    "#         loss = criterion(y_pred, y_true) \n",
    "        loss = criterion(y_pred.to(torch.float32), y_true.to(torch.float32)) \n",
    "        \n",
    "        if args.use_amp:\n",
    "            amp_scaler.scale(loss).backward()\n",
    "            amp_scaler.step(optimizer)\n",
    "            amp_scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step        \n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 0.7)        \n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_metric += metric(y_pred, y_true)\n",
    "        \n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    train_metric = train_metric / len(train_loader)\n",
    "    return model, train_loss, train_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "651ce5cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:47.836252Z",
     "start_time": "2022-12-13T12:12:47.831263Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(model, partition, criterion, args):\n",
    "    val_data = partition['val']\n",
    "    val_loader = DataLoader(partition['val'], batch_size=args.batch_size, shuffle=True, num_workers=0, drop_last = True)\n",
    "    \n",
    "    model.eval() # Turn on the evaluation mode\n",
    "    val_loss = 0.0 \n",
    "    val_metric = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:            \n",
    "            batch_x, batch_y, batch_x_mark, batch_y_mark = data       \n",
    "            y_pred, y_true = process_one_batch(model, val_data, batch_x, batch_y, batch_x_mark, batch_y_mark, args)            \n",
    "            \n",
    "            loss = criterion(y_pred, y_true)\n",
    "            val_loss += loss.item()\n",
    "            val_metric += metric(y_pred, y_true)\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_metric = val_metric / len(val_loader)\n",
    "            \n",
    "    return val_loss, val_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15bc41a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:48.027253Z",
     "start_time": "2022-12-13T12:12:48.013290Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(model, partition, args):\n",
    "    test_data = partition['test']\n",
    "    test_loader = DataLoader(partition['test'], batch_size=args.batch_size, shuffle=False, num_workers=0, drop_last=True)\n",
    "    \n",
    "    model.eval() # Turn on the evaluation mode\n",
    "    \n",
    "    preds = []\n",
    "    trues = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:            \n",
    "            batch_x, batch_y, batch_x_mark, batch_y_mark = data       \n",
    "            y_pred, y_true = process_one_batch(model, test_data, batch_x, batch_y, batch_x_mark, batch_y_mark, args)\n",
    "            \n",
    "            preds.append(y_pred.detach().cpu().numpy())\n",
    "            trues.append(y_true.detach().cpu().numpy())\n",
    "            \n",
    "        preds = np.array(preds)    \n",
    "        trues = np.array(trues)\n",
    "        print('test shape:', preds.shape, trues.shape)\n",
    "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
    "        print('test shape:', preds.shape, trues.shape)\n",
    "#         preds = np.squeeze(preds, axis=1)\n",
    "#         trues = np.squeeze(trues, axis=1)\n",
    "        # print('test shape:', preds.shape, trues.shape)\n",
    "        preds = train_set.scaler.inverse_transform(preds)\n",
    "        trues = train_set.scaler.inverse_transform(trues)\n",
    "#         preds = scaler.inverse_transform(preds)\n",
    "#         trues = scaler.inverse_transform(trues)\n",
    "        \n",
    "    mae, mse, Cv_rmse, mape, mspe, kr_error_maxcap, kr_error_avgcap = test_metric(preds, trues)\n",
    "    print('mse:{:2.4f}, mae:{:2.4f}, Cv_rmse:{:2.4f}, mape:{:2.4f}, mspe:{:2.4f}, kr_error_maxcap:{:2.4f}, kr_error_avgcap:{:2.4f}'.format(mse, mae, Cv_rmse, mape, mspe, kr_error_maxcap, kr_error_avgcap))\n",
    "            \n",
    "    return Cv_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a6a92bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:48.196822Z",
     "start_time": "2022-12-13T12:12:48.176876Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, partition, args): \n",
    "    test_data = partition['test']\n",
    "    test_loader = DataLoader(partition['test'], batch_size=1, shuffle=False, num_workers=0, drop_last=True)\n",
    "    \n",
    "    model.eval() # Turn on the evaluation mode\n",
    "    preds = []\n",
    "    trues = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:            \n",
    "            batch_x, batch_y, batch_x_mark, batch_y_mark = data       \n",
    "            y_pred, y_true = process_one_batch(model, test_data, batch_x, batch_y, batch_x_mark, batch_y_mark, args)\n",
    "            \n",
    "            preds.append(y_pred.detach().cpu().numpy())\n",
    "            trues.append(y_true.detach().cpu().numpy())\n",
    "            \n",
    "        preds = np.array(preds)    \n",
    "        trues = np.array(trues)\n",
    "        print('pred shape:', preds.shape, trues.shape)\n",
    "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
    "        print('pred shape:', preds.shape, trues.shape)        \n",
    "        preds = train_set.scaler.inverse_transform(preds)\n",
    "        trues = train_set.scaler.inverse_transform(trues)        \n",
    "            \n",
    "    return preds, trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67a7b5cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:48.369384Z",
     "start_time": "2022-12-13T12:12:48.354424Z"
    }
   },
   "outputs": [],
   "source": [
    "def experiment(partition, args):\n",
    "  \n",
    "    model = Informer(args.enc_in,\n",
    "                     args.dec_in,\n",
    "                     args.c_out,\n",
    "                     args.seq_len,\n",
    "                     args.label_len,\n",
    "                     args.pred_len,\n",
    "                     args.factor,\n",
    "                     args.d_model,\n",
    "                     args.n_heads,\n",
    "                     args.e_layer,\n",
    "                     args.d_layer,\n",
    "                     args.d_ff,\n",
    "                     args.dropout,\n",
    "                     args.attn,\n",
    "                     args.embed,                     \n",
    "                     args.freq,\n",
    "                     args.activation,                     \n",
    "                     args.output_attention,\n",
    "                     args.distill,\n",
    "                     args.mix,\n",
    "                     args.device\n",
    "                    )\n",
    "    model.cuda()\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    criterion.cuda()    \n",
    "    \n",
    "    if args.optim == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=args.gamma)\n",
    "    elif args.optim == 'Adam':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=args.gamma)\n",
    "    elif args.optim == 'AdamW':\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=args.gamma)\n",
    "    else:\n",
    "        raise ValueError('In-valid optimizer choice')\n",
    "    \n",
    "    # ===== List for epoch-wise data ====== #\n",
    "    train_losses = [] # s 붙은건 list 나타내기 위함 \n",
    "    val_losses = []\n",
    "    train_metrics = []\n",
    "    val_metrics = []\n",
    "    # ===================================== #\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience = args.early_stopping_patience, verbose = True)\n",
    "    for epoch in range(args.epoch):  # loop over the dataset multiple times\n",
    "        ts = time.time()\n",
    "        model, train_loss, train_metric = train(model, partition, optimizer, criterion, args)\n",
    "        val_loss, val_metric = validate(model, partition, criterion, args)\n",
    "        te = time.time()\n",
    "        \n",
    "        # ====== Add Epoch Data ====== #\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_metrics.append(train_metric)\n",
    "        val_metrics.append(val_metric)\n",
    "        # ============================ #\n",
    "        \n",
    "        print('Epoch {}, Metric(train/val): {:2.4f}/{:2.4f}, Loss(train/val) {:2.4f}/{:2.4f}. Took {:2.2f} sec'.format(epoch, train_metric, val_metric, train_loss, val_loss, te-ts))\n",
    "        scheduler.step()    \n",
    "        \n",
    "        # ==== Early_stopping은 validation metric이 감소하였는지 체크, 만약 감소하였을 경우 현재 모델을 checkpoint로 생성 == #    \n",
    "        early_stopping(val_metric, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "    test_metric = test(model, partition, args)\n",
    "    \n",
    "    # ==== Best case가 저장되어 있는 last checkpoint 로드 (callback)\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    \n",
    "    # ======= Add Result to Dictionary ======= #\n",
    "    result = {}\n",
    "    result['train_losses'] = train_losses\n",
    "    result['val_losses'] = val_losses\n",
    "    result['train_metrics'] = train_metrics\n",
    "    result['val_metrics'] = val_metrics\n",
    "    result['train_metric'] = train_metric\n",
    "    result['val_metric'] = val_metric\n",
    "    result['test_metric'] = test_metric\n",
    "    return vars(args), result #args를 vars로 감싸면 dictionary가 됨 \n",
    "    # ===================================== #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7dbbb6",
   "metadata": {},
   "source": [
    "# Save option of experiment result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3356f9cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:48.733458Z",
     "start_time": "2022-12-13T12:12:48.719986Z"
    }
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "\n",
    "def save_exp_result(setting, result):\n",
    "    exp_name = setting['exp_name']\n",
    "    del setting['epoch'] # del: 지우기, epoch이 바뀌어도 다른파일이 생기지 않도록 하기 위해 지움  \n",
    "    del setting['test_batch_size'] # test_batch_size가 바뀌어도 다른파일이 생기 않도록 하기 위해 지움 \n",
    "\n",
    "    hash_key = hashlib.sha1(str(setting).encode()).hexdigest()[:6]\n",
    "    filename = './results/{}-{}.json'.format(exp_name, hash_key)\n",
    "    result.update(setting) # 실험결과 뿐만아니라 셋팅도 저장해야하므로 셋팅 dictionary를 합치는 문법 \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(result, f)\n",
    "\n",
    "    \n",
    "def load_exp_result(exp_name):\n",
    "    dir_path = './results'\n",
    "    filenames = [f for f in listdir(dir_path) if isfile(join(dir_path, f)) if '.json' in f]\n",
    "    list_result = []\n",
    "    for filename in filenames:\n",
    "        if exp_name in filename:\n",
    "            with open(join(dir_path, filename), 'r') as infile:\n",
    "                results = json.load(infile)\n",
    "                list_result.append(results)\n",
    "    df = pd.DataFrame(list_result) # .drop(columns=[])\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f35f0397",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:48.937937Z",
     "start_time": "2022-12-13T12:12:48.912493Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_metric(var1, var2, df):\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3)\n",
    "    fig.set_size_inches(18, 6)\n",
    "    sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "    sns.barplot(x=var1, y='train_metric', hue=var2, data=df, ax=ax[0])\n",
    "    sns.barplot(x=var1, y='val_metric', hue=var2, data=df, ax=ax[1])\n",
    "    sns.barplot(x=var1, y='test_metric', hue=var2, data=df, ax=ax[2])\n",
    "    \n",
    "    ax[0].set_title('Train Metric')\n",
    "    ax[1].set_title('Validation Metric')\n",
    "    ax[2].set_title('Test Metric')\n",
    "\n",
    "    \n",
    "def plot_loss_variation(var1, var2, df, **kwargs):\n",
    "\n",
    "    list_v1 = df[var1].unique()\n",
    "    list_v2 = df[var2].unique()\n",
    "    list_data = []\n",
    "\n",
    "    for value1 in list_v1:\n",
    "        for value2 in list_v2:\n",
    "            row = df.loc[df[var1]==value1]\n",
    "            row = row.loc[df[var2]==value2]\n",
    "\n",
    "            train_losses = list(row.train_losses)[0]\n",
    "            val_losses = list(row.val_losses)[0]\n",
    "\n",
    "            for epoch, train_loss in enumerate(train_losses):\n",
    "                list_data.append({'type':'train', 'loss':train_loss, 'epoch':epoch, var1:value1, var2:value2})\n",
    "            for epoch, val_loss in enumerate(val_losses):\n",
    "                list_data.append({'type':'val', 'loss':val_loss, 'epoch':epoch, var1:value1, var2:value2})\n",
    "\n",
    "    df = pd.DataFrame(list_data)\n",
    "    g = sns.FacetGrid(df, row=var2, col=var1, hue='type', **kwargs)\n",
    "    g = g.map(plt.plot, 'epoch', 'loss', marker='.')\n",
    "    g.add_legend()\n",
    "    g.fig.suptitle('Train loss vs Val loss')\n",
    "    plt.subplots_adjust(top=0.89) # 만약 Title이 그래프랑 겹친다면 top 값을 조정해주면 됩니다! 함수 인자로 받으면 그래프마다 조절할 수 있겠죠?\n",
    "\n",
    "\n",
    "def plot_metric_variation(var1, var2, df, **kwargs):\n",
    "    list_v1 = df[var1].unique()\n",
    "    list_v2 = df[var2].unique()\n",
    "    list_data = []\n",
    "\n",
    "    for value1 in list_v1:\n",
    "        for value2 in list_v2:\n",
    "            row = df.loc[df[var1]==value1]\n",
    "            row = row.loc[df[var2]==value2]\n",
    "\n",
    "            train_metrics = list(row.train_metrics)[0]\n",
    "            val_metrics = list(row.val_metrics)[0]\n",
    "            test_metric = list(row.test_metric)[0]\n",
    "\n",
    "            for epoch, train_metric in enumerate(train_metrics):\n",
    "                list_data.append({'type':'train', 'Metric':train_metric, 'test_metric':test_metric, 'epoch':epoch, var1:value1, var2:value2})                \n",
    "            for epoch, val_metric in enumerate(val_metrics):\n",
    "                list_data.append({'type':'val', 'Metric':val_metric, 'test_metric':test_metric, 'epoch':epoch, var1:value1, var2:value2})\n",
    "\n",
    "    df = pd.DataFrame(list_data)\n",
    "    g = sns.FacetGrid(df, row=var2, col=var1, hue='type', **kwargs)\n",
    "    g = g.map(plt.plot, 'epoch', 'Metric', marker='.')\n",
    "\n",
    "    def show_metric(x, y, metric, **kwargs):\n",
    "        plt.scatter(x, y, alpha=0.3, s=1)\n",
    "        metric = \"Test Metric: {:1.4f}\".format(list(metric.values)[0])\n",
    "        plt.text(0.05, 0.95, metric,  horizontalalignment='left', verticalalignment='center', transform=plt.gca().transAxes, bbox=dict(facecolor='yellow', alpha=0.5, boxstyle=\"round,pad=0.1\"))\n",
    "    g = g.map(show_metric, 'epoch', 'Metric', 'test_metric')\n",
    "\n",
    "    g.add_legend()\n",
    "    g.fig.suptitle('Train Metric vs Val Metric')\n",
    "    plt.subplots_adjust(top=0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e179898",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eb0051",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T05:47:32.975021Z",
     "start_time": "2022-12-01T05:47:32.941019Z"
    }
   },
   "source": [
    "## Domain parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba71c972",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:49.538405Z",
     "start_time": "2022-12-13T12:12:49.527923Z"
    }
   },
   "outputs": [],
   "source": [
    "# input_window = 24 # 예측을 위해 참고할 과거 time-step\n",
    "# output_window = 1 # 예측할 미래 time-step\n",
    "# stride = 1 # data 간격 \n",
    "\n",
    "# train_set = get_data(train_data, input_window, output_window, stride)\n",
    "# val_set = get_data(val_data, input_window, output_window, stride)\n",
    "# test_set = get_data(test_data, input_window, output_window, stride)\n",
    "# partition = {'train':train_set, 'val':val_set, 'test':test_set}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303376f4",
   "metadata": {},
   "source": [
    "## Experiment for hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5aeb5220",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:49.947362Z",
     "start_time": "2022-12-13T12:12:49.934884Z"
    }
   },
   "outputs": [],
   "source": [
    "# # ====== Random Seed Initialization ====== #\n",
    "# seed = 123\n",
    "# np.random.seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "# parser = argparse.ArgumentParser()\n",
    "# args = parser.parse_args(\"\")\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "# # ===== Transformer model capacity ==== #\n",
    "# args.d_model = 512\n",
    "# args.n_heads = 8\n",
    "# args.n_layers = 1\n",
    "# args.enc_in_features = 6 # 인코더 src in 피쳐개수\n",
    "# args.dec_in_features = 5 # 디코더 tgt in 피쳐개수\n",
    "# args.out_features = 1 # decoder output 피쳐개수\n",
    "# args.dim_feedforward = 1024\n",
    "# args.encoding_length = input_window\n",
    "# args.decoding_length = output_window\n",
    "\n",
    "# # ==== Transformer regularization ==== #\n",
    "# args.dropout = 0.05\n",
    "# args.l2 = 0\n",
    "\n",
    "# # ==== Optimizer & Training ====#\n",
    "# args.optim = 'Adam'\n",
    "# args.gamma = 0.95\n",
    "# args.lr = 0.0005\n",
    "# args.epoch = 200\n",
    "# args.batch_size = 256\n",
    "# args.early_stopping_patience = 20\n",
    "\n",
    "# # ====== Experiment Variable ====== #\n",
    "# name_var1 = 'd_model'\n",
    "# name_var2 = 'dim_feedforward'\n",
    "# list_var1 = [64, 128, 256, 512, 1024] # model에서 정의한 순서 지켜야됨\n",
    "# list_var2 = [64, 128, 256, 512, 1024]\n",
    "\n",
    "\n",
    "# for var1 in list_var1:\n",
    "#     for var2 in list_var2:\n",
    "#         setattr(args, name_var1, var1) # 실험변수명 자동화 처리 되도록 하는 구문, string attribute 값 지정되면 그 항목값으로 지정 \n",
    "#         setattr(args, name_var2, var2)\n",
    "#         print(args)\n",
    "                \n",
    "#         setting, result = experiment(partition, deepcopy(args))\n",
    "#         save_exp_result(setting, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eb50b3",
   "metadata": {},
   "source": [
    "# Additional test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02b29ddb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:12:51.018620Z",
     "start_time": "2022-12-13T12:12:50.559797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(activation='gelu', attn='prob', batch_size=32, c_out=1, d_ff=128, d_layer=2, d_model=128, dec_in=1, device=device(type='cuda'), distill=True, dropout=0.05, e_layer=[3, 2, 1], early_stopping_patience=5, embed='fixed', enc_in=1, epoch=20, factor=5, features='S', freq='t', gamma=0.95, inverse=False, l2=0, label_len=72, learning_rate=0.0005, lradj='type1', mix=True, n_heads=4, optim='Adam', output_attention=False, padding=0, pred_len=144, seq_len=144, use_amp=True)\n"
     ]
    }
   ],
   "source": [
    "# ====== Random Seed Initialization ====== #\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "# ===== Informer model ==== #\n",
    "args.enc_in = 1 # enc_in_feature\n",
    "args.dec_in = 1 # dec_in_feature\n",
    "args.c_out = 1 # dec_output\n",
    "args.seq_len = 24*6*1\n",
    "args.label_len = 24*3\n",
    "args.pred_len = 24*6*1\n",
    "args.factor = 5\n",
    "args.d_model = 128\n",
    "args.n_heads = 4\n",
    "args.e_layer = [3,2,1]\n",
    "args.d_layer = 2\n",
    "args.d_ff = 128\n",
    "args.dropout = 0.05\n",
    "args.attn = 'prob'\n",
    "args.embed = 'fixed'\n",
    "args.freq = 't'    \n",
    "args.activation =  'gelu'\n",
    "args.output_attention = False\n",
    "args.distill = True\n",
    "args.mix = True\n",
    "args.device = device\n",
    "\n",
    "# ==== Data & Process_one_batch ====#\n",
    "args.features = 'S' # 'S', 'M' 'MS'\n",
    "size = [args.seq_len, args.label_len, args.pred_len]\n",
    "args.padding = 0\n",
    "args.use_amp = True\n",
    "args.inverse = False\n",
    "\n",
    "# ==== Optimizer & Training ====#\n",
    "args.optim = 'Adam'\n",
    "args.lradj = 'type1'\n",
    "args.learning_rate = 0.0005\n",
    "args.l2 = 0\n",
    "args.epoch = 20\n",
    "args.gamma = 0.95\n",
    "args.batch_size = 32\n",
    "args.early_stopping_patience = 5 \n",
    "\n",
    "\n",
    "# ==== Apply args to dataset and model ====#\n",
    "\n",
    "print(args)\n",
    "\n",
    "train_set = Dataset_Custom(flag='train', size=size, freq = args.freq, features=args.features, dataframe= df, inverse=args.inverse) # features; 'S':Univariate, '\n",
    "val_set = Dataset_Custom(flag='val', size=size, freq = args.freq, features=args.features, dataframe= df, inverse=args.inverse)\n",
    "test_set = Dataset_Custom(flag='test', size=size, freq = args.freq, features=args.features, dataframe= df, inverse=args.inverse)\n",
    "partition = {'train':train_set, 'val':val_set, 'test':test_set}\n",
    "\n",
    "test_model = InformerStack(args.enc_in,\n",
    "                 args.dec_in,\n",
    "                 args.c_out,\n",
    "                 args.seq_len,\n",
    "                 args.label_len,\n",
    "                 args.pred_len,\n",
    "                 args.factor,\n",
    "                 args.d_model,\n",
    "                 args.n_heads,\n",
    "                 args.e_layer,\n",
    "                 args.d_layer,\n",
    "                 args.d_ff,\n",
    "                 args.dropout,\n",
    "                 args.attn,\n",
    "                 args.embed,                     \n",
    "                 args.freq,\n",
    "                 args.activation,                     \n",
    "                 args.output_attention,\n",
    "                 args.distill,\n",
    "                 args.mix,\n",
    "                 args.device\n",
    "                ).to(device)\n",
    "\n",
    "criterion = nn.MSELoss() # Loss function\n",
    "criterion.cuda()\n",
    "\n",
    "if args.optim == 'RMSprop':\n",
    "    optimizer = optim.RMSprop(test_model.parameters(), lr=args.learning_rate, weight_decay=args.l2)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=args.gamma)\n",
    "elif args.optim == 'Adam':\n",
    "    optimizer = optim.Adam(test_model.parameters(), lr=args.learning_rate, weight_decay=args.l2)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=args.gamma)\n",
    "elif args.optim == 'AdamW':\n",
    "    optimizer = optim.AdamW(test_model.parameters(), lr=args.learning_rate, weight_decay=args.l2)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=args.gamma)\n",
    "else:\n",
    "    raise ValueError('In-valid optimizer choice')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defb44e9",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8889e340",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T12:30:51.886879Z",
     "start_time": "2022-12-13T12:12:51.767716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Metric(train/val): 17.4396/17.4253, Loss(train/val) 0.230306/0.151840. Took 82.17 sec\n",
      "Validation metric decreased (inf --> 17.425305).  Saving model ...\n",
      "Updating learning rate to 0.0005\n",
      "Epoch 1, Metric(train/val): 12.4827/17.7889, Loss(train/val) 0.111525/0.159479. Took 78.29 sec\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.00025\n",
      "Epoch 2, Metric(train/val): 10.9049/15.9460, Loss(train/val) 0.084824/0.127901. Took 76.56 sec\n",
      "Validation metric decreased (17.425305 --> 15.946013).  Saving model ...\n",
      "Updating learning rate to 0.000125\n",
      "Epoch 3, Metric(train/val): 10.2610/16.0885, Loss(train/val) 0.075064/0.130514. Took 77.29 sec\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.25e-05\n",
      "Epoch 4, Metric(train/val): 9.9513/15.7843, Loss(train/val) 0.070565/0.125262. Took 76.69 sec\n",
      "Validation metric decreased (15.946013 --> 15.784268).  Saving model ...\n",
      "Updating learning rate to 3.125e-05\n",
      "Epoch 5, Metric(train/val): 9.7711/15.7166, Loss(train/val) 0.068054/0.124590. Took 76.43 sec\n",
      "Validation metric decreased (15.784268 --> 15.716584).  Saving model ...\n",
      "Updating learning rate to 1.5625e-05\n",
      "Epoch 6, Metric(train/val): 9.7066/16.0192, Loss(train/val) 0.067125/0.129123. Took 77.52 sec\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.8125e-06\n",
      "Epoch 7, Metric(train/val): 9.6434/15.9043, Loss(train/val) 0.066261/0.127267. Took 78.00 sec\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.90625e-06\n",
      "Epoch 8, Metric(train/val): 9.6360/15.6793, Loss(train/val) 0.066152/0.123950. Took 75.55 sec\n",
      "Validation metric decreased (15.716584 --> 15.679286).  Saving model ...\n",
      "Updating learning rate to 1.953125e-06\n",
      "Epoch 9, Metric(train/val): 9.6115/15.7404, Loss(train/val) 0.065812/0.124900. Took 77.43 sec\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9.765625e-07\n",
      "Epoch 10, Metric(train/val): 9.6081/15.7106, Loss(train/val) 0.065785/0.124140. Took 75.73 sec\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.8828125e-07\n",
      "Epoch 11, Metric(train/val): 9.5978/15.7347, Loss(train/val) 0.065610/0.124595. Took 74.56 sec\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.44140625e-07\n",
      "Epoch 12, Metric(train/val): 9.6102/15.7434, Loss(train/val) 0.065826/0.124962. Took 76.53 sec\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.220703125e-07\n",
      "Epoch 13, Metric(train/val): 9.6051/15.8342, Loss(train/val) 0.065757/0.126383. Took 77.08 sec\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== List for epoch-wise data ====== #\n",
    "train_losses = [] # s 붙은건 list 나타내기 위함 \n",
    "val_losses = []\n",
    "train_metrics = []\n",
    "val_metrics = []\n",
    "# ===================================== #\n",
    "\n",
    "# ==== Early stopping object 초기화 ====#\n",
    "early_stopping = EarlyStopping(patience = args.early_stopping_patience, verbose = True)\n",
    "\n",
    "\n",
    "for epoch in range(args.epoch):  # loop over the dataset multiple times\n",
    "    ts = time.time()\n",
    "    test_model, train_loss, train_metric = train(test_model, partition, optimizer, criterion, args)\n",
    "    val_loss, val_metric = validate(test_model, partition, criterion, args)\n",
    "    te = time.time()\n",
    "\n",
    "    # ====== Add Epoch Data ====== #\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_metrics.append(train_metric)\n",
    "    val_metrics.append(val_metric)\n",
    "    # ============================ #\n",
    "    print('Epoch {}, Metric(train/val): {:2.4f}/{:2.4f}, Loss(train/val) {:2.6f}/{:2.6f}. Took {:2.2f} sec'.format(epoch, train_metric, val_metric, train_loss, val_loss, te-ts))\n",
    "    \n",
    "    # ==== Early_stopping은 validation metric이 감소하였는지 체크, 만약 감소하였을 경우 현재 모델을 checkpoint로 생성 == #\n",
    "    \n",
    "    early_stopping(val_metric, test_model)\n",
    "    \n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "    adjust_learning_rate(optimizer, epoch+1, args)\n",
    "\n",
    "# ==== Best case가 저장되어 있는 last checkpoint 로드 (callback)\n",
    "test_model.load_state_dict(torch.load('checkpoint.pt'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5713a7c3",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37786f33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T11:45:14.849617Z",
     "start_time": "2022-12-13T11:45:12.304739Z"
    }
   },
   "outputs": [],
   "source": [
    "test(test_model, partition, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af25aa09-a8dd-47f5-8a0c-b91df451a129",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1319bc09-2a56-47e7-a800-ac8c0fa9aa3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T11:45:57.093998Z",
     "start_time": "2022-12-13T11:45:56.921448Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(test_model.state_dict(), \"./model_weight/informer_2.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9785e5d-e54d-4a70-94f2-3667b2c05910",
   "metadata": {},
   "source": [
    "# Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986ccfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.load_state_dict(torch.load(\"./model_weight/transformer_2.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3ce1e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T11:15:30.944686Z",
     "start_time": "2022-12-13T11:12:50.936308Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred, y_true = predict(test_model, partition, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709282eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T11:15:30.992559Z",
     "start_time": "2022-12-13T11:15:30.978596Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a07c3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T11:18:04.313611Z",
     "start_time": "2022-12-13T11:18:04.297654Z"
    }
   },
   "outputs": [],
   "source": [
    "num_test = int(len(df)*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7a83d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T11:18:47.926001Z",
     "start_time": "2022-12-13T11:18:47.921014Z"
    }
   },
   "outputs": [],
   "source": [
    "num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4def34d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T11:19:21.012534Z",
     "start_time": "2022-12-13T11:19:19.601308Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "tick_labelsize=10\n",
    "legend_fontsize=11\n",
    "label_fontsize=11\n",
    "fig_hor = 10\n",
    "fig_time_step = 0\n",
    "num_test = int(len(df)*0.2)\n",
    "x_index1=df.iloc[len(df)-num_test+args.seq_len:].index[fig_time_step + args.pred_len*0 : args.pred_len*1+fig_time_step]\n",
    "x_index2=df.iloc[len(df)-num_test+args.seq_len:].index[fig_time_step + args.pred_len*1 : args.pred_len*2+fig_time_step]\n",
    "x_index3=df.iloc[len(df)-num_test+args.seq_len:].index[fig_time_step + args.pred_len*2 : args.pred_len*3+fig_time_step]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(fig_hor,8), constrained_layout=True, dpi=300) # 가로 x 세로\n",
    "\n",
    "ax1 = fig.add_subplot(3,1,1)\n",
    "ax1.plot(x_index1, y_true[fig_time_step+args.pred_len*0], color = 'slateblue', label='True', lw = 1.0, alpha=1.0)\n",
    "ax1.plot(x_index1, y_pred[fig_time_step+args.pred_len*0], color = 'tomato', label='Pred', lw = 1.0, alpha=1.0, linestyle='--')\n",
    "ax1.set_ylabel('Elec cons (kW)', fontweight='bold', fontsize=label_fontsize, labelpad=10)\n",
    "ax1.set_title('Transformer_KPEC_Acutal vs Forecast', fontsize=15, pad=12)\n",
    "ax1.tick_params(axis='x', labelsize=tick_labelsize)\n",
    "ax1.tick_params(axis='y', labelsize=tick_labelsize)\n",
    "ax1.legend(loc='best', fontsize=legend_fontsize)\n",
    "ax1.set_ylim(-5, 45)\n",
    "ax1.grid()\n",
    "\n",
    "ax2 = fig.add_subplot(3,1,2)\n",
    "ax2.plot(x_index2, y_true[fig_time_step+args.pred_len*1], color = 'slateblue', label='True', lw = 1.0, alpha=1.0)\n",
    "ax2.plot(x_index2, y_pred[fig_time_step+args.pred_len*1], color = 'tomato', label='Pred', lw = 1.0, alpha=1.0, linestyle='--')\n",
    "ax2.set_ylabel('Elec cons (kW)', fontweight='bold', fontsize=label_fontsize, labelpad=10)\n",
    "ax2.tick_params(axis='x', labelsize=tick_labelsize)\n",
    "ax2.tick_params(axis='y', labelsize=tick_labelsize)\n",
    "ax2.legend(loc='best', fontsize=legend_fontsize)\n",
    "ax2.set_ylim(-5, 45)\n",
    "ax2.grid()\n",
    "\n",
    "ax3 = fig.add_subplot(3,1,3)\n",
    "ax3.plot(x_index3, y_true[fig_time_step+args.pred_len*2], color = 'slateblue', label='True', lw = 1.0, alpha=1.0)\n",
    "ax3.plot(x_index3, y_pred[fig_time_step+args.pred_len*2], color = 'tomato', label='Pred', lw = 1.0, alpha=1.0, linestyle='--')\n",
    "ax3.set_ylabel('Elec cons (kW)', fontweight='bold', fontsize=label_fontsize, labelpad=10)\n",
    "ax3.tick_params(axis='x', labelsize=tick_labelsize)\n",
    "ax3.tick_params(axis='y', labelsize=tick_labelsize)\n",
    "ax3.legend(loc='best', fontsize=legend_fontsize)\n",
    "ax3.set_ylim(-5, 45)\n",
    "ax3.grid()\n",
    "\n",
    "plt.savefig('informer_1.png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea9af2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T11:20:43.294530Z",
     "start_time": "2022-12-13T11:20:41.857373Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "tick_labelsize=10\n",
    "legend_fontsize=11\n",
    "label_fontsize=11\n",
    "fig_hor = 10\n",
    "fig_time_step = 0\n",
    "num_test = int(len(df)*0.2)\n",
    "x_index1=df.iloc[len(df)-num_test+args.seq_len:].index[fig_time_step + args.pred_len*0 : args.pred_len*1+fig_time_step]\n",
    "x_index2=df.iloc[len(df)-num_test+args.seq_len:].index[fig_time_step + args.pred_len*1 : args.pred_len*2+fig_time_step]\n",
    "x_index3=df.iloc[len(df)-num_test+args.seq_len:].index[fig_time_step + args.pred_len*2 : args.pred_len*3+fig_time_step]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(fig_hor,8), constrained_layout=True, dpi=300) # 가로 x 세로\n",
    "\n",
    "ax1 = fig.add_subplot(3,1,1)\n",
    "ax1.plot(y_true[fig_time_step+args.pred_len*0], color = 'slateblue', label='True', lw = 1.0, alpha=1.0)\n",
    "ax1.plot(y_pred[fig_time_step+args.pred_len*0], color = 'tomato', label='Pred', lw = 1.0, alpha=1.0, linestyle='--')\n",
    "ax1.set_ylabel('Elec cons (kW)', fontweight='bold', fontsize=label_fontsize, labelpad=10)\n",
    "ax1.set_title('Transformer_KPEC_Acutal vs Forecast', fontsize=15, pad=12)\n",
    "ax1.tick_params(axis='x', labelsize=tick_labelsize)\n",
    "ax1.tick_params(axis='y', labelsize=tick_labelsize)\n",
    "ax1.legend(loc='best', fontsize=legend_fontsize)\n",
    "# ax1.set_ylim(-5, 45)\n",
    "ax1.grid()\n",
    "\n",
    "ax2 = fig.add_subplot(3,1,2)\n",
    "ax2.plot(y_true[fig_time_step+args.pred_len*1], color = 'slateblue', label='True', lw = 1.0, alpha=1.0)\n",
    "ax2.plot(y_pred[fig_time_step+args.pred_len*1], color = 'tomato', label='Pred', lw = 1.0, alpha=1.0, linestyle='--')\n",
    "ax2.set_ylabel('Elec cons (kW)', fontweight='bold', fontsize=label_fontsize, labelpad=10)\n",
    "ax2.tick_params(axis='x', labelsize=tick_labelsize)\n",
    "ax2.tick_params(axis='y', labelsize=tick_labelsize)\n",
    "ax2.legend(loc='best', fontsize=legend_fontsize)\n",
    "# ax2.set_ylim(-5, 45)\n",
    "ax2.grid()\n",
    "\n",
    "ax3 = fig.add_subplot(3,1,3)\n",
    "ax3.plot(y_true[fig_time_step+args.pred_len*2], color = 'slateblue', label='True', lw = 1.0, alpha=1.0)\n",
    "ax3.plot(y_pred[fig_time_step+args.pred_len*2], color = 'tomato', label='Pred', lw = 1.0, alpha=1.0, linestyle='--')\n",
    "ax3.set_ylabel('Elec cons (kW)', fontweight='bold', fontsize=label_fontsize, labelpad=10)\n",
    "ax3.tick_params(axis='x', labelsize=tick_labelsize)\n",
    "ax3.tick_params(axis='y', labelsize=tick_labelsize)\n",
    "ax3.legend(loc='best', fontsize=legend_fontsize)\n",
    "# ax3.set_ylim(-5, 45)\n",
    "ax3.grid()\n",
    "\n",
    "plt.savefig('informer_1.png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c136e85c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3976fdf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d32f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Pred(Dataset):\n",
    "    def __init__(self, flag='pred', size=None, \n",
    "                 features='S', dataframe=None, \n",
    "                 target='562_elec', scale=True, inverse=False, timeenc=0, freq='1min', cols=None):\n",
    "        # size [seq_len, label_len, pred_len]\n",
    "        # info\n",
    "        if size == None:\n",
    "            self.seq_len = 24*4*4\n",
    "            self.label_len = 24*4\n",
    "            self.pred_len = 24*4\n",
    "        else:\n",
    "            self.seq_len = size[0]\n",
    "            self.label_len = size[1]\n",
    "            self.pred_len = size[2]\n",
    "        # init\n",
    "        assert flag in ['pred']\n",
    "        \n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.scale = scale\n",
    "        self.inverse = inverse\n",
    "        self.timeenc = timeenc\n",
    "        self.freq = freq\n",
    "        self.cols=cols        \n",
    "        self.dataframe = df\n",
    "        self.__read_data__()\n",
    "\n",
    "    def __read_data__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        df_raw = self.dataframe\n",
    "        '''\n",
    "        df_raw.columns: ['date', ...(other features), target feature]\n",
    "        '''\n",
    "        if self.cols:\n",
    "            cols=self.cols.copy()\n",
    "            cols.remove(self.target)\n",
    "        else:\n",
    "            cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')\n",
    "        df_raw = df_raw[['date']+cols+[self.target]]\n",
    "        \n",
    "        border1 = len(df_raw)-self.seq_len\n",
    "        border2 = len(df_raw)\n",
    "        \n",
    "        if self.features=='M' or self.features=='MS':\n",
    "            cols_data = df_raw.columns[1:]\n",
    "            df_data = df_raw[cols_data]\n",
    "        elif self.features=='S':\n",
    "            df_data = df_raw[[self.target]]\n",
    "\n",
    "        if self.scale:\n",
    "            self.scaler.fit(df_data.values)\n",
    "            data = self.scaler.transform(df_data.values)\n",
    "        else:\n",
    "            data = df_data.values\n",
    "            \n",
    "        tmp_stamp = df_raw[['date']][border1:border2]\n",
    "        tmp_stamp['date'] = pd.to_datetime(tmp_stamp.date)\n",
    "        pred_dates = pd.date_range(tmp_stamp.date.values[-1], periods=self.pred_len+1, freq=self.freq)\n",
    "        \n",
    "        df_stamp = pd.DataFrame(columns = ['date'])\n",
    "        df_stamp.date = list(tmp_stamp.date.values) + list(pred_dates[1:])\n",
    "        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq[-1:])\n",
    "\n",
    "        self.data_x = data[border1:border2]\n",
    "        if self.inverse:\n",
    "            self.data_y = df_data.values[border1:border2]\n",
    "        else:\n",
    "            self.data_y = data[border1:border2]\n",
    "        self.data_stamp = data_stamp\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end - self.label_len\n",
    "        r_end = r_begin + self.label_len + self.pred_len\n",
    "\n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        if self.inverse:\n",
    "            seq_y = self.data_x[r_begin:r_begin+self.label_len]\n",
    "        else:\n",
    "            seq_y = self.data_y[r_begin:r_begin+self.label_len]\n",
    "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
    "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
    "\n",
    "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_x) - self.seq_len + 1\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return self.scaler.inverse_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862fb72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, args):\n",
    "    pred_set = Dataset_Pred(size=size, freq='1h', dataframe=df)\n",
    "    pred_loader = DataLoader(pred_set, batch_size=1, shuffle=False, num_workers=0)\n",
    "    \n",
    "    model.eval() # Turn on the evaluation mode\n",
    "    preds = []\n",
    "    trues = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in pred_loader:            \n",
    "            batch_x, batch_y, batch_x_mark, batch_y_mark = data       \n",
    "            y_pred, y_true = process_one_batch(model, pred_set, batch_x, batch_y, batch_x_mark, batch_y_mark, args)\n",
    "            preds.append(y_pred.cpu().detach().numpy())\n",
    "            trues.append(y_true.cpu().detach().numpy())       \n",
    "            \n",
    "        preds = np.array(preds) \n",
    "        trues = np.array(trues)\n",
    "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])                \n",
    "            \n",
    "    return preds, trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89922b7-c6e8-4fb3-9a74-bab831a57d91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_model.load_state_dict(torch.load('informer_ver1.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305cc839",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_true = predict(test_model, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0faadb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred.shape, y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f772a4fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T01:27:31.848865Z",
     "start_time": "2022-12-07T01:26:32.340842Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = train_set.scaler.inverse_transform(y_pred)\n",
    "y_true = train_set.scaler.inverse_transform(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1da5cd-2fb5-48a8-babb-83f7da33fbe9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T01:28:54.635941Z",
     "start_time": "2022-12-07T01:28:53.980113Z"
    }
   },
   "outputs": [],
   "source": [
    "# sns.set_style('ticks')\n",
    "tick_labelsize=10\n",
    "legend_fontsize=11\n",
    "label_fontsize=11\n",
    "\n",
    "fig_hor = 10\n",
    "\n",
    "fig = plt.figure(figsize=(fig_hor,4), constrained_layout=True, dpi=400) # 가로 x 세로\n",
    "\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax1.plot(y_true.squeeze(), color = 'slateblue', label='True', lw = 0.5, alpha=1.0)\n",
    "ax1.plot(y_pred.squeeze(), color = 'tomato', label='Pred', lw = 1.0, alpha=0.5, linestyle='--')\n",
    "ax1.set_ylabel('Elec demand', fontweight='bold', fontsize=label_fontsize, labelpad=10)\n",
    "ax1.set_title('562_Acutal vs Forecast', fontsize=15, pad=12)\n",
    "ax1.tick_params(axis='x', labelsize=tick_labelsize)\n",
    "ax1.tick_params(axis='y', labelsize=tick_labelsize)\n",
    "ax1.legend(loc='best', fontsize=legend_fontsize)\n",
    "# ax1.set_ylim(-20, 270)\n",
    "ax1.grid()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f885a91-3274-44b9-a7b2-d127782012d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T01:29:21.403935Z",
     "start_time": "2022-12-07T01:29:21.012930Z"
    }
   },
   "outputs": [],
   "source": [
    "width = 120\n",
    "tick_labelsize=10\n",
    "legend_fontsize=11\n",
    "label_fontsize=11\n",
    "\n",
    "fig_hor = 10\n",
    "\n",
    "fig = plt.figure(figsize=(fig_hor,4), constrained_layout=True, dpi=400) # 가로 x 세로\n",
    "\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "ax1.plot(y_true[:,0,:][:width], color = 'slateblue', label='True', lw = 0.5, alpha=1.0)\n",
    "ax1.plot(y_pred[:,0,:][:width], color = 'tomato', label='Pred', lw = 1.0, alpha=0.5, linestyle='--')\n",
    "ax1.set_ylabel('Elec demand', fontweight='bold', fontsize=label_fontsize, labelpad=10)\n",
    "ax1.set_title('562_Acutal vs Forecast', fontsize=15, pad=12)\n",
    "ax1.tick_params(axis='x', labelsize=tick_labelsize)\n",
    "ax1.tick_params(axis='y', labelsize=tick_labelsize)\n",
    "ax1.legend(loc='best', fontsize=legend_fontsize)\n",
    "# ax1.set_ylim(-20, 270)\n",
    "ax1.grid()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bbdab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 120\n",
    "tick_labelsize=10\n",
    "legend_fontsize=11\n",
    "label_fontsize=11\n",
    "\n",
    "fig_hor = 10\n",
    "\n",
    "fig = plt.figure(figsize=(fig_hor,4), constrained_layout=True, dpi=400) # 가로 x 세로\n",
    "\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "ax1.plot(y_true[:,5,:][:width], color = 'slateblue', label='True', lw = 0.5, alpha=1.0)\n",
    "ax1.plot(y_pred[:,5,:][:width], color = 'tomato', label='Pred', lw = 1.0, alpha=0.5, linestyle='--')\n",
    "ax1.set_ylabel('Elec demand', fontweight='bold', fontsize=label_fontsize, labelpad=10)\n",
    "ax1.set_title('562_Acutal vs Forecast', fontsize=15, pad=12)\n",
    "ax1.tick_params(axis='x', labelsize=tick_labelsize)\n",
    "ax1.tick_params(axis='y', labelsize=tick_labelsize)\n",
    "ax1.legend(loc='best', fontsize=legend_fontsize)\n",
    "# ax1.set_ylim(-20, 270)\n",
    "ax1.grid()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011e767d",
   "metadata": {},
   "source": [
    "# Test with other data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dfb6d5",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba6a18f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T01:34:14.953267Z",
     "start_time": "2022-12-07T01:34:14.940302Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tgt2 = df[['ELEC_561_Ptot']]\n",
    "df_nontgt2 = df[['MONTH', 'DAY', 'HOUR', 'WEEKDAY', \"HOLIDAY\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15b607b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T01:34:22.474510Z",
     "start_time": "2022-12-07T01:34:22.459550Z"
    }
   },
   "outputs": [],
   "source": [
    "df_nontgt2['MONTH'] = df_nontgt2['MONTH']/12\n",
    "df_nontgt2['DAY'] = df_nontgt2['DAY']/31\n",
    "df_nontgt2['HOUR'] = df_nontgt2['HOUR']/24\n",
    "df_nontgt2['WEEKDAY'] = df_nontgt2['WEEKDAY']/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59f8c16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T01:35:57.931347Z",
     "start_time": "2022-12-07T01:35:57.923863Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tgt2 = scaler.transform(df_tgt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ac3da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T01:37:15.247938Z",
     "start_time": "2022-12-07T01:37:15.221011Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_data = np.concatenate((df_nontgt2, df_tgt2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a847400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T01:37:32.476921Z",
     "start_time": "2022-12-07T01:37:32.458970Z"
    }
   },
   "outputs": [],
   "source": [
    "print(pred_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bf76b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T01:41:59.343162Z",
     "start_time": "2022-12-07T01:41:58.939216Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_set = get_data(pred_data, input_window, output_window, stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab75817",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T01:42:00.731539Z",
     "start_time": "2022-12-07T01:42:00.722563Z"
    }
   },
   "outputs": [],
   "source": [
    "def general_predict(model):\n",
    "    pred_loader = DataLoader(pred_set, batch_size=1, shuffle=False, num_workers=0)\n",
    "    \n",
    "    model.eval() # Turn on the evaluation mode\n",
    "    preds = []\n",
    "    trues = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in pred_loader:            \n",
    "            src, tgt, y_true = data\n",
    "            src = src.cuda()\n",
    "            tgt = tgt.cuda()\n",
    "            y_true = y_true.cuda()            \n",
    "            y_pred = model(src, tgt)            \n",
    "            preds.append(y_pred.cpu().detach().numpy())\n",
    "            trues.append(y_true.cpu().detach().numpy())       \n",
    "            \n",
    "        preds = np.array(preds) \n",
    "        trues = np.array(trues)\n",
    "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])                \n",
    "            \n",
    "    return preds, trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b7e1ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T01:52:05.032149Z",
     "start_time": "2022-12-07T01:42:06.196267Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred2, y_true2 = general_predict(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e03f4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T01:52:05.203715Z",
     "start_time": "2022-12-07T01:52:05.189243Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred2 = scaler.inverse_transform(y_pred2)\n",
    "y_true2 = scaler.inverse_transform(y_true2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aacb556",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T01:56:38.202168Z",
     "start_time": "2022-12-07T01:56:37.050102Z"
    }
   },
   "outputs": [],
   "source": [
    "# sns.set_style('ticks')\n",
    "tick_labelsize=10\n",
    "legend_fontsize=11\n",
    "label_fontsize=11\n",
    "\n",
    "fig_hor = 10\n",
    "\n",
    "fig = plt.figure(figsize=(fig_hor,4), constrained_layout=True, dpi=400) # 가로 x 세로\n",
    "\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax1.plot(y_true2.squeeze(1), color = 'slateblue', label='True', lw = 0.5, alpha=1.0)\n",
    "ax1.plot(y_pred2.squeeze(1), color = 'tomato', label='Pred', lw = 1.0, alpha=0.5, linestyle='--')\n",
    "ax1.set_ylabel('Elec demand', fontweight='bold', fontsize=label_fontsize, labelpad=10)\n",
    "ax1.set_title('561_Acutal vs Forecast', fontsize=15, pad=12)\n",
    "ax1.tick_params(axis='x', labelsize=tick_labelsize)\n",
    "ax1.tick_params(axis='y', labelsize=tick_labelsize)\n",
    "ax1.legend(loc='best', fontsize=legend_fontsize)\n",
    "# ax1.set_ylim(-20, 270)\n",
    "ax1.grid()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dd7a74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T01:56:42.346064Z",
     "start_time": "2022-12-07T01:56:41.802449Z"
    }
   },
   "outputs": [],
   "source": [
    "# sns.set_style('ticks')\n",
    "tick_labelsize=10\n",
    "legend_fontsize=11\n",
    "label_fontsize=11\n",
    "\n",
    "fig_hor = 10\n",
    "\n",
    "fig = plt.figure(figsize=(fig_hor,4), constrained_layout=True, dpi=400) # 가로 x 세로\n",
    "\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax1.plot(y_true2.squeeze(1)[:24000], color = 'slateblue', label='True', lw = 0.5, alpha=1.0)\n",
    "ax1.plot(y_pred2.squeeze(1)[:24000], color = 'tomato', label='Pred', lw = 1.0, alpha=0.5, linestyle='--')\n",
    "ax1.set_ylabel('Elec demand', fontweight='bold', fontsize=label_fontsize, labelpad=10)\n",
    "ax1.set_title('561_Acutal vs Forecast', fontsize=15, pad=12)\n",
    "ax1.tick_params(axis='x', labelsize=tick_labelsize)\n",
    "ax1.tick_params(axis='y', labelsize=tick_labelsize)\n",
    "ax1.legend(loc='best', fontsize=legend_fontsize)\n",
    "# ax1.set_ylim(-20, 270)\n",
    "ax1.grid()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff9905c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74307dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eebb89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908deea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf2253e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748d2cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f5f198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c692781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e555b99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
