{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4908,
     "status": "ok",
     "timestamp": 1713352097192,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "jCfL6bLPsKfh"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# # 그래프에서 한글이 깨지지 않게 폰트 설치..\n",
    "# # *맨처음 실행 후 세션 다시 시작해야 반영됨!!\n",
    "# !sudo apt-get install -y fonts-nanum\n",
    "# !sudo fc-cache -fv\n",
    "# !rm ~/.cache/matplotlib -rf\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family='NanumBarunGothic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidConfigError",
     "evalue": "Invalid client secrets file ('Error opening file', 'client_secrets.json', 'No such file or directory', 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\oauth2client\\clientsecrets.py:121\u001b[0m, in \u001b[0;36m_loadfile\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m    122\u001b[0m         obj \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(fp)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'client_secrets.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidClientSecretsError\u001b[0m                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pydrive\\auth.py:386\u001b[0m, in \u001b[0;36mGoogleAuth.LoadClientConfigFile\u001b[1;34m(self, client_config_file)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 386\u001b[0m   client_type, client_info \u001b[38;5;241m=\u001b[39m \u001b[43mclientsecrets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_config_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m clientsecrets\u001b[38;5;241m.\u001b[39mInvalidClientSecretsError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\oauth2client\\clientsecrets.py:165\u001b[0m, in \u001b[0;36mloadfile\u001b[1;34m(filename, cache)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache:\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_loadfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m obj \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(filename, namespace\u001b[38;5;241m=\u001b[39m_SECRET_NAMESPACE)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\oauth2client\\clientsecrets.py:124\u001b[0m, in \u001b[0;36m_loadfile\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidClientSecretsError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError opening file\u001b[39m\u001b[38;5;124m'\u001b[39m, exc\u001b[38;5;241m.\u001b[39mfilename,\n\u001b[0;32m    125\u001b[0m                                     exc\u001b[38;5;241m.\u001b[39mstrerror, exc\u001b[38;5;241m.\u001b[39merrno)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _validate_clientsecrets(obj)\n",
      "\u001b[1;31mInvalidClientSecretsError\u001b[0m: ('Error opening file', 'client_secrets.json', 'No such file or directory', 2)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidConfigError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 인증 객체 생성\u001b[39;00m\n\u001b[0;32m      2\u001b[0m gauth \u001b[38;5;241m=\u001b[39m GoogleAuth()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mgauth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLocalWebserverAuth\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pydrive\\auth.py:113\u001b[0m, in \u001b[0;36mCheckAuth.<locals>._decorated\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLoadCredentials()\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflow \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGetFlow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcredentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    115\u001b[0m   code \u001b[38;5;241m=\u001b[39m decoratee(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pydrive\\auth.py:443\u001b[0m, in \u001b[0;36mGoogleAuth.GetFlow\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Gets Flow object from client configuration.\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \n\u001b[0;32m    439\u001b[0m \u001b[38;5;124;03m:raises: InvalidConfigError\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(config \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient_config \\\n\u001b[0;32m    442\u001b[0m            \u001b[38;5;28;01mfor\u001b[39;00m config \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCLIENT_CONFIGS_LIST):\n\u001b[1;32m--> 443\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoadClientConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m constructor_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mredirect_uri\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mredirect_uri\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauth_uri\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauth_uri\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_uri\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_uri\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    448\u001b[0m }\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrevoke_uri\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pydrive\\auth.py:366\u001b[0m, in \u001b[0;36mGoogleAuth.LoadClientConfig\u001b[1;34m(self, backend)\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidConfigError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease specify client config backend\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 366\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoadClientConfigFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msettings\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    368\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLoadClientConfigSettings()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pydrive\\auth.py:388\u001b[0m, in \u001b[0;36mGoogleAuth.LoadClientConfigFile\u001b[1;34m(self, client_config_file)\u001b[0m\n\u001b[0;32m    386\u001b[0m   client_type, client_info \u001b[38;5;241m=\u001b[39m clientsecrets\u001b[38;5;241m.\u001b[39mloadfile(client_config_file)\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m clientsecrets\u001b[38;5;241m.\u001b[39mInvalidClientSecretsError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m--> 388\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m InvalidConfigError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid client secrets file \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m error)\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m client_type \u001b[38;5;129;01min\u001b[39;00m (clientsecrets\u001b[38;5;241m.\u001b[39mTYPE_WEB,\n\u001b[0;32m    390\u001b[0m                        clientsecrets\u001b[38;5;241m.\u001b[39mTYPE_INSTALLED):\n\u001b[0;32m    391\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m InvalidConfigError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown client_type of client config file\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mInvalidConfigError\u001b[0m: Invalid client secrets file ('Error opening file', 'client_secrets.json', 'No such file or directory', 2)"
     ]
    }
   ],
   "source": [
    "# 인증 객체 생성\n",
    "gauth = GoogleAuth()\n",
    "gauth.LocalWebserverAuth()  # 웹 브라우저를 통해 인증 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18481,
     "status": "ok",
     "timestamp": 1713352115665,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "1spvtzWeN_qA",
    "outputId": "ad3769aa-cd72-4110-ff32-c7bd6cb7f321",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'drive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# from google.colab import drive\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdrive\u001b[49m\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'drive' is not defined"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24956,
     "status": "ok",
     "timestamp": 1713352148924,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "zLax66xAd6EE"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install gdown\n",
    "!pip install einops\n",
    "!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15808,
     "status": "ok",
     "timestamp": 1713352169061,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "MTWYysoYmgVO",
    "outputId": "553dbf33-fd42-4688-b866-a3d71fc38529"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import math, random\n",
    "from einops import rearrange\n",
    "import time\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1713352169061,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "rsIpxtPusch4"
   },
   "outputs": [],
   "source": [
    "# for random seed\n",
    "random_seed = 0\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320,
     "referenced_widgets": [
      "12409705e490475ab24cce661ec3e4ba",
      "4b83da33aaff4b0eabb965370d676214",
      "1e9673caa1324401802b246240fb9397",
      "a14f2b61d6224dd59645dc010bb18bbe",
      "5bc8c11f8dab470e9429320a54b64dac",
      "ad54caeecb9d4857ac0102a50dbe0fa1",
      "80240161b8f7421db6a9c52cd1f27f96",
      "9af99b269cf843b6bb04884cd44f4251",
      "c7de655990c64e1495fc9ad849a83699",
      "544f7b4bad9d4f5f8d489069120cc94d",
      "ac0085b3780f4dd897689fa396a2036d",
      "a19268ef46924f9abe496fe658bbc370",
      "10224ff7f8fb4a56a1046f10f12754b2",
      "fb21d1709b2048188c9b82f8cdb207ee",
      "0d64ca08ba8a4c1b8a8aae3eee98d05a",
      "3e200bf03f6f4b7782ecd59ed0a82f5a",
      "50138f718fcd4a97a92ead014cc993de",
      "5294f88fe97e44bc9fa514ca481eb1dd",
      "c0bec189a74f4326ad6a70e500b31c45",
      "13f13c99ea704629951f2902c200b3b1",
      "92365e84af0349609ece11a133454774",
      "5357c28e5a344b398a03b92dff05d30e",
      "72d6e28f94434fb99326b232182e0fa8",
      "62441f096afa4b0fb5465b42e522948e",
      "d11ed627731349f6b5308c489bdfa24d",
      "cf6f97d1d1cb4b848a7ba14d03f0bc43",
      "85ff2397941b48a8a01bb32f7725db29",
      "ef2e106fa5a3499ba932cb6617529adc",
      "1212fd2a03354f31b18706001b0cf445",
      "1e4a35e92af94b9392c8eeecda70eb2d",
      "a4494c5ad498407ab42728d8f5d7f1ca",
      "806f67dff29d402da2ef49721cd389be",
      "838d260527e14b77aa48c12eb3b8ec41"
     ]
    },
    "executionInfo": {
     "elapsed": 2525,
     "status": "ok",
     "timestamp": 1713352171567,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "M91CMRBUxnOX",
    "outputId": "02a64d66-3f44-462e-abe6-63d61d5ea245"
   },
   "outputs": [],
   "source": [
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
    "pad_idx = tokenizer.pad_token_id\n",
    "print(\"pad_idx = \", pad_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5yc63mSLmhA"
   },
   "source": [
    "## 하이퍼파라미터 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12237,
     "status": "ok",
     "timestamp": 1713352459247,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "LrCcO4lFbavF",
    "outputId": "7e9290dc-3813-4201-ee23-3f88a4d466e1"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64 # GPT-1 논문의 값, Fine-tune 시에는 32 사용, GPT-2 에선 512 사용\n",
    "LAMBDA = 0 # GPT-1 에선 0.01, l2-Regularization를 위한 hyperparam.\n",
    "EPOCH = 15 # GPT-1 에선 100 Epoch, Fine-tune 시에는 3 사용\n",
    "max_len = 100\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = pad_idx) # pad token 이 출력 나와야하는 시점의 loss는 무시 (즉, label이 <pad> 일 때는 무시)\n",
    "\n",
    "warmup_steps = 2000 # GPT-1 논문의 값, Fine-tune 시에는 total_steps의 0.2% 만 warmup\n",
    "LR_peak = 2.5e-4 # GPT-1 논문의 값, Fine-tune 시에는 6.25e-5\n",
    "total_steps = EPOCH * math.ceil(97000/BATCH_SIZE) # 97000: 문장 데이터 수\n",
    "def lr_lambda(step): # LambdaLR 쓰면 Custom 스케쥴러처럼 일일히 step+=1 할 필요 없음! step 만 입력 받으면 되는 스케쥴러라면 LambdaLR 사용하면 됨\n",
    "    return min(step / warmup_steps, (0.5 * (1 + math.cos(math.pi * (step - warmup_steps) / (total_steps - warmup_steps))))) # 이게 LR_peak 에 곱해짐\n",
    "\n",
    "new_model_train = False\n",
    "hyuk_model_use = True # 여러분만의 모델 만들어서 사용하고 싶다면 False로\n",
    "if hyuk_model_use:\n",
    "    !gdown https://drive.google.com/uc?id=1u4-QhuKcHwDifff5eHLhuZmfJ52c3tkN -O GPT_small.pt\n",
    "    !gdown https://drive.google.com/uc?id=1-3uZGsxgaoll8LNzDBNGjhCYRYorRdRq -O GPT_small_history.pt\n",
    "    save_model_path = 'GPT_small.pt'\n",
    "    save_history_path = 'GPT_small_history.pt'\n",
    "else:\n",
    "    save_model_path = '/content/drive/MyDrive/Colab Notebooks/results/GPT_small2.pt'\n",
    "    save_history_path = '/content/drive/MyDrive/Colab Notebooks/results/GPT_small2_history.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1713352459247,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "z_s8XVEO0FJV",
    "outputId": "ff50a5fc-dcc9-41c0-ae4e-076994b89bb3"
   },
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "print(vocab_size)\n",
    "\n",
    "# GPT-3 (1750억개 파라미터)\n",
    "# n_layers = 96\n",
    "# d_model = 12288\n",
    "# d_ff = 49152 # d_model 의 네 배\n",
    "# n_heads = 96\n",
    "# drop_p = 0.1\n",
    "\n",
    "# 실험에서 사용할 작은 GPT (drop_p 이외엔 GPT-1 과 일치)\n",
    "n_layers = 12\n",
    "d_model = 768\n",
    "d_ff = d_model * 4\n",
    "n_heads = 12\n",
    "drop_p = 0.25 # GPT-1 에서는 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6864,
     "status": "ok",
     "timestamp": 1713352530469,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "pCprHKgYcfHN",
    "outputId": "f8b03394-c0be-48e2-c9c1-9a918726c656"
   },
   "outputs": [],
   "source": [
    "print(tokenizer.get_vocab())\n",
    "print(tokenizer.vocab_size)\n",
    "\n",
    "print(tokenizer.tokenize(\"신발이 참 예쁘네요!\"))\n",
    "print(tokenizer.encode('신발이 참 예쁘네요!')) # string to index\n",
    "print(tokenizer.decode([2155]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEdSAEdAYzBf"
   },
   "source": [
    "## DS, DL 생성 & 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20156,
     "status": "ok",
     "timestamp": 1713352615153,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "VmDVZxIOdnKJ"
   },
   "outputs": [],
   "source": [
    "# data 다운\n",
    "%%capture\n",
    "# https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=126 에서 받을 수 있어요\n",
    "!gdown https://drive.google.com/uc?id=14lAjaR2dRp5p5kEsm5GnwNM9KH-VgoOq -O 대화체.xlsx\n",
    "data = pd.read_excel('대화체.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1713352850323,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "LO8CDAgiFzgW",
    "outputId": "bd6e77f1-91da-433c-d8d9-e5fdc0c21c07"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.loc[idx, '원문']\n",
    "\n",
    "custom_DS = CustomDataset(data)\n",
    "\n",
    "train_DS, val_DS, test_DS, _ = torch.utils.data.random_split(custom_DS, [97000, 2000, 1000, len(custom_DS)-97000-2000-1000])\n",
    "\n",
    "train_DL = torch.utils.data.DataLoader(train_DS, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_DL = torch.utils.data.DataLoader(val_DS, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_DL = torch.utils.data.DataLoader(test_DS, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(len(train_DS))\n",
    "print(len(val_DS))\n",
    "print(len(test_DS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1713352962414,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "g1eSFkg9pYkl",
    "outputId": "345e4e13-21f9-469e-cd2a-d26f3a9cab98"
   },
   "outputs": [],
   "source": [
    "# train_DL 테스트\n",
    "for texts in train_DL:\n",
    "\n",
    "    print(texts)\n",
    "    print(len(texts))\n",
    "\n",
    "    texts = [s + ' [SEP]'for s in texts]\n",
    "    x_batch = tokenizer(texts, padding=True, truncation=True, max_length = max_len, return_tensors='pt', add_special_tokens = False).input_ids # pt: pytorch tensor로 변환\n",
    "    # add_special_tokens = True (default)면 첫 토큰에 [CLS], 마지막 토큰에 [SEP]이 붙어 나옴\n",
    "\n",
    "    print(x_batch[:2])\n",
    "    print(x_batch.shape)\n",
    "    print(x_batch[5,:-1]) # 입력\n",
    "    print(x_batch[5,1:]) # label\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1QI9ylaH8jN"
   },
   "source": [
    "## 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 514,
     "status": "ok",
     "timestamp": 1713353796338,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "KHjUdTFQl4sW"
   },
   "outputs": [],
   "source": [
    "class MHA(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, drop_p):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.fc_q = nn.Linear(d_model, d_model) # 차 or 개x차 or 개x개x차 로 입력해줘야\n",
    "        self.fc_k = nn.Linear(d_model, d_model)\n",
    "        self.fc_v = nn.Linear(d_model, d_model)\n",
    "        self.fc_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(drop_p) # GPT-1 논문에서 어텐션 드롭아웃 적용\n",
    "        self.scale = torch.sqrt(torch.tensor(d_model / n_heads))\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        Q = self.fc_q(x)  # 개단차\n",
    "        K = self.fc_k(x)\n",
    "        V = self.fc_v(x)\n",
    "\n",
    "        Q = rearrange(Q, '개 단 (헤 차) -> 개 헤 단 차', 헤 = self.n_heads) # 개단차 -> 개헤단차\n",
    "        K = rearrange(K, '개 단 (헤 차) -> 개 헤 단 차', 헤 = self.n_heads)\n",
    "        V = rearrange(V, '개 단 (헤 차) -> 개 헤 단 차', 헤 = self.n_heads)\n",
    "\n",
    "        attention_score = Q @ K.transpose(-2,-1) / self.scale # 개헤단단\n",
    "\n",
    "        if mask is not None:\n",
    "            attention_score[mask] = -1e10\n",
    "        attention_weights = torch.softmax(attention_score, dim=-1) # 개헤단단\n",
    "\n",
    "        attention_weights = self.dropout(attention_weights) # 개헤단단\n",
    "\n",
    "        attention = attention_weights @ V # 개헤단차\n",
    "\n",
    "        x = rearrange(attention, '개 헤 단 차 -> 개 단 (헤 차)') # 개헤단차 -> 개단차\n",
    "        x = self.fc_o(x)  # 개단차\n",
    "\n",
    "        return x, attention_weights\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, drop_p):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Sequential(nn.Linear(d_model, d_ff),\n",
    "                                    nn.GELU(),\n",
    "                                    nn.Dropout(drop_p), # 논문에는 명시되어 있지 않지만.. overfitting 취약한 부분이라\n",
    "                                    nn.Linear(d_ff, d_model))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, n_heads, drop_p):\n",
    "        super().__init__()\n",
    "\n",
    "        self.self_atten_LN = nn.LayerNorm(d_model)\n",
    "        self.self_atten = MHA(d_model, n_heads, drop_p)\n",
    "\n",
    "        self.FF_LN = nn.LayerNorm(d_model)\n",
    "        self.FF = FeedForward(d_model, d_ff, drop_p)\n",
    "\n",
    "        self.dropout = nn.Dropout(drop_p)\n",
    "\n",
    "    def forward(self, x, dec_mask):\n",
    "\n",
    "        residual = self.self_atten_LN(x)\n",
    "        residual, atten_dec = self.self_atten(residual, dec_mask)\n",
    "        residual = self.dropout(residual) # 원랜 attn -> drop -> add -> norm 이었는데 norm -> attn -> drop -> add 순으로 변경 (GPT-2 에서)\n",
    "        x = x + residual\n",
    "\n",
    "        residual = self.FF_LN(x)\n",
    "        residual = self.FF(residual)\n",
    "        residual = self.dropout(residual)\n",
    "        x = x + residual\n",
    "\n",
    "        return x, atten_dec\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, max_len, n_layers, d_model, d_ff, n_heads, drop_p):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embedding = nn.Embedding(max_len, d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(drop_p)\n",
    "\n",
    "        self.layers = nn.ModuleList([DecoderLayer(d_model, d_ff, n_heads, drop_p) for _ in range(n_layers)])\n",
    "\n",
    "        self.LN_out = nn.LayerNorm(d_model)\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x, dec_mask, atten_map_save = False): # x.shape = 개단, enc_out.shape = 개단차, dec_mask.shape = 개헤단단\n",
    "\n",
    "        pos = torch.arange(x.shape[1]).expand_as(x).to(DEVICE) # 개단\n",
    "\n",
    "        x = self.input_embedding(x) + self.pos_embedding(pos) # 개단차\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        atten_decs = torch.tensor([]).to(DEVICE)\n",
    "        for layer in self.layers:\n",
    "            x, atten_dec = layer(x, dec_mask)\n",
    "            if atten_map_save is True:\n",
    "                atten_decs = torch.cat([atten_decs , atten_dec[0].unsqueeze(0)], dim=0) # 층헤단단 ㅋ\n",
    "\n",
    "        x = self.LN_out(x) # pre-acrivation 이기 때문에 fc_out 전에 (CNN 에서는 GAP-fc => BN-relu-GAP-fc 로 추가했었음)\n",
    "        x = self.fc_out(x) # activation 없이 바로 fc_out 통과시키더라 (https://github.com/graykode/gpt-2-Pytorch/blob/master/GPT2/model.py#L205 참고)\n",
    "\n",
    "        return x, atten_decs\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, vocab_size, max_len, n_layers, d_model, d_ff, n_heads, drop_p):\n",
    "        super().__init__()\n",
    "\n",
    "        self.decoder = Decoder(vocab_size, max_len, n_layers, d_model, d_ff, n_heads, drop_p)\n",
    "\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        # 초기화 기법은 GPT-2 참고해서 만듦\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.02) # GPT-1 논문에서의 초기화\n",
    "                m.weight.data *= 1/torch.sqrt(torch.tensor(n_layers*2)) # 이건 GPT-2 논문에서 변형한 초기화 (residual 에 1/sqrt(N) 곱하기, N:residual 총 개수)\n",
    "            elif isinstance(m, nn.Embedding):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.02) # 임베딩 레이어는 residual이 아니라서 이것만\n",
    "\n",
    "        nn.init.normal_(self.decoder.fc_out.weight, mean=0, std=0.02) # 얘는 residual이 아니기 때문에 원래 초기화대로\n",
    "\n",
    "    def make_dec_mask(self, x): # x.shape = 개단\n",
    "\n",
    "        pad_mask = (x == pad_idx).unsqueeze(1).unsqueeze(2) # 개11단\n",
    "        pad_mask = pad_mask.expand(x.shape[0], self.n_heads, x.shape[1], x.shape[1]) # 개헤단단\n",
    "        \"\"\" pad mask\n",
    "        F F F T T\n",
    "        F F F T T\n",
    "        F F F T T\n",
    "        F F F T T\n",
    "        F F F T T\n",
    "        \"\"\"\n",
    "        future_mask = torch.tril(torch.ones(x.shape[0], self.n_heads, x.shape[1], x.shape[1]))==0 # 개헤단단\n",
    "        future_mask = future_mask.to(DEVICE) # pad_mask | future_mask 할 때 같은 DEVICE 여야\n",
    "        \"\"\" future mask\n",
    "        F T T T T\n",
    "        F F T T T\n",
    "        F F F T T\n",
    "        F F F F T\n",
    "        F F F F F\n",
    "        \"\"\"\n",
    "        dec_mask = pad_mask | future_mask # dec_mask.shape = 개헤단단\n",
    "        \"\"\" decoder mask\n",
    "        F T T T T\n",
    "        F F T T T\n",
    "        F F F T T\n",
    "        F F F T T\n",
    "        F F F T T\n",
    "        \"\"\"\n",
    "        return dec_mask\n",
    "\n",
    "    def forward(self, x, atten_map_save = False):\n",
    "\n",
    "        dec_mask = self.make_dec_mask(x)\n",
    "        out, atten_decs = self.decoder(x, dec_mask, atten_map_save = atten_map_save)\n",
    "\n",
    "        return out, atten_decs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1781,
     "status": "ok",
     "timestamp": 1713353798114,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "gYItYsWf3yMK",
    "outputId": "2fb619bd-e11a-496d-cbb9-b02fecae50f3"
   },
   "outputs": [],
   "source": [
    "Q = torch.randn(1, 4, 6) # 개단차\n",
    "print(Q)\n",
    "\n",
    "Q = rearrange(Q, '개 단 (헤 차) -> 개 헤 단 차', 헤 = 3) # 개단차 -> 개헤단차\n",
    "# 주의! (차 헤) 로 해보면 또 다름. 차원의 수 6을 헤드의 수 3으로 쪼개는 것이므로 (헤 차) 가 맞다\n",
    "print(Q)\n",
    "print(Q.shape)\n",
    "\n",
    "x = rearrange(Q, '개 헤 단 차 -> 개 단 (헤 차)') # 개헤단차 -> 개단차,\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ha5rYiwSIBz6"
   },
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3155,
     "status": "ok",
     "timestamp": 1713353807426,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "1XyuIUlwKm8B",
    "outputId": "57bd28d9-b2aa-4594-bdd7-2fb2dcbecabc"
   },
   "outputs": [],
   "source": [
    "model = GPT(vocab_size, max_len, n_layers, d_model, d_ff, n_heads, drop_p).to(DEVICE)\n",
    "\n",
    "x = torch.tensor([[2,5,4,4,3,1,1],[2,9,6,7,3,1,1]]).to(DEVICE)\n",
    "print(x.shape)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x = model(x)[0]\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGTrDJKUIO7Q"
   },
   "source": [
    "## Train, Test, loss_epoch 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 395,
     "status": "ok",
     "timestamp": 1713353916525,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "9zx5gmVYkhFv"
   },
   "outputs": [],
   "source": [
    "def Train(model, train_DL, val_DL, criterion, optimizer, scheduler = None):\n",
    "    loss_history = {\"train\": [], \"val\": []}\n",
    "    best_loss = 9999\n",
    "    for ep in range(EPOCH):\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        model.train() # train mode로 전환\n",
    "        train_loss = loss_epoch(model, train_DL, criterion, optimizer = optimizer, scheduler = scheduler)\n",
    "        loss_history[\"train\"] += [train_loss]\n",
    "\n",
    "        model.eval() # test mode로 전환\n",
    "        with torch.no_grad():\n",
    "            val_loss = loss_epoch(model, val_DL, criterion)\n",
    "            loss_history[\"val\"] += [val_loss]\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save({\"model\": model,\n",
    "                            \"ep\": ep,\n",
    "                            \"optimizer\": optimizer,\n",
    "                            \"scheduler\": scheduler,}, save_model_path)\n",
    "        # print loss\n",
    "        print(f\"Epoch {ep+1}: train loss: {train_loss:.5f}   val loss: {val_loss:.5f}   current_LR: {optimizer.param_groups[0]['lr']:.8f}   time: {time.time()-epoch_start:.0f} s\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "    torch.save({\"loss_history\": loss_history,\n",
    "                \"EPOCH\": EPOCH,\n",
    "                \"BATCH_SIZE\": BATCH_SIZE}, save_history_path)\n",
    "\n",
    "def Test(model, test_DL, criterion):\n",
    "    model.eval() # test mode로 전환\n",
    "    with torch.no_grad():\n",
    "        test_loss = loss_epoch(model, test_DL, criterion)\n",
    "    print(f\"Test loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):.3f}\")\n",
    "\n",
    "def loss_epoch(model, DL, criterion, optimizer = None, scheduler = None):\n",
    "    N = len(DL.dataset) # the number of data\n",
    "\n",
    "    rloss=0\n",
    "    for texts in tqdm(DL, leave=False):\n",
    "        texts = [s + ' [SEP]'for s in texts]\n",
    "        x_batch = tokenizer(texts, padding=True, truncation=True, max_length = max_len, return_tensors='pt', add_special_tokens = False).input_ids.to(DEVICE)\n",
    "        # inference\n",
    "        y_hat = model(x_batch[:,:-1])[0] # 모델 통과 시킬 땐 마지막 토큰은 제외!\n",
    "        # y_hat.shape = 개단차 즉, 훈련 땐 문장이 한번에 튀어나옴\n",
    "        # loss\n",
    "        loss = criterion(y_hat.permute(0,2,1), x_batch[:,1:]) # loss 계산 시엔 첫 토큰은 제외!\n",
    "        # update\n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        # loss accumulation\n",
    "        loss_b = loss.item() * x_batch.shape[0]\n",
    "        rloss += loss_b\n",
    "    loss_e = rloss/N\n",
    "    return loss_e\n",
    "\n",
    "def count_params(model):\n",
    "    num = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "    return num\n",
    "\n",
    "def plot_scheduler(optimizer, scheduler, total_steps): # LR curve 보기\n",
    "    lr_history = []\n",
    "    steps = range(1, total_steps)\n",
    "\n",
    "    for _ in steps:\n",
    "        lr_history += [optimizer.param_groups[0]['lr']]\n",
    "        scheduler.step()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(steps, lr_history, 'b', linewidth=2, label=\"Learning Rate\")\n",
    "    plt.ylim([-0.1*max(lr_history), 1.2*max(lr_history)])\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "executionInfo": {
     "elapsed": 614,
     "status": "ok",
     "timestamp": 1713353917548,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "Slx6NMtjYrPv",
    "outputId": "b65fae12-3a77-4873-e19c-b65980e34824"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(nn.Linear(1, 1).parameters(), lr=LR_peak)\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "plot_scheduler(optimizer = optimizer, scheduler = scheduler, total_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_G1AoumLOVA"
   },
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 325,
     "status": "ok",
     "timestamp": 1713353926267,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "Nfg_BYSFmy6w"
   },
   "outputs": [],
   "source": [
    "if new_model_train:\n",
    "    params = [p for p in model.parameters() if p.requires_grad] # 사전 학습된 layer를 사용할 경우를 대비\n",
    "    optimizer = optim.AdamW(params, lr=LR_peak, weight_decay=LAMBDA) # GPT-1 논문에서 AdamW를 사용했음\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "\n",
    "    Train(model, train_DL, val_DL, criterion, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1S70EQLBIUR8"
   },
   "source": [
    "## 로드 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6046,
     "status": "ok",
     "timestamp": 1713353935228,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "OQh9irraw_fd",
    "outputId": "afb83d5b-ca9f-4050-c40f-337e68cc065a"
   },
   "outputs": [],
   "source": [
    "loaded = torch.load(save_model_path, map_location=DEVICE)\n",
    "load_model = loaded[\"model\"]\n",
    "ep = loaded[\"ep\"]\n",
    "optimizer = loaded[\"optimizer\"]\n",
    "\n",
    "loaded = torch.load(save_history_path, map_location=DEVICE)\n",
    "loss_history = loaded[\"loss_history\"]\n",
    "\n",
    "print(ep)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "executionInfo": {
     "elapsed": 776,
     "status": "ok",
     "timestamp": 1713353935998,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "W8eVKmFpxBA9",
    "outputId": "6f8d5b1a-e462-4ac0-b067-32d334b59b8e"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(1,EPOCH+1),loss_history[\"train\"], label=\"train\")\n",
    "plt.plot(range(1,EPOCH+1),loss_history[\"val\"], label=\"val\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Train, Val Loss\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 118699,
     "status": "ok",
     "timestamp": 1713267603565,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "xkMe28pnma4R",
    "outputId": "274f41aa-ef2e-4a44-9983-840fce7accfc"
   },
   "outputs": [],
   "source": [
    "Test(load_model, test_DL, criterion)\n",
    "count_params(load_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqzZvCENIXcj"
   },
   "source": [
    "## 번역 함수, 어텐션 map 그리는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1713354078816,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "kEWhBsifvLUw"
   },
   "outputs": [],
   "source": [
    "def generate(model, src_text, atten_map_save = False):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = tokenizer.encode(src_text, return_tensors='pt', add_special_tokens=False).to(DEVICE) # 1x단\n",
    "        init_length = pred.shape[1]\n",
    "\n",
    "        for _ in range(max_len-init_length):\n",
    "            out, atten_decs = model(pred, atten_map_save = atten_map_save)\n",
    "            # out.shape = (개=1,단,차)\n",
    "\n",
    "            pred_word = out[:,-1,:].argmax(dim=1).unsqueeze(0) # 마지막 단어에 대해 argmax해서 prediction 하고 shape = (1,1)로\n",
    "            pred = torch.cat([pred, pred_word], dim=1) # 1x단 (단은 하나씩 늘면서)\n",
    "\n",
    "            if tokenizer.decode(pred_word.item()) == '[SEP]':\n",
    "                break\n",
    "\n",
    "        pred_text = tokenizer.decode(pred[0])\n",
    "\n",
    "    return pred_text, atten_decs\n",
    "\n",
    "def show_attention(atten, Query, Key, n):\n",
    "    atten = atten.cpu()\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=[atten.shape[3]*1.5,atten.shape[2]])\n",
    "    for i in range(3):\n",
    "        ax[i].set_yticks(range(atten.shape[2]))\n",
    "        ax[i].set_yticklabels(Query, rotation=45)\n",
    "        ax[i].set_xticks(range(atten.shape[3]))\n",
    "        ax[i].set_xticklabels(Key, rotation=60)\n",
    "        ax[i].imshow(atten[n][i], cmap='bone') # n 번째 layer, 앞 세 개의 헤드만 plot\n",
    "        # ax[i].xaxis.tick_top()  # x축 레이블을 위쪽으로 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2105,
     "status": "ok",
     "timestamp": 1713355690065,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "fy3e9yXVKToo",
    "outputId": "a9dba28e-1214-45d5-98f2-8e5245fc6727"
   },
   "outputs": [],
   "source": [
    "# 생성해보기\n",
    "# src_text = \"죄송합니다. 고객님 해당 상품이 재입고\"\n",
    "# src_text = \"번거롭게 해드려서 죄송해요. HDMI랑 RGB 연결선이면 될 것\"\n",
    "# src_text = \"다시 확인해봐도 아예 켜지지 않네요. 출장 수리 가능\"\n",
    "# src_text = \"여기 전에 와 본\"\n",
    "src_text = \"제가 창고 확인해보고 다시\"\n",
    "\n",
    "# src_text = \"죄송합니다. 내일 회식에는\"\n",
    "# src_text = \"기대되네요! 내일 회식에는\"\n",
    "print(f\"입력: {src_text}\")\n",
    "\n",
    "pred_text, atten_decs = generate(load_model, src_text, atten_map_save = True)\n",
    "print(f\"생성된 문장: {pred_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "executionInfo": {
     "elapsed": 2105,
     "status": "ok",
     "timestamp": 1713357316294,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     },
     "user_tz": -540
    },
    "id": "vQaSRui-0YDK",
    "outputId": "6ff7d66a-593d-457f-acf3-71f9c8d71f41"
   },
   "outputs": [],
   "source": [
    "dec_tokens = tokenizer.tokenize(pred_text)\n",
    "dec_input = dec_tokens[:-1] # 디코더 입력으로 들어가는 문장(sos, eos는 없고)\n",
    "dec_output = dec_tokens[1:] # 디코더 출력으로 나간 문장\n",
    "\n",
    "show_attention(atten_decs, dec_output, dec_input, n = 11) # 이 출력이 나가게끔 하기 위해 어떤 토큰을 attention 했나"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuClass": "premium",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d64ca08ba8a4c1b8a8aae3eee98d05a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92365e84af0349609ece11a133454774",
      "placeholder": "​",
      "style": "IPY_MODEL_5357c28e5a344b398a03b92dff05d30e",
      "value": " 371k/371k [00:00&lt;00:00, 3.20MB/s]"
     }
    },
    "10224ff7f8fb4a56a1046f10f12754b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50138f718fcd4a97a92ead014cc993de",
      "placeholder": "​",
      "style": "IPY_MODEL_5294f88fe97e44bc9fa514ca481eb1dd",
      "value": "spiece.model: 100%"
     }
    },
    "1212fd2a03354f31b18706001b0cf445": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "12409705e490475ab24cce661ec3e4ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4b83da33aaff4b0eabb965370d676214",
       "IPY_MODEL_1e9673caa1324401802b246240fb9397",
       "IPY_MODEL_a14f2b61d6224dd59645dc010bb18bbe"
      ],
      "layout": "IPY_MODEL_5bc8c11f8dab470e9429320a54b64dac"
     }
    },
    "13f13c99ea704629951f2902c200b3b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1e4a35e92af94b9392c8eeecda70eb2d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e9673caa1324401802b246240fb9397": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9af99b269cf843b6bb04884cd44f4251",
      "max": 432,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c7de655990c64e1495fc9ad849a83699",
      "value": 432
     }
    },
    "3e200bf03f6f4b7782ecd59ed0a82f5a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b83da33aaff4b0eabb965370d676214": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad54caeecb9d4857ac0102a50dbe0fa1",
      "placeholder": "​",
      "style": "IPY_MODEL_80240161b8f7421db6a9c52cd1f27f96",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "50138f718fcd4a97a92ead014cc993de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5294f88fe97e44bc9fa514ca481eb1dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5357c28e5a344b398a03b92dff05d30e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "544f7b4bad9d4f5f8d489069120cc94d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bc8c11f8dab470e9429320a54b64dac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62441f096afa4b0fb5465b42e522948e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef2e106fa5a3499ba932cb6617529adc",
      "placeholder": "​",
      "style": "IPY_MODEL_1212fd2a03354f31b18706001b0cf445",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "72d6e28f94434fb99326b232182e0fa8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_62441f096afa4b0fb5465b42e522948e",
       "IPY_MODEL_d11ed627731349f6b5308c489bdfa24d",
       "IPY_MODEL_cf6f97d1d1cb4b848a7ba14d03f0bc43"
      ],
      "layout": "IPY_MODEL_85ff2397941b48a8a01bb32f7725db29"
     }
    },
    "80240161b8f7421db6a9c52cd1f27f96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "806f67dff29d402da2ef49721cd389be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "838d260527e14b77aa48c12eb3b8ec41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "85ff2397941b48a8a01bb32f7725db29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92365e84af0349609ece11a133454774": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9af99b269cf843b6bb04884cd44f4251": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a14f2b61d6224dd59645dc010bb18bbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_544f7b4bad9d4f5f8d489069120cc94d",
      "placeholder": "​",
      "style": "IPY_MODEL_ac0085b3780f4dd897689fa396a2036d",
      "value": " 432/432 [00:00&lt;00:00, 4.90kB/s]"
     }
    },
    "a19268ef46924f9abe496fe658bbc370": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_10224ff7f8fb4a56a1046f10f12754b2",
       "IPY_MODEL_fb21d1709b2048188c9b82f8cdb207ee",
       "IPY_MODEL_0d64ca08ba8a4c1b8a8aae3eee98d05a"
      ],
      "layout": "IPY_MODEL_3e200bf03f6f4b7782ecd59ed0a82f5a"
     }
    },
    "a4494c5ad498407ab42728d8f5d7f1ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ac0085b3780f4dd897689fa396a2036d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ad54caeecb9d4857ac0102a50dbe0fa1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0bec189a74f4326ad6a70e500b31c45": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7de655990c64e1495fc9ad849a83699": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cf6f97d1d1cb4b848a7ba14d03f0bc43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_806f67dff29d402da2ef49721cd389be",
      "placeholder": "​",
      "style": "IPY_MODEL_838d260527e14b77aa48c12eb3b8ec41",
      "value": " 244/244 [00:00&lt;00:00, 5.10kB/s]"
     }
    },
    "d11ed627731349f6b5308c489bdfa24d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e4a35e92af94b9392c8eeecda70eb2d",
      "max": 244,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a4494c5ad498407ab42728d8f5d7f1ca",
      "value": 244
     }
    },
    "ef2e106fa5a3499ba932cb6617529adc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb21d1709b2048188c9b82f8cdb207ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0bec189a74f4326ad6a70e500b31c45",
      "max": 371427,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_13f13c99ea704629951f2902c200b3b1",
      "value": 371427
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
