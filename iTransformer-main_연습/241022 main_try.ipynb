{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0305945f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T02:24:34.116125Z",
     "start_time": "2024-10-28T02:24:29.477008Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from experiments.exp_long_term_forecasting import Exp_Long_Term_Forecast\n",
    "from experiments.exp_long_term_forecasting_partial import Exp_Long_Term_Forecast_Partial\n",
    "import random\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "461bd1b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T02:39:54.091817Z",
     "start_time": "2024-10-28T02:25:10.669784Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ECL_180_60_iTransformer_custom_M_ft180_sl48_ll60_pl512_dm8_nh3_el1_dl512_df1_fcfixed_ebTrue_dtExp_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 18173\n",
      "val 2573\n",
      "test 5201\n",
      "\titers: 100, epoch: 1 | loss: 0.1740425\n",
      "\tspeed: 0.2203s/iter; left time: 2478.0645s\n",
      "\titers: 200, epoch: 1 | loss: 0.1462003\n",
      "\tspeed: 0.0137s/iter; left time: 153.2629s\n",
      "\titers: 300, epoch: 1 | loss: 0.1377575\n",
      "\tspeed: 0.0137s/iter; left time: 151.3473s\n",
      "\titers: 400, epoch: 1 | loss: 0.1367540\n",
      "\tspeed: 0.0137s/iter; left time: 150.4353s\n",
      "\titers: 500, epoch: 1 | loss: 0.1343808\n",
      "\tspeed: 0.0137s/iter; left time: 148.6260s\n",
      "\titers: 600, epoch: 1 | loss: 0.1411413\n",
      "\tspeed: 0.0138s/iter; left time: 148.1641s\n",
      "\titers: 700, epoch: 1 | loss: 0.1784377\n",
      "\tspeed: 0.0138s/iter; left time: 146.6543s\n",
      "\titers: 800, epoch: 1 | loss: 0.1308763\n",
      "\tspeed: 0.0137s/iter; left time: 144.5054s\n",
      "\titers: 900, epoch: 1 | loss: 0.1287638\n",
      "\tspeed: 0.0137s/iter; left time: 143.5889s\n",
      "\titers: 1000, epoch: 1 | loss: 0.1280279\n",
      "\tspeed: 0.0137s/iter; left time: 141.6196s\n",
      "\titers: 1100, epoch: 1 | loss: 0.1244650\n",
      "\tspeed: 0.0137s/iter; left time: 140.6094s\n",
      "Epoch: 1 cost time: 36.71074914932251\n",
      "Epoch: 1, Steps: 1135 | Train Loss: 0.1529841 Vali Loss: 0.1144284 Test Loss: 0.1305454\n",
      "Validation loss decreased (inf --> 0.114428).  Saving model ...\n",
      "Updating learning rate to 0.0005\n",
      "\titers: 100, epoch: 2 | loss: 0.1289751\n",
      "\tspeed: 0.7713s/iter; left time: 7802.5117s\n",
      "\titers: 200, epoch: 2 | loss: 0.1268935\n",
      "\tspeed: 0.0137s/iter; left time: 137.5706s\n",
      "\titers: 300, epoch: 2 | loss: 0.1281641\n",
      "\tspeed: 0.0137s/iter; left time: 135.7750s\n",
      "\titers: 400, epoch: 2 | loss: 0.1272539\n",
      "\tspeed: 0.0137s/iter; left time: 134.3441s\n",
      "\titers: 500, epoch: 2 | loss: 0.1324197\n",
      "\tspeed: 0.0137s/iter; left time: 133.0724s\n",
      "\titers: 600, epoch: 2 | loss: 0.1381255\n",
      "\tspeed: 0.0137s/iter; left time: 131.3007s\n",
      "\titers: 700, epoch: 2 | loss: 0.1317361\n",
      "\tspeed: 0.0137s/iter; left time: 130.4899s\n",
      "\titers: 800, epoch: 2 | loss: 0.1125169\n",
      "\tspeed: 0.0137s/iter; left time: 128.7858s\n",
      "\titers: 900, epoch: 2 | loss: 0.1101136\n",
      "\tspeed: 0.0137s/iter; left time: 127.7177s\n",
      "\titers: 1000, epoch: 2 | loss: 0.1116028\n",
      "\tspeed: 0.0137s/iter; left time: 126.4119s\n",
      "\titers: 1100, epoch: 2 | loss: 0.1174571\n",
      "\tspeed: 0.0137s/iter; left time: 124.5630s\n",
      "Epoch: 2 cost time: 35.62763714790344\n",
      "Epoch: 2, Steps: 1135 | Train Loss: 0.1281250 Vali Loss: 0.1094853 Test Loss: 0.1244103\n",
      "Validation loss decreased (0.114428 --> 0.109485).  Saving model ...\n",
      "Updating learning rate to 0.00025\n",
      "\titers: 100, epoch: 3 | loss: 0.1161958\n",
      "\tspeed: 0.7666s/iter; left time: 6884.7531s\n",
      "\titers: 200, epoch: 3 | loss: 0.1244208\n",
      "\tspeed: 0.0135s/iter; left time: 120.2730s\n",
      "\titers: 300, epoch: 3 | loss: 0.1101910\n",
      "\tspeed: 0.0136s/iter; left time: 119.4786s\n",
      "\titers: 400, epoch: 3 | loss: 0.1152190\n",
      "\tspeed: 0.0136s/iter; left time: 118.1497s\n",
      "\titers: 500, epoch: 3 | loss: 0.1198185\n",
      "\tspeed: 0.0136s/iter; left time: 116.4554s\n",
      "\titers: 600, epoch: 3 | loss: 0.1179530\n",
      "\tspeed: 0.0136s/iter; left time: 115.3674s\n",
      "\titers: 700, epoch: 3 | loss: 0.1166430\n",
      "\tspeed: 0.0136s/iter; left time: 113.9193s\n",
      "\titers: 800, epoch: 3 | loss: 0.1079529\n",
      "\tspeed: 0.0136s/iter; left time: 112.7478s\n",
      "\titers: 900, epoch: 3 | loss: 0.1265089\n",
      "\tspeed: 0.0136s/iter; left time: 111.5778s\n",
      "\titers: 1000, epoch: 3 | loss: 0.1319079\n",
      "\tspeed: 0.0137s/iter; left time: 110.3742s\n",
      "\titers: 1100, epoch: 3 | loss: 0.1231193\n",
      "\tspeed: 0.0137s/iter; left time: 109.4838s\n",
      "Epoch: 3 cost time: 35.730376958847046\n",
      "Epoch: 3, Steps: 1135 | Train Loss: 0.1191719 Vali Loss: 0.1077327 Test Loss: 0.1230115\n",
      "Validation loss decreased (0.109485 --> 0.107733).  Saving model ...\n",
      "Updating learning rate to 0.000125\n",
      "\titers: 100, epoch: 4 | loss: 0.1135460\n",
      "\tspeed: 0.7676s/iter; left time: 6022.6261s\n",
      "\titers: 200, epoch: 4 | loss: 0.1499020\n",
      "\tspeed: 0.0137s/iter; left time: 106.0167s\n",
      "\titers: 300, epoch: 4 | loss: 0.1119451\n",
      "\tspeed: 0.0137s/iter; left time: 104.9589s\n",
      "\titers: 400, epoch: 4 | loss: 0.0989500\n",
      "\tspeed: 0.0136s/iter; left time: 102.9463s\n",
      "\titers: 500, epoch: 4 | loss: 0.1121868\n",
      "\tspeed: 0.0138s/iter; left time: 102.9062s\n",
      "\titers: 600, epoch: 4 | loss: 0.1346563\n",
      "\tspeed: 0.0137s/iter; left time: 100.6742s\n",
      "\titers: 700, epoch: 4 | loss: 0.1031994\n",
      "\tspeed: 0.0137s/iter; left time: 98.9530s\n",
      "\titers: 800, epoch: 4 | loss: 0.1360502\n",
      "\tspeed: 0.0137s/iter; left time: 97.7072s\n",
      "\titers: 900, epoch: 4 | loss: 0.1056969\n",
      "\tspeed: 0.0137s/iter; left time: 96.3178s\n",
      "\titers: 1000, epoch: 4 | loss: 0.1067551\n",
      "\tspeed: 0.0136s/iter; left time: 94.7210s\n",
      "\titers: 1100, epoch: 4 | loss: 0.1113443\n",
      "\tspeed: 0.0137s/iter; left time: 93.8805s\n",
      "Epoch: 4 cost time: 35.64216470718384\n",
      "Epoch: 4, Steps: 1135 | Train Loss: 0.1135271 Vali Loss: 0.1056024 Test Loss: 0.1198433\n",
      "Validation loss decreased (0.107733 --> 0.105602).  Saving model ...\n",
      "Updating learning rate to 6.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1036162\n",
      "\tspeed: 0.7668s/iter; left time: 5145.8997s\n",
      "\titers: 200, epoch: 5 | loss: 0.1029502\n",
      "\tspeed: 0.0136s/iter; left time: 90.1458s\n",
      "\titers: 300, epoch: 5 | loss: 0.0922599\n",
      "\tspeed: 0.0136s/iter; left time: 88.7307s\n",
      "\titers: 400, epoch: 5 | loss: 0.1100183\n",
      "\tspeed: 0.0136s/iter; left time: 87.2638s\n",
      "\titers: 500, epoch: 5 | loss: 0.1079069\n",
      "\tspeed: 0.0136s/iter; left time: 86.1325s\n",
      "\titers: 600, epoch: 5 | loss: 0.0998517\n",
      "\tspeed: 0.0137s/iter; left time: 85.3351s\n",
      "\titers: 700, epoch: 5 | loss: 0.1066360\n",
      "\tspeed: 0.0136s/iter; left time: 83.3401s\n",
      "\titers: 800, epoch: 5 | loss: 0.1018317\n",
      "\tspeed: 0.0137s/iter; left time: 82.2934s\n",
      "\titers: 900, epoch: 5 | loss: 0.1080637\n",
      "\tspeed: 0.0137s/iter; left time: 80.9892s\n",
      "\titers: 1000, epoch: 5 | loss: 0.1127440\n",
      "\tspeed: 0.0137s/iter; left time: 79.7365s\n",
      "\titers: 1100, epoch: 5 | loss: 0.1016622\n",
      "\tspeed: 0.0137s/iter; left time: 78.2023s\n",
      "Epoch: 5 cost time: 35.553518295288086\n",
      "Epoch: 5, Steps: 1135 | Train Loss: 0.1097007 Vali Loss: 0.1046972 Test Loss: 0.1196634\n",
      "Validation loss decreased (0.105602 --> 0.104697).  Saving model ...\n",
      "Updating learning rate to 3.125e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1009994\n",
      "\tspeed: 0.7670s/iter; left time: 4276.8840s\n",
      "\titers: 200, epoch: 6 | loss: 0.1018420\n",
      "\tspeed: 0.0136s/iter; left time: 74.3222s\n",
      "\titers: 300, epoch: 6 | loss: 0.1064452\n",
      "\tspeed: 0.0136s/iter; left time: 72.9852s\n",
      "\titers: 400, epoch: 6 | loss: 0.1054790\n",
      "\tspeed: 0.0136s/iter; left time: 71.6208s\n",
      "\titers: 500, epoch: 6 | loss: 0.1069936\n",
      "\tspeed: 0.0136s/iter; left time: 70.2934s\n",
      "\titers: 600, epoch: 6 | loss: 0.1002279\n",
      "\tspeed: 0.0137s/iter; left time: 69.4460s\n",
      "\titers: 700, epoch: 6 | loss: 0.1154250\n",
      "\tspeed: 0.0136s/iter; left time: 67.6152s\n",
      "\titers: 800, epoch: 6 | loss: 0.1146266\n",
      "\tspeed: 0.0136s/iter; left time: 66.4259s\n",
      "\titers: 900, epoch: 6 | loss: 0.1101428\n",
      "\tspeed: 0.0136s/iter; left time: 65.1435s\n",
      "\titers: 1000, epoch: 6 | loss: 0.1139070\n",
      "\tspeed: 0.0136s/iter; left time: 63.4335s\n",
      "\titers: 1100, epoch: 6 | loss: 0.1039439\n",
      "\tspeed: 0.0136s/iter; left time: 62.2085s\n",
      "Epoch: 6 cost time: 35.53641057014465\n",
      "Epoch: 6, Steps: 1135 | Train Loss: 0.1073739 Vali Loss: 0.1045379 Test Loss: 0.1188421\n",
      "Validation loss decreased (0.104697 --> 0.104538).  Saving model ...\n",
      "Updating learning rate to 1.5625e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1005083\n",
      "\tspeed: 0.7657s/iter; left time: 3400.4844s\n",
      "\titers: 200, epoch: 7 | loss: 0.0997235\n",
      "\tspeed: 0.0136s/iter; left time: 59.1795s\n",
      "\titers: 300, epoch: 7 | loss: 0.1041176\n",
      "\tspeed: 0.0136s/iter; left time: 57.8590s\n",
      "\titers: 400, epoch: 7 | loss: 0.1116998\n",
      "\tspeed: 0.0137s/iter; left time: 56.5254s\n",
      "\titers: 500, epoch: 7 | loss: 0.1033146\n",
      "\tspeed: 0.0136s/iter; left time: 55.1532s\n",
      "\titers: 600, epoch: 7 | loss: 0.1059355\n",
      "\tspeed: 0.0137s/iter; left time: 53.9504s\n",
      "\titers: 700, epoch: 7 | loss: 0.1018922\n",
      "\tspeed: 0.0137s/iter; left time: 52.4846s\n",
      "\titers: 800, epoch: 7 | loss: 0.1132359\n",
      "\tspeed: 0.0137s/iter; left time: 51.0706s\n",
      "\titers: 900, epoch: 7 | loss: 0.1127276\n",
      "\tspeed: 0.0137s/iter; left time: 49.7576s\n",
      "\titers: 1000, epoch: 7 | loss: 0.1096142\n",
      "\tspeed: 0.0137s/iter; left time: 48.5318s\n",
      "\titers: 1100, epoch: 7 | loss: 0.1060563\n",
      "\tspeed: 0.0137s/iter; left time: 47.2565s\n",
      "Epoch: 7 cost time: 35.694268226623535\n",
      "Epoch: 7, Steps: 1135 | Train Loss: 0.1061844 Vali Loss: 0.1050866 Test Loss: 0.1193288\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1100609\n",
      "\tspeed: 0.7651s/iter; left time: 2529.4175s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\titers: 200, epoch: 8 | loss: 0.0906345\n",
      "\tspeed: 0.0135s/iter; left time: 43.4236s\n",
      "\titers: 300, epoch: 8 | loss: 0.1047162\n",
      "\tspeed: 0.0136s/iter; left time: 42.1252s\n",
      "\titers: 400, epoch: 8 | loss: 0.1113221\n",
      "\tspeed: 0.0137s/iter; left time: 41.1424s\n",
      "\titers: 500, epoch: 8 | loss: 0.1017798\n",
      "\tspeed: 0.0137s/iter; left time: 39.8275s\n",
      "\titers: 600, epoch: 8 | loss: 0.1091222\n",
      "\tspeed: 0.0136s/iter; left time: 38.2273s\n",
      "\titers: 700, epoch: 8 | loss: 0.1075649\n",
      "\tspeed: 0.0136s/iter; left time: 36.7366s\n",
      "\titers: 800, epoch: 8 | loss: 0.0977144\n",
      "\tspeed: 0.0136s/iter; left time: 35.4616s\n",
      "\titers: 900, epoch: 8 | loss: 0.1004089\n",
      "\tspeed: 0.0136s/iter; left time: 34.0795s\n",
      "\titers: 1000, epoch: 8 | loss: 0.1111329\n",
      "\tspeed: 0.0136s/iter; left time: 32.7865s\n",
      "\titers: 1100, epoch: 8 | loss: 0.1065480\n",
      "\tspeed: 0.0136s/iter; left time: 31.4069s\n",
      "Epoch: 8 cost time: 35.41035771369934\n",
      "Epoch: 8, Steps: 1135 | Train Loss: 0.1055523 Vali Loss: 0.1048533 Test Loss: 0.1192991\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0988090\n",
      "\tspeed: 0.7657s/iter; left time: 1662.3614s\n",
      "\titers: 200, epoch: 9 | loss: 0.0937833\n",
      "\tspeed: 0.0136s/iter; left time: 28.2629s\n",
      "\titers: 300, epoch: 9 | loss: 0.0910094\n",
      "\tspeed: 0.0136s/iter; left time: 26.8913s\n",
      "\titers: 400, epoch: 9 | loss: 0.1111749\n",
      "\tspeed: 0.0137s/iter; left time: 25.6993s\n",
      "\titers: 500, epoch: 9 | loss: 0.1137909\n",
      "\tspeed: 0.0137s/iter; left time: 24.1753s\n",
      "\titers: 600, epoch: 9 | loss: 0.1016008\n",
      "\tspeed: 0.0137s/iter; left time: 22.8742s\n",
      "\titers: 700, epoch: 9 | loss: 0.1029906\n",
      "\tspeed: 0.0136s/iter; left time: 21.4369s\n",
      "\titers: 800, epoch: 9 | loss: 0.0975701\n",
      "\tspeed: 0.0137s/iter; left time: 20.1018s\n",
      "\titers: 900, epoch: 9 | loss: 0.1136224\n",
      "\tspeed: 0.0137s/iter; left time: 18.7573s\n",
      "\titers: 1000, epoch: 9 | loss: 0.1015747\n",
      "\tspeed: 0.0137s/iter; left time: 17.4134s\n",
      "\titers: 1100, epoch: 9 | loss: 0.0925337\n",
      "\tspeed: 0.0137s/iter; left time: 15.9923s\n",
      "Epoch: 9 cost time: 35.438589096069336\n",
      "Epoch: 9, Steps: 1135 | Train Loss: 0.1052331 Vali Loss: 0.1049187 Test Loss: 0.1194386\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ECL_180_60_iTransformer_custom_M_ft180_sl48_ll60_pl512_dm8_nh3_el1_dl512_df1_fcfixed_ebTrue_dtExp_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 5201\n",
      "test shape: (5201, 1, 60, 321) (5201, 1, 60, 321)\n",
      "test shape: (5201, 60, 321) (5201, 60, 321)\n",
      "mse:0.11884211748838425, mae:0.21434013545513153\n"
     ]
    }
   ],
   "source": [
    "# 시드 설정\n",
    "fix_seed = 2023\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "\n",
    "# args 설정\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.is_training = 1\n",
    "        self.root_path = './dataset/electricity/'\n",
    "        self.data_path = 'electricity.csv'\n",
    "        self.model_id = 'ECL_180_60'\n",
    "        self.model = 'iTransformer'  # $model_name 대신 실제 모델명 입력\n",
    "        self.data = 'custom'\n",
    "        self.features = 'M'\n",
    "        self.seq_len = 180\n",
    "        self.pred_len = 60\n",
    "        self.e_layers = 3\n",
    "        self.enc_in = 321\n",
    "        self.dec_in = 321\n",
    "        self.c_out = 321\n",
    "        self.des = 'Exp'\n",
    "        self.d_model = 512\n",
    "        self.d_ff = 512\n",
    "        self.batch_size = 16\n",
    "        self.learning_rate = 0.0005\n",
    "        self.itr = 1\n",
    "        \n",
    "        # 기본값 설정\n",
    "        self.label_len = 48\n",
    "        self.target = 'OT'\n",
    "        self.freq = 'h'\n",
    "        self.checkpoints = './checkpoints/'\n",
    "        self.n_heads = 8\n",
    "        self.d_layers = 1\n",
    "        self.moving_avg = 25\n",
    "        self.factor = 1\n",
    "        self.distil = True\n",
    "        self.dropout = 0.1\n",
    "        self.embed = 'fixed'\n",
    "        self.activation = 'gelu'\n",
    "        self.output_attention = False\n",
    "        self.do_predict = False\n",
    "        self.num_workers = 10\n",
    "        self.train_epochs = 10\n",
    "        self.patience = 3\n",
    "        self.loss = 'MSE'\n",
    "        self.lradj = 'type1'\n",
    "        self.use_amp = False\n",
    "        self.use_gpu = True if torch.cuda.is_available() else False\n",
    "        self.gpu = 0\n",
    "        self.use_multi_gpu = False\n",
    "        self.devices = '0,1,2,3'\n",
    "        self.exp_name = 'MTSF'\n",
    "        self.channel_independence = False\n",
    "        self.inverse = False\n",
    "        self.class_strategy = 'projection'\n",
    "#         self.target_root_path = './data/electricity/'\n",
    "#         self.target_data_path = 'electricity.csv'\n",
    "        self.efficient_training = False\n",
    "        self.use_norm = True\n",
    "        self.partial_start_index = 0\n",
    "\n",
    "args = Args()\n",
    "\n",
    "if args.exp_name == 'partial_train':\n",
    "    Exp = Exp_Long_Term_Forecast_Partial\n",
    "else:\n",
    "    Exp = Exp_Long_Term_Forecast\n",
    "\n",
    "if args.is_training:\n",
    "    for ii in range(args.itr):\n",
    "        # setting record of experiments\n",
    "        setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "            args.model_id,\n",
    "            args.model,\n",
    "            args.data,\n",
    "            args.features,\n",
    "            args.seq_len,\n",
    "            args.label_len,\n",
    "            args.pred_len,\n",
    "            args.d_model,\n",
    "            args.n_heads,\n",
    "            args.e_layers,\n",
    "            args.d_layers,\n",
    "            args.d_ff,\n",
    "            args.factor,\n",
    "            args.embed,\n",
    "            args.distil,\n",
    "            args.des,\n",
    "            args.class_strategy, ii)\n",
    "\n",
    "        exp = Exp(args)  # set experiments\n",
    "        print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "        exp.train(setting)\n",
    "\n",
    "        print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "        exp.test(setting)\n",
    "\n",
    "        if args.do_predict:\n",
    "            print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "            exp.predict(setting, True)\n",
    "\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43455c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b82b92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
