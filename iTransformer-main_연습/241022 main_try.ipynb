{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0305945f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T07:45:35.197714Z",
     "start_time": "2024-10-22T07:45:35.180716Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from experiments.exp_long_term_forecasting import Exp_Long_Term_Forecast\n",
    "from experiments.exp_long_term_forecasting_partial import Exp_Long_Term_Forecast_Partial\n",
    "import random\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "461bd1b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T08:00:37.013934Z",
     "start_time": "2024-10-22T07:45:35.405876Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ECL_180_60_iTransformer_custom_M_ft180_sl48_ll60_pl512_dm8_nh3_el1_dl512_df1_fctimeF_ebTrue_dtExp_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 18173\n",
      "val 2573\n",
      "test 5201\n",
      "\titers: 100, epoch: 1 | loss: 0.1659804\n",
      "\tspeed: 0.2529s/iter; left time: 2845.2301s\n",
      "\titers: 200, epoch: 1 | loss: 0.1421303\n",
      "\tspeed: 0.0137s/iter; left time: 153.2712s\n",
      "\titers: 300, epoch: 1 | loss: 0.1348758\n",
      "\tspeed: 0.0138s/iter; left time: 152.4087s\n",
      "\titers: 400, epoch: 1 | loss: 0.1347505\n",
      "\tspeed: 0.0137s/iter; left time: 150.4365s\n",
      "\titers: 500, epoch: 1 | loss: 0.1333068\n",
      "\tspeed: 0.0137s/iter; left time: 148.2923s\n",
      "\titers: 600, epoch: 1 | loss: 0.1398303\n",
      "\tspeed: 0.0138s/iter; left time: 148.4649s\n",
      "\titers: 700, epoch: 1 | loss: 0.1748246\n",
      "\tspeed: 0.0139s/iter; left time: 148.1808s\n",
      "\titers: 800, epoch: 1 | loss: 0.1294991\n",
      "\tspeed: 0.0139s/iter; left time: 146.7042s\n",
      "\titers: 900, epoch: 1 | loss: 0.1261814\n",
      "\tspeed: 0.0141s/iter; left time: 147.3385s\n",
      "\titers: 1000, epoch: 1 | loss: 0.1256398\n",
      "\tspeed: 0.0139s/iter; left time: 143.8960s\n",
      "\titers: 1100, epoch: 1 | loss: 0.1211875\n",
      "\tspeed: 0.0138s/iter; left time: 141.3800s\n",
      "Epoch: 1 cost time: 40.08133625984192\n",
      "Epoch: 1, Steps: 1135 | Train Loss: 0.1482239 Vali Loss: 0.1136740 Test Loss: 0.1298600\n",
      "Validation loss decreased (inf --> 0.113674).  Saving model ...\n",
      "Updating learning rate to 0.0005\n",
      "\titers: 100, epoch: 2 | loss: 0.1288116\n",
      "\tspeed: 0.8103s/iter; left time: 8196.5604s\n",
      "\titers: 200, epoch: 2 | loss: 0.1246232\n",
      "\tspeed: 0.0138s/iter; left time: 138.3907s\n",
      "\titers: 300, epoch: 2 | loss: 0.1266896\n",
      "\tspeed: 0.0137s/iter; left time: 136.1461s\n",
      "\titers: 400, epoch: 2 | loss: 0.1275295\n",
      "\tspeed: 0.0137s/iter; left time: 134.9605s\n",
      "\titers: 500, epoch: 2 | loss: 0.1328731\n",
      "\tspeed: 0.0138s/iter; left time: 133.6899s\n",
      "\titers: 600, epoch: 2 | loss: 0.1381713\n",
      "\tspeed: 0.0138s/iter; left time: 132.9517s\n",
      "\titers: 700, epoch: 2 | loss: 0.1316434\n",
      "\tspeed: 0.0138s/iter; left time: 131.2966s\n",
      "\titers: 800, epoch: 2 | loss: 0.1128386\n",
      "\tspeed: 0.0139s/iter; left time: 130.7092s\n",
      "\titers: 900, epoch: 2 | loss: 0.1094717\n",
      "\tspeed: 0.0138s/iter; left time: 128.6819s\n",
      "\titers: 1000, epoch: 2 | loss: 0.1103340\n",
      "\tspeed: 0.0138s/iter; left time: 127.5143s\n",
      "\titers: 1100, epoch: 2 | loss: 0.1132108\n",
      "\tspeed: 0.0138s/iter; left time: 125.7844s\n",
      "Epoch: 2 cost time: 36.937517404556274\n",
      "Epoch: 2, Steps: 1135 | Train Loss: 0.1274189 Vali Loss: 0.1093035 Test Loss: 0.1246210\n",
      "Validation loss decreased (0.113674 --> 0.109303).  Saving model ...\n",
      "Updating learning rate to 0.00025\n",
      "\titers: 100, epoch: 3 | loss: 0.1156262\n",
      "\tspeed: 0.7910s/iter; left time: 7103.8315s\n",
      "\titers: 200, epoch: 3 | loss: 0.1247408\n",
      "\tspeed: 0.0137s/iter; left time: 121.3723s\n",
      "\titers: 300, epoch: 3 | loss: 0.1096093\n",
      "\tspeed: 0.0136s/iter; left time: 119.6176s\n",
      "\titers: 400, epoch: 3 | loss: 0.1137992\n",
      "\tspeed: 0.0136s/iter; left time: 118.0668s\n",
      "\titers: 500, epoch: 3 | loss: 0.1192341\n",
      "\tspeed: 0.0136s/iter; left time: 116.6345s\n",
      "\titers: 600, epoch: 3 | loss: 0.1169877\n",
      "\tspeed: 0.0136s/iter; left time: 115.1991s\n",
      "\titers: 700, epoch: 3 | loss: 0.1166347\n",
      "\tspeed: 0.0138s/iter; left time: 115.7956s\n",
      "\titers: 800, epoch: 3 | loss: 0.1067545\n",
      "\tspeed: 0.0136s/iter; left time: 112.4229s\n",
      "\titers: 900, epoch: 3 | loss: 0.1238029\n",
      "\tspeed: 0.0137s/iter; left time: 111.6867s\n",
      "\titers: 1000, epoch: 3 | loss: 0.1286157\n",
      "\tspeed: 0.0136s/iter; left time: 110.2714s\n",
      "\titers: 1100, epoch: 3 | loss: 0.1222365\n",
      "\tspeed: 0.0136s/iter; left time: 108.4059s\n",
      "Epoch: 3 cost time: 36.16212201118469\n",
      "Epoch: 3, Steps: 1135 | Train Loss: 0.1181115 Vali Loss: 0.1069924 Test Loss: 0.1225169\n",
      "Validation loss decreased (0.109303 --> 0.106992).  Saving model ...\n",
      "Updating learning rate to 0.000125\n",
      "\titers: 100, epoch: 4 | loss: 0.1123720\n",
      "\tspeed: 0.7833s/iter; left time: 6145.6322s\n",
      "\titers: 200, epoch: 4 | loss: 0.1476945\n",
      "\tspeed: 0.0137s/iter; left time: 105.8724s\n",
      "\titers: 300, epoch: 4 | loss: 0.1115623\n",
      "\tspeed: 0.0136s/iter; left time: 104.1555s\n",
      "\titers: 400, epoch: 4 | loss: 0.0988995\n",
      "\tspeed: 0.0137s/iter; left time: 103.1506s\n",
      "\titers: 500, epoch: 4 | loss: 0.1112536\n",
      "\tspeed: 0.0137s/iter; left time: 102.0965s\n",
      "\titers: 600, epoch: 4 | loss: 0.1326990\n",
      "\tspeed: 0.0137s/iter; left time: 100.9591s\n",
      "\titers: 700, epoch: 4 | loss: 0.1003044\n",
      "\tspeed: 0.0138s/iter; left time: 99.6523s\n",
      "\titers: 800, epoch: 4 | loss: 0.1439162\n",
      "\tspeed: 0.0138s/iter; left time: 98.6850s\n",
      "\titers: 900, epoch: 4 | loss: 0.1059832\n",
      "\tspeed: 0.0138s/iter; left time: 97.2433s\n",
      "\titers: 1000, epoch: 4 | loss: 0.1037180\n",
      "\tspeed: 0.0138s/iter; left time: 95.5266s\n",
      "\titers: 1100, epoch: 4 | loss: 0.1104675\n",
      "\tspeed: 0.0138s/iter; left time: 94.6151s\n",
      "Epoch: 4 cost time: 36.00330471992493\n",
      "Epoch: 4, Steps: 1135 | Train Loss: 0.1124165 Vali Loss: 0.1052675 Test Loss: 0.1198968\n",
      "Validation loss decreased (0.106992 --> 0.105268).  Saving model ...\n",
      "Updating learning rate to 6.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1003143\n",
      "\tspeed: 0.7783s/iter; left time: 5222.8543s\n",
      "\titers: 200, epoch: 5 | loss: 0.1021130\n",
      "\tspeed: 0.0137s/iter; left time: 90.3648s\n",
      "\titers: 300, epoch: 5 | loss: 0.0923651\n",
      "\tspeed: 0.0138s/iter; left time: 89.6415s\n",
      "\titers: 400, epoch: 5 | loss: 0.1082518\n",
      "\tspeed: 0.0137s/iter; left time: 87.8402s\n",
      "\titers: 500, epoch: 5 | loss: 0.1069706\n",
      "\tspeed: 0.0137s/iter; left time: 86.4780s\n",
      "\titers: 600, epoch: 5 | loss: 0.0973210\n",
      "\tspeed: 0.0137s/iter; left time: 84.8745s\n",
      "\titers: 700, epoch: 5 | loss: 0.1051260\n",
      "\tspeed: 0.0136s/iter; left time: 83.2040s\n",
      "\titers: 800, epoch: 5 | loss: 0.1006407\n",
      "\tspeed: 0.0136s/iter; left time: 81.8915s\n",
      "\titers: 900, epoch: 5 | loss: 0.1070064\n",
      "\tspeed: 0.0136s/iter; left time: 80.6281s\n",
      "\titers: 1000, epoch: 5 | loss: 0.1144982\n",
      "\tspeed: 0.0136s/iter; left time: 78.9863s\n",
      "\titers: 1100, epoch: 5 | loss: 0.1016403\n",
      "\tspeed: 0.0136s/iter; left time: 77.8723s\n",
      "Epoch: 5 cost time: 35.913707971572876\n",
      "Epoch: 5, Steps: 1135 | Train Loss: 0.1082254 Vali Loss: 0.1042851 Test Loss: 0.1195207\n",
      "Validation loss decreased (0.105268 --> 0.104285).  Saving model ...\n",
      "Updating learning rate to 3.125e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1002562\n",
      "\tspeed: 0.7750s/iter; left time: 4321.2596s\n",
      "\titers: 200, epoch: 6 | loss: 0.1014147\n",
      "\tspeed: 0.0137s/iter; left time: 74.9213s\n",
      "\titers: 300, epoch: 6 | loss: 0.1051122\n",
      "\tspeed: 0.0136s/iter; left time: 73.3665s\n",
      "\titers: 400, epoch: 6 | loss: 0.1036118\n",
      "\tspeed: 0.0138s/iter; left time: 72.7454s\n",
      "\titers: 500, epoch: 6 | loss: 0.1042637\n",
      "\tspeed: 0.0138s/iter; left time: 71.5561s\n",
      "\titers: 600, epoch: 6 | loss: 0.0987283\n",
      "\tspeed: 0.0137s/iter; left time: 69.7857s\n",
      "\titers: 700, epoch: 6 | loss: 0.1145196\n",
      "\tspeed: 0.0138s/iter; left time: 68.8853s\n",
      "\titers: 800, epoch: 6 | loss: 0.1103766\n",
      "\tspeed: 0.0138s/iter; left time: 67.2144s\n",
      "\titers: 900, epoch: 6 | loss: 0.1078636\n",
      "\tspeed: 0.0138s/iter; left time: 65.7752s\n",
      "\titers: 1000, epoch: 6 | loss: 0.1121790\n",
      "\tspeed: 0.0139s/iter; left time: 64.9649s\n",
      "\titers: 1100, epoch: 6 | loss: 0.1041853\n",
      "\tspeed: 0.0139s/iter; left time: 63.4300s\n",
      "Epoch: 6 cost time: 35.72892212867737\n",
      "Epoch: 6, Steps: 1135 | Train Loss: 0.1058754 Vali Loss: 0.1042770 Test Loss: 0.1191283\n",
      "Validation loss decreased (0.104285 --> 0.104277).  Saving model ...\n",
      "Updating learning rate to 1.5625e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0995056\n",
      "\tspeed: 0.7719s/iter; left time: 3428.1133s\n",
      "\titers: 200, epoch: 7 | loss: 0.0991922\n",
      "\tspeed: 0.0138s/iter; left time: 59.8509s\n",
      "\titers: 300, epoch: 7 | loss: 0.1036745\n",
      "\tspeed: 0.0138s/iter; left time: 58.4465s\n",
      "\titers: 400, epoch: 7 | loss: 0.1108216\n",
      "\tspeed: 0.0137s/iter; left time: 56.7977s\n",
      "\titers: 500, epoch: 7 | loss: 0.1013999\n",
      "\tspeed: 0.0138s/iter; left time: 55.6278s\n",
      "\titers: 600, epoch: 7 | loss: 0.1047866\n",
      "\tspeed: 0.0138s/iter; left time: 54.2070s\n",
      "\titers: 700, epoch: 7 | loss: 0.1001461\n",
      "\tspeed: 0.0138s/iter; left time: 52.9832s\n",
      "\titers: 800, epoch: 7 | loss: 0.1125851\n",
      "\tspeed: 0.0138s/iter; left time: 51.7805s\n",
      "\titers: 900, epoch: 7 | loss: 0.1108277\n",
      "\tspeed: 0.0138s/iter; left time: 50.1608s\n",
      "\titers: 1000, epoch: 7 | loss: 0.1089656\n",
      "\tspeed: 0.0137s/iter; left time: 48.6242s\n",
      "\titers: 1100, epoch: 7 | loss: 0.1049342\n",
      "\tspeed: 0.0137s/iter; left time: 47.2845s\n",
      "Epoch: 7 cost time: 35.786468267440796\n",
      "Epoch: 7, Steps: 1135 | Train Loss: 0.1047222 Vali Loss: 0.1051265 Test Loss: 0.1202189\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1073477\n",
      "\tspeed: 0.7741s/iter; left time: 2559.2067s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\titers: 200, epoch: 8 | loss: 0.0903484\n",
      "\tspeed: 0.0137s/iter; left time: 43.8571s\n",
      "\titers: 300, epoch: 8 | loss: 0.1053530\n",
      "\tspeed: 0.0136s/iter; left time: 42.1556s\n",
      "\titers: 400, epoch: 8 | loss: 0.1125701\n",
      "\tspeed: 0.0136s/iter; left time: 40.8487s\n",
      "\titers: 500, epoch: 8 | loss: 0.0989260\n",
      "\tspeed: 0.0136s/iter; left time: 39.5840s\n",
      "\titers: 600, epoch: 8 | loss: 0.1076653\n",
      "\tspeed: 0.0136s/iter; left time: 38.2121s\n",
      "\titers: 700, epoch: 8 | loss: 0.1070102\n",
      "\tspeed: 0.0137s/iter; left time: 37.0934s\n",
      "\titers: 800, epoch: 8 | loss: 0.0973806\n",
      "\tspeed: 0.0136s/iter; left time: 35.5663s\n",
      "\titers: 900, epoch: 8 | loss: 0.1021517\n",
      "\tspeed: 0.0137s/iter; left time: 34.4238s\n",
      "\titers: 1000, epoch: 8 | loss: 0.1096423\n",
      "\tspeed: 0.0137s/iter; left time: 32.9512s\n",
      "\titers: 1100, epoch: 8 | loss: 0.1063446\n",
      "\tspeed: 0.0137s/iter; left time: 31.5342s\n",
      "Epoch: 8 cost time: 35.53463792800903\n",
      "Epoch: 8, Steps: 1135 | Train Loss: 0.1041385 Vali Loss: 0.1046648 Test Loss: 0.1198785\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0979147\n",
      "\tspeed: 0.7753s/iter; left time: 1683.0853s\n",
      "\titers: 200, epoch: 9 | loss: 0.0911772\n",
      "\tspeed: 0.0137s/iter; left time: 28.4079s\n",
      "\titers: 300, epoch: 9 | loss: 0.0897628\n",
      "\tspeed: 0.0138s/iter; left time: 27.1764s\n",
      "\titers: 400, epoch: 9 | loss: 0.1092880\n",
      "\tspeed: 0.0138s/iter; left time: 25.8233s\n",
      "\titers: 500, epoch: 9 | loss: 0.1132812\n",
      "\tspeed: 0.0138s/iter; left time: 24.4251s\n",
      "\titers: 600, epoch: 9 | loss: 0.1010085\n",
      "\tspeed: 0.0138s/iter; left time: 22.9857s\n",
      "\titers: 700, epoch: 9 | loss: 0.1001027\n",
      "\tspeed: 0.0137s/iter; left time: 21.5057s\n",
      "\titers: 800, epoch: 9 | loss: 0.0963507\n",
      "\tspeed: 0.0137s/iter; left time: 20.2155s\n",
      "\titers: 900, epoch: 9 | loss: 0.1112443\n",
      "\tspeed: 0.0138s/iter; left time: 18.9291s\n",
      "\titers: 1000, epoch: 9 | loss: 0.1001675\n",
      "\tspeed: 0.0137s/iter; left time: 17.4727s\n",
      "\titers: 1100, epoch: 9 | loss: 0.0913255\n",
      "\tspeed: 0.0137s/iter; left time: 16.0706s\n",
      "Epoch: 9 cost time: 35.7346727848053\n",
      "Epoch: 9, Steps: 1135 | Train Loss: 0.1038212 Vali Loss: 0.1046679 Test Loss: 0.1199081\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ECL_180_60_iTransformer_custom_M_ft180_sl48_ll60_pl512_dm8_nh3_el1_dl512_df1_fctimeF_ebTrue_dtExp_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 5201\n",
      "test shape: (5201, 1, 60, 321) (5201, 1, 60, 321)\n",
      "test shape: (5201, 60, 321) (5201, 60, 321)\n",
      "mse:0.11912839859724045, mae:0.21442697942256927\n"
     ]
    }
   ],
   "source": [
    "# 시드 설정\n",
    "fix_seed = 2023\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "\n",
    "# args 설정\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.is_training = 1\n",
    "        self.root_path = './dataset/electricity/'\n",
    "        self.data_path = 'electricity.csv'\n",
    "        self.model_id = 'ECL_180_60'\n",
    "        self.model = 'iTransformer'  # $model_name 대신 실제 모델명 입력\n",
    "        self.data = 'custom'\n",
    "        self.features = 'M'\n",
    "        self.seq_len = 180\n",
    "        self.pred_len = 60\n",
    "        self.e_layers = 3\n",
    "        self.enc_in = 321\n",
    "        self.dec_in = 321\n",
    "        self.c_out = 321\n",
    "        self.des = 'Exp'\n",
    "        self.d_model = 512\n",
    "        self.d_ff = 512\n",
    "        self.batch_size = 16\n",
    "        self.learning_rate = 0.0005\n",
    "        self.itr = 1\n",
    "        \n",
    "        # 기본값 설정\n",
    "        self.label_len = 48\n",
    "        self.target = 'OT'\n",
    "        self.freq = 'h'\n",
    "        self.checkpoints = './checkpoints/'\n",
    "        self.n_heads = 8\n",
    "        self.d_layers = 1\n",
    "        self.moving_avg = 25\n",
    "        self.factor = 1\n",
    "        self.distil = True\n",
    "        self.dropout = 0.1\n",
    "        self.embed = 'timeF'\n",
    "        self.activation = 'gelu'\n",
    "        self.output_attention = False\n",
    "        self.do_predict = False\n",
    "        self.num_workers = 10\n",
    "        self.train_epochs = 10\n",
    "        self.patience = 3\n",
    "        self.loss = 'MSE'\n",
    "        self.lradj = 'type1'\n",
    "        self.use_amp = False\n",
    "        self.use_gpu = True if torch.cuda.is_available() else False\n",
    "        self.gpu = 0\n",
    "        self.use_multi_gpu = False\n",
    "        self.devices = '0,1,2,3'\n",
    "        self.exp_name = 'MTSF'\n",
    "        self.channel_independence = False\n",
    "        self.inverse = False\n",
    "        self.class_strategy = 'projection'\n",
    "        self.target_root_path = './data/electricity/'\n",
    "        self.target_data_path = 'electricity.csv'\n",
    "        self.efficient_training = False\n",
    "        self.use_norm = True\n",
    "        self.partial_start_index = 0\n",
    "\n",
    "args = Args()\n",
    "\n",
    "if args.exp_name == 'partial_train':\n",
    "    Exp = Exp_Long_Term_Forecast_Partial\n",
    "else:\n",
    "    Exp = Exp_Long_Term_Forecast\n",
    "\n",
    "if args.is_training:\n",
    "    for ii in range(args.itr):\n",
    "        # setting record of experiments\n",
    "        setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "            args.model_id,\n",
    "            args.model,\n",
    "            args.data,\n",
    "            args.features,\n",
    "            args.seq_len,\n",
    "            args.label_len,\n",
    "            args.pred_len,\n",
    "            args.d_model,\n",
    "            args.n_heads,\n",
    "            args.e_layers,\n",
    "            args.d_layers,\n",
    "            args.d_ff,\n",
    "            args.factor,\n",
    "            args.embed,\n",
    "            args.distil,\n",
    "            args.des,\n",
    "            args.class_strategy, ii)\n",
    "\n",
    "        exp = Exp(args)  # set experiments\n",
    "        print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "        exp.train(setting)\n",
    "\n",
    "        print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "        exp.test(setting)\n",
    "\n",
    "        if args.do_predict:\n",
    "            print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "            exp.predict(setting, True)\n",
    "\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43455c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b82b92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
