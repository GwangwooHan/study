{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f12dbb3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T12:59:08.685423Z",
     "start_time": "2022-05-02T12:59:08.670465Z"
    }
   },
   "outputs": [],
   "source": [
    "# 필요한 package들을 import 한다. \n",
    "import os\n",
    "import sys\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "# device 설정\n",
    "# GPU를 사용할 수 있으면 사용하고, 아니면 CPU를 사용한다.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955fedbe",
   "metadata": {},
   "source": [
    "# Replay Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d3043d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T12:59:09.011551Z",
     "start_time": "2022-05-02T12:59:09.006565Z"
    }
   },
   "outputs": [],
   "source": [
    "# namedtuple은 key와 index를 통해 값에 접근할 수 있다.\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward', 'done'))\n",
    "\n",
    "\n",
    "# ReplayMemory를 정의\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        # deque는 양방향 queue를 의미한다.\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        # Transition을 저장하는 부분이다.\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        # memory로부터 batch_size 길이 만큼의 list를 반환한다.\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        # memory의 길이를 반환한다.\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b41539d",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f51b7e16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T12:59:09.307759Z",
     "start_time": "2022-05-02T12:59:09.301775Z"
    }
   },
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self, action_size):\n",
    "        super(net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, action_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = x.to(device)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8469b3da",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c315a0e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T12:59:09.638873Z",
     "start_time": "2022-05-02T12:59:09.630895Z"
    }
   },
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, action_size):\n",
    "        self.render = False\n",
    "        \n",
    "        self.action_size = action_size\n",
    "        \n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.001\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.999\n",
    "        self.epsilon_min = 0.01        \n",
    "        self.train_start = 1000\n",
    "        \n",
    "        self.model = net(action_size).to(device)\n",
    "        self.target_model = net(action_size).to(device)        \n",
    "        self.optimizer = optim.Adam(self.model.parameters(), self.learning_rate)\n",
    "        self.update_target_model()\n",
    "        \n",
    "    def update_target_model(self):\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "        \n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return torch.tensor([[random.randrange(self.action_size)]], device=device, \\\n",
    "        dtype=torch.long)\n",
    "        else:\n",
    "            return self.model(state).data.max(1)[1].view(1,1)\n",
    "        \n",
    "    def train_model(self):\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "            \n",
    "        transitions = memory.sample(BATCH_SIZE)\n",
    "        batch = Transition(*zip(*transitions))\n",
    "        \n",
    "        state_batch = torch.cat(batch.state)\n",
    "        action_batch = torch.cat(batch.action)\n",
    "        next_state_batch = torch.cat(batch.next_state)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "        done_batch = torch.cat(batch.done)\n",
    "        \n",
    "        \n",
    "        predicts = self.model(state_batch).gather(1, action_batch)\n",
    "        target_predicts = self.target_model(next_state_batch).detach()\n",
    "                \n",
    "        max_q = target_predicts.max(1)[0]\n",
    "        targets = reward_batch + (~done_batch)*self.discount_factor*max_q            \n",
    "        \n",
    "\n",
    "    # Huber Loss 계산\n",
    "        criterion = nn.SmoothL1Loss()\n",
    "        loss = criterion(predicts, targets.unsqueeze(1)) # unsqueeze(): 차원 추가 \n",
    "\n",
    "    # Optimize parameters\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in self.model.parameters():\n",
    "            # 모든 원소를 [ min, max ]의 범위로 clamp\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        self.optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e4f552",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9ead4e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T12:59:09.967993Z",
     "start_time": "2022-05-02T12:59:09.950042Z"
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "action_size = env.action_space.n\n",
    "memory = ReplayMemory(2000)\n",
    "\n",
    "agent = DQNAgent(action_size)\n",
    "scores, episodes = [], []\n",
    "score_avg=0\n",
    "HM_EPISODES = 300\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f972bb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T13:00:17.747717Z",
     "start_time": "2022-05-02T12:59:10.118591Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:   0 | score avg: 17.00 | steps: 17 | memory lengh:   17\n",
      "episode:   1 | score avg: 17.10 | steps: 18 | memory lengh:   35\n",
      "episode:   2 | score avg: 19.99 | steps: 46 | memory lengh:   81\n",
      "episode:   3 | score avg: 21.99 | steps: 40 | memory lengh:  121\n",
      "episode:   4 | score avg: 24.59 | steps: 48 | memory lengh:  169\n",
      "episode:   5 | score avg: 24.13 | steps: 20 | memory lengh:  189\n",
      "episode:   6 | score avg: 22.92 | steps: 12 | memory lengh:  201\n",
      "episode:   7 | score avg: 22.43 | steps: 18 | memory lengh:  219\n",
      "episode:   8 | score avg: 23.08 | steps: 29 | memory lengh:  248\n",
      "episode:   9 | score avg: 22.18 | steps: 14 | memory lengh:  262\n",
      "episode:  10 | score avg: 22.56 | steps: 26 | memory lengh:  288\n",
      "episode:  11 | score avg: 22.60 | steps: 23 | memory lengh:  311\n",
      "episode:  12 | score avg: 21.94 | steps: 16 | memory lengh:  327\n",
      "episode:  13 | score avg: 21.65 | steps: 19 | memory lengh:  346\n",
      "episode:  14 | score avg: 20.48 | steps: 10 | memory lengh:  356\n",
      "episode:  15 | score avg: 20.74 | steps: 23 | memory lengh:  379\n",
      "episode:  16 | score avg: 22.56 | steps: 39 | memory lengh:  418\n",
      "episode:  17 | score avg: 21.81 | steps: 15 | memory lengh:  433\n",
      "episode:  18 | score avg: 21.02 | steps: 14 | memory lengh:  447\n",
      "episode:  19 | score avg: 19.82 | steps:  9 | memory lengh:  456\n",
      "episode:  20 | score avg: 19.54 | steps: 17 | memory lengh:  473\n",
      "episode:  21 | score avg: 18.79 | steps: 12 | memory lengh:  485\n",
      "episode:  22 | score avg: 18.51 | steps: 16 | memory lengh:  501\n",
      "episode:  23 | score avg: 18.96 | steps: 23 | memory lengh:  524\n",
      "episode:  24 | score avg: 18.36 | steps: 13 | memory lengh:  537\n",
      "episode:  25 | score avg: 18.62 | steps: 21 | memory lengh:  558\n",
      "episode:  26 | score avg: 19.96 | steps: 32 | memory lengh:  590\n",
      "episode:  27 | score avg: 20.27 | steps: 23 | memory lengh:  613\n",
      "episode:  28 | score avg: 19.54 | steps: 13 | memory lengh:  626\n",
      "episode:  29 | score avg: 19.79 | steps: 22 | memory lengh:  648\n",
      "episode:  30 | score avg: 20.41 | steps: 26 | memory lengh:  674\n",
      "episode:  31 | score avg: 21.47 | steps: 31 | memory lengh:  705\n",
      "episode:  32 | score avg: 21.12 | steps: 18 | memory lengh:  723\n",
      "episode:  33 | score avg: 20.61 | steps: 16 | memory lengh:  739\n",
      "episode:  34 | score avg: 22.05 | steps: 35 | memory lengh:  774\n",
      "episode:  35 | score avg: 21.14 | steps: 13 | memory lengh:  787\n",
      "episode:  36 | score avg: 23.03 | steps: 40 | memory lengh:  827\n",
      "episode:  37 | score avg: 25.23 | steps: 45 | memory lengh:  872\n",
      "episode:  38 | score avg: 24.60 | steps: 19 | memory lengh:  891\n",
      "episode:  39 | score avg: 26.84 | steps: 47 | memory lengh:  938\n",
      "episode:  40 | score avg: 25.16 | steps: 10 | memory lengh:  948\n",
      "episode:  41 | score avg: 24.04 | steps: 14 | memory lengh:  962\n",
      "episode:  42 | score avg: 24.04 | steps: 24 | memory lengh:  986\n",
      "episode:  43 | score avg: 23.13 | steps: 15 | memory lengh: 1001\n",
      "episode:  44 | score avg: 22.22 | steps: 14 | memory lengh: 1015\n",
      "episode:  45 | score avg: 21.80 | steps: 18 | memory lengh: 1033\n",
      "episode:  46 | score avg: 22.12 | steps: 25 | memory lengh: 1058\n",
      "episode:  47 | score avg: 22.01 | steps: 21 | memory lengh: 1079\n",
      "episode:  48 | score avg: 22.71 | steps: 29 | memory lengh: 1108\n",
      "episode:  49 | score avg: 22.34 | steps: 19 | memory lengh: 1127\n",
      "episode:  50 | score avg: 26.50 | steps: 64 | memory lengh: 1191\n",
      "episode:  51 | score avg: 25.25 | steps: 14 | memory lengh: 1205\n",
      "episode:  52 | score avg: 24.43 | steps: 17 | memory lengh: 1222\n",
      "episode:  53 | score avg: 24.28 | steps: 23 | memory lengh: 1245\n",
      "episode:  54 | score avg: 24.86 | steps: 30 | memory lengh: 1275\n",
      "episode:  55 | score avg: 25.47 | steps: 31 | memory lengh: 1306\n",
      "episode:  56 | score avg: 27.72 | steps: 48 | memory lengh: 1354\n",
      "episode:  57 | score avg: 27.85 | steps: 29 | memory lengh: 1383\n",
      "episode:  58 | score avg: 28.67 | steps: 36 | memory lengh: 1419\n",
      "episode:  59 | score avg: 27.20 | steps: 14 | memory lengh: 1433\n",
      "episode:  60 | score avg: 36.18 | steps:117 | memory lengh: 1550\n",
      "episode:  61 | score avg: 36.56 | steps: 40 | memory lengh: 1590\n",
      "episode:  62 | score avg: 37.61 | steps: 47 | memory lengh: 1637\n",
      "episode:  63 | score avg: 41.34 | steps: 75 | memory lengh: 1712\n",
      "episode:  64 | score avg: 41.01 | steps: 38 | memory lengh: 1750\n",
      "episode:  65 | score avg: 41.31 | steps: 44 | memory lengh: 1794\n",
      "episode:  66 | score avg: 61.48 | steps:243 | memory lengh: 2000\n",
      "episode:  67 | score avg: 63.23 | steps: 79 | memory lengh: 2000\n",
      "episode:  68 | score avg: 68.91 | steps:120 | memory lengh: 2000\n",
      "episode:  69 | score avg: 63.12 | steps: 11 | memory lengh: 2000\n",
      "episode:  70 | score avg: 68.30 | steps:115 | memory lengh: 2000\n",
      "episode:  71 | score avg: 76.37 | steps:149 | memory lengh: 2000\n",
      "episode:  72 | score avg: 92.44 | steps:237 | memory lengh: 2000\n",
      "episode:  73 | score avg: 109.09 | steps:259 | memory lengh: 2000\n",
      "episode:  74 | score avg: 110.68 | steps:125 | memory lengh: 2000\n",
      "episode:  75 | score avg: 112.12 | steps:125 | memory lengh: 2000\n",
      "episode:  76 | score avg: 113.90 | steps:130 | memory lengh: 2000\n",
      "episode:  77 | score avg: 115.31 | steps:128 | memory lengh: 2000\n",
      "episode:  78 | score avg: 117.58 | steps:138 | memory lengh: 2000\n",
      "episode:  79 | score avg: 118.92 | steps:131 | memory lengh: 2000\n",
      "episode:  80 | score avg: 119.63 | steps:126 | memory lengh: 2000\n",
      "episode:  81 | score avg: 122.97 | steps:153 | memory lengh: 2000\n",
      "episode:  82 | score avg: 129.37 | steps:187 | memory lengh: 2000\n",
      "episode:  83 | score avg: 138.43 | steps:220 | memory lengh: 2000\n",
      "episode:  84 | score avg: 137.99 | steps:134 | memory lengh: 2000\n",
      "episode:  85 | score avg: 140.09 | steps:159 | memory lengh: 2000\n",
      "episode:  86 | score avg: 142.88 | steps:168 | memory lengh: 2000\n",
      "episode:  87 | score avg: 144.19 | steps:156 | memory lengh: 2000\n",
      "episode:  88 | score avg: 145.08 | steps:153 | memory lengh: 2000\n",
      "episode:  89 | score avg: 150.37 | steps:198 | memory lengh: 2000\n",
      "episode:  90 | score avg: 149.03 | steps:137 | memory lengh: 2000\n",
      "episode:  91 | score avg: 148.73 | steps:146 | memory lengh: 2000\n",
      "episode:  92 | score avg: 149.15 | steps:153 | memory lengh: 2000\n",
      "episode:  93 | score avg: 147.54 | steps:133 | memory lengh: 2000\n",
      "episode:  94 | score avg: 152.79 | steps:200 | memory lengh: 2000\n",
      "episode:  95 | score avg: 158.21 | steps:207 | memory lengh: 2000\n",
      "episode:  96 | score avg: 159.29 | steps:169 | memory lengh: 2000\n",
      "episode:  97 | score avg: 159.66 | steps:163 | memory lengh: 2000\n",
      "episode:  98 | score avg: 159.89 | steps:162 | memory lengh: 2000\n",
      "episode:  99 | score avg: 160.80 | steps:169 | memory lengh: 2000\n",
      "episode: 100 | score avg: 162.32 | steps:176 | memory lengh: 2000\n",
      "episode: 101 | score avg: 164.19 | steps:181 | memory lengh: 2000\n",
      "episode: 102 | score avg: 164.67 | steps:169 | memory lengh: 2000\n",
      "episode: 103 | score avg: 167.20 | steps:190 | memory lengh: 2000\n",
      "episode: 104 | score avg: 169.08 | steps:186 | memory lengh: 2000\n",
      "episode: 105 | score avg: 175.88 | steps:237 | memory lengh: 2000\n",
      "episode: 106 | score avg: 176.79 | steps:185 | memory lengh: 2000\n",
      "episode: 107 | score avg: 177.21 | steps:181 | memory lengh: 2000\n",
      "episode: 108 | score avg: 177.19 | steps:177 | memory lengh: 2000\n",
      "episode: 109 | score avg: 178.77 | steps:193 | memory lengh: 2000\n",
      "episode: 110 | score avg: 188.09 | steps:272 | memory lengh: 2000\n",
      "episode: 111 | score avg: 195.38 | steps:261 | memory lengh: 2000\n",
      "episode: 112 | score avg: 191.84 | steps:160 | memory lengh: 2000\n",
      "episode: 113 | score avg: 191.06 | steps:184 | memory lengh: 2000\n",
      "episode: 114 | score avg: 187.85 | steps:159 | memory lengh: 2000\n",
      "episode: 115 | score avg: 186.47 | steps:174 | memory lengh: 2000\n",
      "episode: 116 | score avg: 188.72 | steps:209 | memory lengh: 2000\n",
      "episode: 117 | score avg: 189.55 | steps:197 | memory lengh: 2000\n",
      "episode: 118 | score avg: 202.09 | steps:315 | memory lengh: 2000\n",
      "episode: 119 | score avg: 202.99 | steps:211 | memory lengh: 2000\n",
      "episode: 120 | score avg: 203.99 | steps:213 | memory lengh: 2000\n",
      "episode: 121 | score avg: 206.19 | steps:226 | memory lengh: 2000\n",
      "episode: 122 | score avg: 202.77 | steps:172 | memory lengh: 2000\n",
      "episode: 123 | score avg: 198.09 | steps:156 | memory lengh: 2000\n",
      "episode: 124 | score avg: 197.48 | steps:192 | memory lengh: 2000\n",
      "episode: 125 | score avg: 207.03 | steps:293 | memory lengh: 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 126 | score avg: 209.43 | steps:231 | memory lengh: 2000\n",
      "episode: 127 | score avg: 211.19 | steps:227 | memory lengh: 2000\n",
      "episode: 128 | score avg: 212.47 | steps:224 | memory lengh: 2000\n",
      "episode: 129 | score avg: 216.72 | steps:255 | memory lengh: 2000\n",
      "episode: 130 | score avg: 217.35 | steps:223 | memory lengh: 2000\n",
      "episode: 131 | score avg: 220.32 | steps:247 | memory lengh: 2000\n",
      "episode: 132 | score avg: 223.08 | steps:248 | memory lengh: 2000\n",
      "episode: 133 | score avg: 230.48 | steps:297 | memory lengh: 2000\n",
      "episode: 134 | score avg: 230.93 | steps:235 | memory lengh: 2000\n",
      "episode: 135 | score avg: 237.23 | steps:294 | memory lengh: 2000\n",
      "episode: 136 | score avg: 234.31 | steps:208 | memory lengh: 2000\n",
      "episode: 137 | score avg: 241.88 | steps:310 | memory lengh: 2000\n",
      "episode: 138 | score avg: 267.69 | steps:500 | memory lengh: 2000\n",
      "episode: 139 | score avg: 276.72 | steps:358 | memory lengh: 2000\n",
      "episode: 140 | score avg: 296.55 | steps:475 | memory lengh: 2000\n",
      "episode: 141 | score avg: 298.20 | steps:313 | memory lengh: 2000\n",
      "episode: 142 | score avg: 318.38 | steps:500 | memory lengh: 2000\n",
      "episode: 143 | score avg: 336.54 | steps:500 | memory lengh: 2000\n",
      "episode: 144 | score avg: 352.88 | steps:500 | memory lengh: 2000\n",
      "episode: 145 | score avg: 351.60 | steps:340 | memory lengh: 2000\n",
      "episode: 146 | score avg: 365.44 | steps:490 | memory lengh: 2000\n",
      "episode: 147 | score avg: 352.19 | steps:233 | memory lengh: 2000\n",
      "episode: 148 | score avg: 366.97 | steps:500 | memory lengh: 2000\n",
      "episode: 149 | score avg: 380.28 | steps:500 | memory lengh: 2000\n",
      "episode: 150 | score avg: 392.25 | steps:500 | memory lengh: 2000\n",
      "episode: 151 | score avg: 403.02 | steps:500 | memory lengh: 2000\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for episode in range(HM_EPISODES):    \n",
    "    done = False\n",
    "    score = 0\n",
    "    steps = 0\n",
    "    \n",
    "    # env와 state 초기화\n",
    "    state = env.reset()         # state shape >> torch.Size([1, 3, 40, 90]) \n",
    "    state = torch.tensor([state], device=device, dtype =torch.float) # state에 차원하나 추가 필요\n",
    "\n",
    "\n",
    "    while not done:    \n",
    "        \n",
    "        if agent.render:\n",
    "            env.render()\n",
    "        \n",
    "        action = agent.get_action(state)    # action result >> tensor([[0]]) or tensor([[1]])\n",
    "\n",
    "        # 선택한 action을 대입하여 reward와 done을 얻어낸다. \n",
    "        # env.step(action.item())의 예시  \n",
    "        # >> (array([-0.008956, -0.160571,  0.005936,  0.302326]), 1.0, False, {})\n",
    "        next_state, reward, done, info = env.step(action.item())                \n",
    "        score += reward\n",
    "        reward = 0.1 if not done or score == 500 else -1\n",
    "        \n",
    "        reward = torch.tensor([reward], device=device, dtype = torch.float)\n",
    "        next_state = torch.tensor([next_state], device=device, dtype =torch.float)                \n",
    "        done = torch.tensor([done], device=device, dtype = torch.bool)\n",
    "\n",
    "        # 얻어낸 transition set을 memory에 저장\n",
    "        memory.push(state, action, next_state, reward, done)\n",
    "        # (policy network에서) 최적화 한단계 수행\n",
    "        \n",
    "        if len(memory) >= agent.train_start:\n",
    "            agent.train_model()\n",
    "\n",
    "        # 다음 상태로 이동\n",
    "        state = next_state\n",
    "        steps += 1\n",
    "\n",
    "        # 마찬가지로 done이 True 라면,\n",
    "        if done:\n",
    "            agent.update_target_model()\n",
    "            score_avg = 0.9 * score_avg + 0.1 * score if score_avg !=0 else score\n",
    "            print('episode: {:3d} | score avg: {:3.2f} | steps:{:3d} | memory lengh: {:4d}'.format(\n",
    "                episode, score_avg, steps, len(memory)))\n",
    "            scores.append(score_avg)\n",
    "            episodes.append(episode)\n",
    "            plt.plot(episodes, scores, 'b')\n",
    "            plt.xlabel('episode')\n",
    "            plt.ylabel('average score')\n",
    "            \n",
    "   \n",
    "            if score_avg > 400:\n",
    "                sys.exit()       \n",
    "    \n",
    "\n",
    "    \n",
    "print('Complete')\n",
    "scores.clear\n",
    "episodes.clear\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2bb72b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a30220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4a0c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
