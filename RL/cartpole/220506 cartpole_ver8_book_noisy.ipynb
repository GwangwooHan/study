{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f12dbb3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:56:38.010870Z",
     "start_time": "2022-05-05T16:56:38.000863Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import operator\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torch.autograd as autograd \n",
    "\n",
    "\n",
    "# device 설정:GPU를 사용할 수 있으면 사용하고, 아니면 CPU를 사용한다.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5be650",
   "metadata": {},
   "source": [
    "# Ver7에서 Ver8 바꾼내용\n",
    "* Noisy networks for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ccb4b73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:56:38.504306Z",
     "start_time": "2022-05-05T16:56:38.496303Z"
    }
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955fedbe",
   "metadata": {},
   "source": [
    "# Replay Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37c8c4ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:56:39.059617Z",
     "start_time": "2022-05-05T16:56:39.040000Z"
    }
   },
   "outputs": [],
   "source": [
    "class SegmentTree(object):\n",
    "    def __init__(self, capacity, operation, neutral_element):\n",
    "        assert capacity > 0 and capacity & (capacity - 1) == 0, \"capacity must be positive and a power of 2.\"\n",
    "        self._capacity = capacity\n",
    "        self._value = [neutral_element for _ in range(2 * capacity)]\n",
    "        self._operation = operation\n",
    "\n",
    "    def _reduce_helper(self, start, end, node, node_start, node_end):\n",
    "        if start == node_start and end == node_end:\n",
    "            return self._value[node]\n",
    "        mid = (node_start + node_end) // 2\n",
    "        if end <= mid:\n",
    "            return self._reduce_helper(start, end, 2 * node, node_start, mid)\n",
    "        else:\n",
    "            if mid + 1 <= start:\n",
    "                return self._reduce_helper(start, end, 2 * node + 1, mid + 1, node_end)\n",
    "            else:\n",
    "                return self._operation(\n",
    "                    self._reduce_helper(start, mid, 2 * node, node_start, mid),\n",
    "                    self._reduce_helper(mid + 1, end, 2 * node + 1, mid + 1, node_end)\n",
    "                )\n",
    "\n",
    "    def reduce(self, start=0, end=None):\n",
    "        if end is None:\n",
    "            end = self._capacity\n",
    "        if end < 0:\n",
    "            end += self._capacity\n",
    "        end -= 1\n",
    "        return self._reduce_helper(start, end, 1, 0, self._capacity - 1)\n",
    "\n",
    "    def __setitem__(self, idx, val):\n",
    "        # index of the leaf\n",
    "        idx += self._capacity\n",
    "        self._value[idx] = val\n",
    "        idx //= 2\n",
    "        while idx >= 1:\n",
    "            self._value[idx] = self._operation(\n",
    "                self._value[2 * idx],\n",
    "                self._value[2 * idx + 1]\n",
    "            )\n",
    "            idx //= 2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        assert 0 <= idx < self._capacity\n",
    "        return self._value[self._capacity + idx]\n",
    "\n",
    "\n",
    "class SumSegmentTree(SegmentTree):\n",
    "    def __init__(self, capacity):\n",
    "        super(SumSegmentTree, self).__init__(\n",
    "            capacity=capacity,\n",
    "            operation=operator.add,\n",
    "            neutral_element=0.0\n",
    "        )\n",
    "\n",
    "    def sum(self, start=0, end=None):\n",
    "        \"\"\"Returns arr[start] + ... + arr[end]\"\"\"\n",
    "        return super(SumSegmentTree, self).reduce(start, end)\n",
    "\n",
    "    def find_prefixsum_idx(self, prefixsum):\n",
    "        \"\"\"Find the highest index `i` in the array such that\n",
    "            sum(arr[0] + arr[1] + ... + arr[i - i]) <= prefixsum\n",
    "        if array values are probabilities, this function\n",
    "        allows to sample indexes according to the discrete\n",
    "        probability efficiently.\n",
    "        Parameters\n",
    "        ----------\n",
    "        perfixsum: float\n",
    "            upperbound on the sum of array prefix\n",
    "        Returns\n",
    "        -------\n",
    "        idx: int\n",
    "            highest index satisfying the prefixsum constraint\n",
    "        \"\"\"\n",
    "        assert 0 <= prefixsum <= self.sum() + 1e-5\n",
    "        idx = 1\n",
    "        while idx < self._capacity:  # while non-leaf\n",
    "            if self._value[2 * idx] > prefixsum:\n",
    "                idx = 2 * idx\n",
    "            else:\n",
    "                prefixsum -= self._value[2 * idx]\n",
    "                idx = 2 * idx + 1\n",
    "        return idx - self._capacity\n",
    "\n",
    "\n",
    "class MinSegmentTree(SegmentTree):\n",
    "    def __init__(self, capacity):\n",
    "        super(MinSegmentTree, self).__init__(\n",
    "            capacity=capacity,\n",
    "            operation=min,\n",
    "            neutral_element=float('inf')\n",
    "        )\n",
    "\n",
    "    def min(self, start=0, end=None):\n",
    "        \"\"\"Returns min(arr[start], ...,  arr[end])\"\"\"\n",
    "\n",
    "        return super(MinSegmentTree, self).reduce(start, end)\n",
    "\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, size):\n",
    "        \"\"\"Create Replay buffer.\n",
    "        Parameters\n",
    "        ----------\n",
    "        size: int\n",
    "            Max number of transitions to store in the buffer. When the buffer\n",
    "            overflows the old memories are dropped.\n",
    "        \"\"\"\n",
    "        self._storage = []\n",
    "        self._maxsize = size\n",
    "        self._next_idx = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._storage)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        state = torch.tensor([state], device=device, dtype =torch.float)        \n",
    "        reward = torch.tensor([reward], device=device, dtype = torch.float)\n",
    "        next_state = torch.tensor([next_state], device=device, dtype =torch.float)\n",
    "        done =  torch.tensor([done], device=device, dtype = torch.bool) \n",
    "        data = (state, action, reward, next_state, done)\n",
    "\n",
    "        if self._next_idx >= len(self._storage):\n",
    "            self._storage.append(data)\n",
    "        else:\n",
    "            self._storage[self._next_idx] = data\n",
    "        self._next_idx = (self._next_idx + 1) % self._maxsize\n",
    "\n",
    "    def _encode_sample(self, idxes):\n",
    "        obses_t, actions, rewards, obses_tp1, dones = [], [], [], [], []\n",
    "        for i in idxes:\n",
    "            data = self._storage[i]\n",
    "            obs_t, action, reward, obs_tp1, done = data\n",
    "            obses_t.append(np.array(obs_t, copy=False))\n",
    "            actions.append(np.array(action, copy=False))\n",
    "            rewards.append(reward)\n",
    "            obses_tp1.append(np.array(obs_tp1, copy=False))\n",
    "            dones.append(done)\n",
    "        return np.array(obses_t), np.array(actions), np.array(rewards), np.array(obses_tp1), np.array(dones)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Sample a batch of experiences.\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size: int\n",
    "            How many transitions to sample.\n",
    "        Returns\n",
    "        -------\n",
    "        obs_batch: np.array\n",
    "            batch of observations\n",
    "        act_batch: np.array\n",
    "            batch of actions executed given obs_batch\n",
    "        rew_batch: np.array\n",
    "            rewards received as results of executing act_batch\n",
    "        next_obs_batch: np.array\n",
    "            next set of observations seen after executing act_batch\n",
    "        done_mask: np.array\n",
    "            done_mask[i] = 1 if executing act_batch[i] resulted in\n",
    "            the end of an episode and 0 otherwise.\n",
    "        \"\"\"\n",
    "        idxes = [random.randint(0, len(self._storage) - 1) for _ in range(batch_size)]\n",
    "        return self._encode_sample(idxes)\n",
    "\n",
    "\n",
    "class PrioritizedReplayBuffer(ReplayBuffer):\n",
    "    def __init__(self, size, alpha):\n",
    "        \"\"\"Create Prioritized Replay buffer.\n",
    "        Parameters\n",
    "        ----------\n",
    "        size: int\n",
    "            Max number of transitions to store in the buffer. When the buffer\n",
    "            overflows the old memories are dropped.\n",
    "        alpha: float\n",
    "            how much prioritization is used\n",
    "            (0 - no prioritization, 1 - full prioritization)\n",
    "        See Also\n",
    "        --------\n",
    "        ReplayBuffer.__init__\n",
    "        \"\"\"\n",
    "        super(PrioritizedReplayBuffer, self).__init__(size)\n",
    "        assert alpha > 0\n",
    "        self._alpha = alpha\n",
    "\n",
    "        it_capacity = 1\n",
    "        while it_capacity < size:\n",
    "            it_capacity *= 2\n",
    "\n",
    "        self._it_sum = SumSegmentTree(it_capacity)\n",
    "        self._it_min = MinSegmentTree(it_capacity)\n",
    "        self._max_priority = 1.0\n",
    "\n",
    "    def push(self, *args, **kwargs):\n",
    "        \"\"\"See ReplayBuffer.store_effect\"\"\"\n",
    "        idx = self._next_idx\n",
    "        super(PrioritizedReplayBuffer, self).push(*args, **kwargs)\n",
    "        self._it_sum[idx] = self._max_priority ** self._alpha\n",
    "        self._it_min[idx] = self._max_priority ** self._alpha\n",
    "\n",
    "    def _sample_proportional(self, batch_size):\n",
    "        res = []\n",
    "        for _ in range(batch_size):\n",
    "            # TODO(szymon): should we ensure no repeats?\n",
    "            mass = random.random() * self._it_sum.sum(0, len(self._storage) - 1)\n",
    "            idx = self._it_sum.find_prefixsum_idx(mass)\n",
    "            res.append(idx)\n",
    "        return res\n",
    "\n",
    "    def sample(self, batch_size, beta):\n",
    "        \"\"\"Sample a batch of experiences.\n",
    "        compared to ReplayBuffer.sample\n",
    "        it also returns importance weights and idxes\n",
    "        of sampled experiences.\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size: int\n",
    "            How many transitions to sample.\n",
    "        beta: float\n",
    "            To what degree to use importance weights\n",
    "            (0 - no corrections, 1 - full correction)\n",
    "        Returns\n",
    "        -------\n",
    "        obs_batch: np.array\n",
    "            batch of observations\n",
    "        act_batch: np.array\n",
    "            batch of actions executed given obs_batch\n",
    "        rew_batch: np.array\n",
    "            rewards received as results of executing act_batch\n",
    "        next_obs_batch: np.array\n",
    "            next set of observations seen after executing act_batch\n",
    "        done_mask: np.array\n",
    "            done_mask[i] = 1 if executing act_batch[i] resulted in\n",
    "            the end of an episode and 0 otherwise.\n",
    "        weights: np.array\n",
    "            Array of shape (batch_size,) and dtype np.float32\n",
    "            denoting importance weight of each sampled transition\n",
    "        idxes: np.array\n",
    "            Array of shape (batch_size,) and dtype np.int32\n",
    "            idexes in buffer of sampled experiences\n",
    "        \"\"\"\n",
    "        assert beta > 0\n",
    "\n",
    "        idxes = self._sample_proportional(batch_size)\n",
    "\n",
    "        weights = []\n",
    "        p_min = self._it_min.min() / self._it_sum.sum()\n",
    "        max_weight = (p_min * len(self._storage)) ** (-beta)\n",
    "\n",
    "        for idx in idxes:\n",
    "            p_sample = self._it_sum[idx] / self._it_sum.sum()\n",
    "            weight = (p_sample * len(self._storage)) ** (-beta)\n",
    "            weights.append(weight / max_weight)\n",
    "        weights = np.array(weights)\n",
    "        encoded_sample = self._encode_sample(idxes)\n",
    "        return tuple(list(encoded_sample) + [weights, idxes])\n",
    "\n",
    "    def update_priorities(self, idxes, priorities):\n",
    "        \"\"\"Update priorities of sampled transitions.\n",
    "        sets priority of transition at index idxes[i] in buffer\n",
    "        to priorities[i].\n",
    "        Parameters\n",
    "        ----------\n",
    "        idxes: [int]\n",
    "            List of idxes of sampled transitions\n",
    "        priorities: [float]\n",
    "            List of updated priorities corresponding to\n",
    "            transitions at the sampled idxes denoted by\n",
    "            variable `idxes`.\n",
    "        \"\"\"\n",
    "        assert len(idxes) == len(priorities)\n",
    "        for idx, priority in zip(idxes, priorities):\n",
    "            assert priority > 0\n",
    "            assert 0 <= idx < len(self._storage)\n",
    "            self._it_sum[idx] = priority ** self._alpha\n",
    "            self._it_min[idx] = priority ** self._alpha\n",
    "\n",
    "            self._max_priority = max(self._max_priority, priority)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17749a85",
   "metadata": {},
   "source": [
    "# Noisy Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82c5d5e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:56:39.325621Z",
     "start_time": "2022-05-05T16:56:39.312617Z"
    }
   },
   "outputs": [],
   "source": [
    "class NoisyLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, std_init=0.4):\n",
    "        super(NoisyLinear, self).__init__()\n",
    "        \n",
    "        self.in_features  = in_features\n",
    "        self.out_features = out_features\n",
    "        self.std_init     = std_init\n",
    "        \n",
    "        self.weight_mu    = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        self.weight_sigma = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        self.register_buffer('weight_epsilon', torch.FloatTensor(out_features, in_features))\n",
    "        \n",
    "        self.bias_mu    = nn.Parameter(torch.FloatTensor(out_features))\n",
    "        self.bias_sigma = nn.Parameter(torch.FloatTensor(out_features))\n",
    "        self.register_buffer('bias_epsilon', torch.FloatTensor(out_features))\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.training: \n",
    "            weight = self.weight_mu + self.weight_sigma.mul(Variable(self.weight_epsilon))\n",
    "            bias   = self.bias_mu   + self.bias_sigma.mul(Variable(self.bias_epsilon))\n",
    "        else:\n",
    "            weight = self.weight_mu\n",
    "            bias   = self.bias_mu\n",
    "        \n",
    "        return F.linear(x, weight, bias)\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        mu_range = 1 / math.sqrt(self.weight_mu.size(1))\n",
    "        \n",
    "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.weight_sigma.data.fill_(self.std_init / math.sqrt(self.weight_sigma.size(1)))\n",
    "        \n",
    "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.bias_sigma.data.fill_(self.std_init / math.sqrt(self.bias_sigma.size(0)))\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        epsilon_in  = self._scale_noise(self.in_features)\n",
    "        epsilon_out = self._scale_noise(self.out_features)\n",
    "        \n",
    "        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n",
    "        self.bias_epsilon.copy_(self._scale_noise(self.out_features))\n",
    "    \n",
    "    def _scale_noise(self, size):\n",
    "        x = torch.randn(size)\n",
    "        x = x.sign().mul(x.abs().sqrt())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b41539d",
   "metadata": {},
   "source": [
    "# NoisyNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f51b7e16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:56:39.832507Z",
     "start_time": "2022-05-05T16:56:39.817506Z"
    }
   },
   "outputs": [],
   "source": [
    "class NoisyDQN(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions):\n",
    "        super(NoisyDQN, self).__init__()\n",
    "        \n",
    "        self.linear =  nn.Linear(env.observation_space.shape[0], 128)\n",
    "        self.noisy1 = NoisyLinear(128, 128)\n",
    "        self.noisy2 = NoisyLinear(128, env.action_space.n)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear(x))\n",
    "        x = F.relu(self.noisy1(x))\n",
    "        x = self.noisy2(x)\n",
    "        return x\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        self.noisy1.reset_noise()\n",
    "        self.noisy2.reset_noise()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8469b3da",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c315a0e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:56:40.308158Z",
     "start_time": "2022-05-05T16:56:40.293155Z"
    }
   },
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, action_size):\n",
    "        self.render = False\n",
    "\n",
    "        self.action_size = action_size\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.001        \n",
    "        self.train_start = 1000\n",
    "\n",
    "        self.model = NoisyDQN(env.observation_space.shape[0], env.action_space.n).to(device)\n",
    "        self.target_model = NoisyDQN(env.observation_space.shape[0], env.action_space.n).to(device)\n",
    "        self.optimizer = optim.Adam(\n",
    "            self.model.parameters(), self.learning_rate)\n",
    "        self.update_target_model()\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "    def get_action(self, state):\n",
    "        state = torch.tensor([state], device=device, dtype=torch.float)\n",
    "        return self.model(state).detach().max(1)[1].view(1,1)  # tensor[[]]\n",
    "\n",
    "    def train_model(self):        \n",
    "        Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward', 'done', 'weights', 'indices'))        \n",
    "        transitions = memory.sample(BATCH_SIZE, beta)\n",
    "        batch = Transition(*zip(*transitions))  # batch에 BATCH_SIZE 만큼 state_batch, 등 5종류를 구분하여 꺼내둠       \n",
    "\n",
    "        state_batch = torch.cat(batch.state)\n",
    "        action_batch = torch.cat(batch.action)\n",
    "        next_state_batch = torch.cat(batch.next_state)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "        done_batch = torch.cat(batch.done)\n",
    "        weights_batch = torch.cat(batch.weights)\n",
    "        indices_batch = torch.cat(batch.indices)\n",
    "\n",
    "        predicts = self.model(state_batch).gather(1, action_batch)\n",
    "        target_predicts = self.target_model(next_state_batch).detach()\n",
    "\n",
    "        max_q = target_predicts.max(1)[0]\n",
    "        targets = reward_batch + (~done_batch)*self.discount_factor*max_q\n",
    "\n",
    "    # Huber Loss 계산\n",
    "        criterion = nn.SmoothL1Loss()\n",
    "        loss = criterion(predicts, targets.unsqueeze(1))  # unsqueeze(): 차원 추가\n",
    "        prios = loss + 1e-5\n",
    "        loss = loss.mean()\n",
    "\n",
    "    # Optimize parameters\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in self.model.parameters():\n",
    "            # 모든 원소를 [ min, max ]의 범위로 clamp\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        memory.update_priorities(indices_batch, prios.detach().cpu().numpy())\n",
    "        model.reset_noise()\n",
    "        target_model.reset_noise()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e4f552",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9ead4e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:56:40.908012Z",
     "start_time": "2022-05-05T16:56:40.899505Z"
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "action_size = env.action_space.n\n",
    "beta_start = 0.4\n",
    "beta_episodes = 10\n",
    "beta_by_episode = lambda episode: min(1.0, beta_start + episode*(1.0 - beta_start)/beta_episodes)\n",
    "\n",
    "# memory = ReplayMemory(2000)\n",
    "memory = PrioritizedReplayBuffer(2000, alpha=0.6)\n",
    "\n",
    "agent = DQNAgent(action_size)\n",
    "scores, episodes = [], []\n",
    "score_avg=0\n",
    "HM_EPISODES = 300\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f972bb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:56:42.086695Z",
     "start_time": "2022-05-05T16:56:41.265505Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:   0 | score avg: 20.00 | steps: 20 | memory lengh:   20\n",
      "episode:   1 | score avg: 19.50 | steps: 15 | memory lengh:   35\n",
      "episode:   2 | score avg: 19.75 | steps: 22 | memory lengh:   57\n",
      "episode:   3 | score avg: 19.98 | steps: 22 | memory lengh:   79\n",
      "episode:   4 | score avg: 19.48 | steps: 15 | memory lengh:   94\n",
      "episode:   5 | score avg: 19.13 | steps: 16 | memory lengh:  110\n",
      "episode:   6 | score avg: 18.92 | steps: 17 | memory lengh:  127\n",
      "episode:   7 | score avg: 19.53 | steps: 25 | memory lengh:  152\n",
      "episode:   8 | score avg: 19.57 | steps: 20 | memory lengh:  172\n",
      "episode:   9 | score avg: 19.42 | steps: 18 | memory lengh:  190\n",
      "episode:  10 | score avg: 19.67 | steps: 22 | memory lengh:  212\n",
      "episode:  11 | score avg: 19.61 | steps: 19 | memory lengh:  231\n",
      "episode:  12 | score avg: 19.75 | steps: 21 | memory lengh:  252\n",
      "episode:  13 | score avg: 20.17 | steps: 24 | memory lengh:  276\n",
      "episode:  14 | score avg: 19.75 | steps: 16 | memory lengh:  292\n",
      "episode:  15 | score avg: 19.58 | steps: 18 | memory lengh:  310\n",
      "episode:  16 | score avg: 20.02 | steps: 24 | memory lengh:  334\n",
      "episode:  17 | score avg: 19.62 | steps: 16 | memory lengh:  350\n",
      "episode:  18 | score avg: 19.16 | steps: 15 | memory lengh:  365\n",
      "episode:  19 | score avg: 18.84 | steps: 16 | memory lengh:  381\n",
      "episode:  20 | score avg: 18.76 | steps: 18 | memory lengh:  399\n",
      "episode:  21 | score avg: 19.58 | steps: 27 | memory lengh:  426\n",
      "episode:  22 | score avg: 19.62 | steps: 20 | memory lengh:  446\n",
      "episode:  23 | score avg: 19.46 | steps: 18 | memory lengh:  464\n",
      "episode:  24 | score avg: 19.21 | steps: 17 | memory lengh:  481\n",
      "episode:  25 | score avg: 18.89 | steps: 16 | memory lengh:  497\n",
      "episode:  26 | score avg: 18.50 | steps: 15 | memory lengh:  512\n",
      "episode:  27 | score avg: 19.05 | steps: 24 | memory lengh:  536\n",
      "episode:  28 | score avg: 19.55 | steps: 24 | memory lengh:  560\n",
      "episode:  29 | score avg: 20.59 | steps: 30 | memory lengh:  590\n",
      "episode:  30 | score avg: 20.33 | steps: 18 | memory lengh:  608\n",
      "episode:  31 | score avg: 19.90 | steps: 16 | memory lengh:  624\n",
      "episode:  32 | score avg: 19.81 | steps: 19 | memory lengh:  643\n",
      "episode:  33 | score avg: 20.03 | steps: 22 | memory lengh:  665\n",
      "episode:  34 | score avg: 20.23 | steps: 22 | memory lengh:  687\n",
      "episode:  35 | score avg: 20.60 | steps: 24 | memory lengh:  711\n",
      "episode:  36 | score avg: 20.54 | steps: 20 | memory lengh:  731\n",
      "episode:  37 | score avg: 21.09 | steps: 26 | memory lengh:  757\n",
      "episode:  38 | score avg: 20.98 | steps: 20 | memory lengh:  777\n",
      "episode:  39 | score avg: 20.88 | steps: 20 | memory lengh:  797\n",
      "episode:  40 | score avg: 21.79 | steps: 30 | memory lengh:  827\n",
      "episode:  41 | score avg: 21.21 | steps: 16 | memory lengh:  843\n",
      "episode:  42 | score avg: 21.69 | steps: 26 | memory lengh:  869\n",
      "episode:  43 | score avg: 22.12 | steps: 26 | memory lengh:  895\n",
      "episode:  44 | score avg: 21.71 | steps: 18 | memory lengh:  913\n",
      "episode:  45 | score avg: 22.04 | steps: 25 | memory lengh:  938\n",
      "episode:  46 | score avg: 21.44 | steps: 16 | memory lengh:  954\n",
      "episode:  47 | score avg: 21.59 | steps: 23 | memory lengh:  977\n",
      "episode:  48 | score avg: 21.23 | steps: 18 | memory lengh:  995\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'function' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8852\\1464385762.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_start\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbeta_by_episode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8852\\1125430188.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     24\u001b[0m         Transition = namedtuple('Transition',\n\u001b[0;32m     25\u001b[0m                         ('state', 'action', 'next_state', 'reward', 'done', 'weights', 'indices'))        \n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mtransitions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTransition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# batch에 BATCH_SIZE 만큼 state_batch, 등 5종류를 구분하여 꺼내둠\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8852\\1240503710.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, batch_size, beta)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[0midexes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0mof\u001b[0m \u001b[0msampled\u001b[0m \u001b[0mexperiences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \"\"\"\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[0midxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sample_proportional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'function' and 'int'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for episode in range(HM_EPISODES):    \n",
    "    done = False\n",
    "    score = 0\n",
    "    steps = 0\n",
    "    \n",
    "    # env와 state 초기화\n",
    "    state = env.reset()         \n",
    "\n",
    "    while not done:    \n",
    "        \n",
    "        if agent.render:\n",
    "            env.render()\n",
    "        \n",
    "        action = agent.get_action(state)    # action: tensor[[]]\n",
    "\n",
    "        next_state, reward, done, info = env.step(action.item()) #next_state: np[], reward: [], done: []               \n",
    "        score += reward\n",
    "        reward = 0.1 if not done or score == 500 else -1        \n",
    "        \n",
    "        memory.push(state, action, next_state, reward, done) #state: np[], action: tensor[[]], reward: [], next_state: np[], done: []\n",
    "\n",
    "                \n",
    "        # (policy network에서) 최적화 한단계 수행                \n",
    "        if len(memory) >= agent.train_start:\n",
    "            beta = beta_by_episode\n",
    "            agent.train_model()\n",
    "            \n",
    " \n",
    "        # 다음 상태로 이동\n",
    "        state = next_state\n",
    "        steps += 1\n",
    "\n",
    "        # 마찬가지로 done이 True 라면,\n",
    "        if done:\n",
    "            agent.update_target_model()\n",
    "            score_avg = 0.9 * score_avg + 0.1 * score if score_avg !=0 else score\n",
    "            print('episode: {:3d} | score avg: {:3.2f} | steps:{:3d} | memory lengh: {:4d}'.format(\n",
    "                episode, score_avg, steps, len(memory)))\n",
    "            scores.append(score_avg)\n",
    "            episodes.append(episode)\n",
    "            plt.plot(episodes, scores, 'b')\n",
    "            plt.xlabel('episode')\n",
    "            plt.ylabel('average score')\n",
    "            \n",
    "   \n",
    "            if score_avg > 1000:\n",
    "                sys.exit()       \n",
    "    \n",
    "\n",
    "    \n",
    "print('Complete')\n",
    "scores.clear\n",
    "episodes.clear\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2bb72b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a30220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4a0c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
