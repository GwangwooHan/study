{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f12dbb3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T11:55:25.447734Z",
     "start_time": "2022-05-02T11:55:24.401532Z"
    }
   },
   "outputs": [],
   "source": [
    "# 필요한 package들을 import 한다. \n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "# device 설정\n",
    "# GPU를 사용할 수 있으면 사용하고, 아니면 CPU를 사용한다.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955fedbe",
   "metadata": {},
   "source": [
    "# Replay Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d3043d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T11:55:25.636230Z",
     "start_time": "2022-05-02T11:55:25.622267Z"
    }
   },
   "outputs": [],
   "source": [
    "# namedtuple은 key와 index를 통해 값에 접근할 수 있다.\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "# ReplayMemory를 정의\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        # deque는 양방향 queue를 의미한다.\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        # Transition을 저장하는 부분이다.\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        # memory로부터 batch_size 길이 만큼의 list를 반환한다.\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        # memory의 길이를 반환한다.\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b41539d",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f51b7e16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T11:55:25.821734Z",
     "start_time": "2022-05-02T11:55:25.807771Z"
    }
   },
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self, outputs):\n",
    "        super(net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 24)\n",
    "        self.fc2 = nn.Linear(24, 24)\n",
    "        self.fc3 = nn.Linear(24, outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = x.to(device)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00804c82",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1096941e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T11:55:26.008235Z",
     "start_time": "2022-05-02T11:55:25.993275Z"
    }
   },
   "outputs": [],
   "source": [
    "def select_action(state, epsilon):\n",
    "\n",
    "    sample = random.random()\n",
    "\n",
    "    if sample > epsilon:\n",
    "#         with torch.no_grad():\n",
    "        return policy_net(state).max(1)[1].view(1,1)\n",
    "\n",
    "    else:\n",
    "        # tensor([['index']])의 형식으로 random하게 action이 선택된다. \n",
    "        # 즉, 0 이나 1 값이 선택됨.\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, \\\n",
    "        dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08582161",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c1a1634",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T11:55:26.194736Z",
     "start_time": "2022-05-02T11:55:26.181771Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "\n",
    " \n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    \n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    next_state_batch = torch.cat(batch.next_state)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "    \n",
    "\n",
    "\n",
    "    current_q_values = policy_net(state_batch).gather(1, action_batch)\n",
    "    max_next_q_values = target_net(next_state_batch).detach().max(1)[0]\n",
    "    target_q_values = reward_batch + (GAMMA * max_next_q_values)\n",
    "\n",
    "#     # Huber Loss 계산\n",
    "#     criterion = nn.SmoothL1Loss()\n",
    "# #     criterion = F.smooth_l1_loss()\n",
    "#     loss = criterion(current_q_values, target_q_values) # unsqueeze(): 차원 추가 \n",
    "    loss = F.mse_loss(current_q_values.squeeze(), target_q_values)    \n",
    "\n",
    "    # Optimize parameters\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        # 모든 원소를 [ min, max ]의 범위로 clamp\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ab92ab",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4324744",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d3ac45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T11:55:26.442075Z",
     "start_time": "2022-05-02T11:55:26.425120Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==== Hyperparameters ==== #\n",
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.98\n",
    "# EPS_START = 0.9\n",
    "# EPS_END = 0.05\n",
    "# EPS_DECAY = 200\n",
    "TARGET_UPDATE = 1\n",
    "LR = 0.0005\n",
    "# ========================== #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60680928",
   "metadata": {},
   "source": [
    "## Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7195dab8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T11:55:27.626906Z",
     "start_time": "2022-05-02T11:55:26.761221Z"
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# gym의 action space에서 action의 가짓수를 얻는다.\n",
    "# n_actions >> 2\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "# network\n",
    "policy_net = net(n_actions).to(device)\n",
    "target_net = net(n_actions).to(device)\n",
    "\n",
    "# policy network의 network parameter를 불러온다.   \n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "optimizer = optim.Adam(policy_net.parameters(), LR)\n",
    "\n",
    "# Capacity (즉, maximum length) 2000짜리 deque 이다.\n",
    "memory = ReplayMemory(2000)\n",
    "\n",
    "steps_done = 0\n",
    "score_avg = 0\n",
    "scores, episodes = [], []\n",
    "train_start = 2000\n",
    "HM_EPISODES = 10_000\n",
    "SHOW_EVERY = 20\n",
    "score = 0\n",
    "steps = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f972bb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T11:55:46.442583Z",
     "start_time": "2022-05-02T11:55:27.799444Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  20 | score: 10.2 | memory lengh:  203 | eps: 8.0%\n",
      "episode:  40 | score: 9.9 | memory lengh:  401 | eps: 8.0%\n",
      "episode:  60 | score: 9.6 | memory lengh:  592 | eps: 8.0%\n",
      "episode:  80 | score: 9.8 | memory lengh:  788 | eps: 8.0%\n",
      "episode: 100 | score: 9.6 | memory lengh:  979 | eps: 8.0%\n",
      "episode: 120 | score: 9.6 | memory lengh: 1171 | eps: 8.0%\n",
      "episode: 140 | score: 9.7 | memory lengh: 1364 | eps: 8.0%\n",
      "episode: 160 | score: 9.8 | memory lengh: 1560 | eps: 8.0%\n",
      "episode: 180 | score: 10.1 | memory lengh: 1761 | eps: 8.0%\n",
      "episode: 200 | score: 9.9 | memory lengh: 1959 | eps: 8.0%\n",
      "episode: 220 | score: 9.5 | memory lengh: 2149 | eps: 8.0%\n",
      "episode: 240 | score: 10.1 | memory lengh: 2351 | eps: 8.0%\n",
      "episode: 260 | score: 9.6 | memory lengh: 2542 | eps: 7.9%\n",
      "episode: 280 | score: 9.8 | memory lengh: 2739 | eps: 7.9%\n",
      "episode: 300 | score: 9.8 | memory lengh: 2934 | eps: 7.9%\n",
      "episode: 320 | score: 9.9 | memory lengh: 3132 | eps: 7.9%\n",
      "episode: 340 | score: 9.6 | memory lengh: 3323 | eps: 7.9%\n",
      "episode: 360 | score: 9.8 | memory lengh: 3518 | eps: 7.9%\n",
      "episode: 380 | score: 10.4 | memory lengh: 3726 | eps: 7.9%\n",
      "episode: 400 | score: 10.0 | memory lengh: 3926 | eps: 7.9%\n",
      "episode: 420 | score: 9.5 | memory lengh: 4116 | eps: 7.9%\n",
      "episode: 440 | score: 9.9 | memory lengh: 4314 | eps: 7.9%\n",
      "episode: 460 | score: 9.9 | memory lengh: 4512 | eps: 7.9%\n",
      "episode: 480 | score: 9.8 | memory lengh: 4707 | eps: 7.9%\n",
      "episode: 500 | score: 9.3 | memory lengh: 4893 | eps: 7.9%\n",
      "episode: 520 | score: 9.8 | memory lengh: 5089 | eps: 7.9%\n",
      "episode: 540 | score: 9.7 | memory lengh: 5283 | eps: 7.9%\n",
      "episode: 560 | score: 9.5 | memory lengh: 5473 | eps: 7.9%\n",
      "episode: 580 | score: 10.1 | memory lengh: 5674 | eps: 7.9%\n",
      "episode: 600 | score: 9.4 | memory lengh: 5863 | eps: 7.9%\n",
      "episode: 620 | score: 9.3 | memory lengh: 6049 | eps: 7.9%\n",
      "episode: 640 | score: 9.8 | memory lengh: 6245 | eps: 7.9%\n",
      "episode: 660 | score: 10.2 | memory lengh: 6448 | eps: 7.9%\n",
      "episode: 680 | score: 9.9 | memory lengh: 6646 | eps: 7.9%\n",
      "episode: 700 | score: 9.4 | memory lengh: 6834 | eps: 7.9%\n",
      "episode: 720 | score: 9.8 | memory lengh: 7029 | eps: 7.9%\n",
      "episode: 740 | score: 9.4 | memory lengh: 7218 | eps: 7.9%\n",
      "episode: 760 | score: 9.3 | memory lengh: 7405 | eps: 7.8%\n",
      "episode: 780 | score: 9.8 | memory lengh: 7601 | eps: 7.8%\n",
      "episode: 800 | score: 9.6 | memory lengh: 7793 | eps: 7.8%\n",
      "episode: 820 | score: 10.0 | memory lengh: 7993 | eps: 7.8%\n",
      "episode: 840 | score: 9.8 | memory lengh: 8190 | eps: 7.8%\n",
      "episode: 860 | score: 9.7 | memory lengh: 8383 | eps: 7.8%\n",
      "episode: 880 | score: 9.6 | memory lengh: 8575 | eps: 7.8%\n",
      "episode: 900 | score: 9.6 | memory lengh: 8766 | eps: 7.8%\n",
      "episode: 920 | score: 9.6 | memory lengh: 8958 | eps: 7.8%\n",
      "episode: 940 | score: 10.0 | memory lengh: 9158 | eps: 7.8%\n",
      "episode: 960 | score: 9.8 | memory lengh: 9353 | eps: 7.8%\n",
      "episode: 980 | score: 9.7 | memory lengh: 9547 | eps: 7.8%\n",
      "episode: 1000 | score: 9.7 | memory lengh: 9741 | eps: 7.8%\n",
      "episode: 1020 | score: 9.4 | memory lengh: 9929 | eps: 7.8%\n",
      "episode: 1040 | score: 9.9 | memory lengh: 10128 | eps: 7.8%\n",
      "episode: 1060 | score: 9.8 | memory lengh: 10323 | eps: 7.8%\n",
      "episode: 1080 | score: 9.8 | memory lengh: 10518 | eps: 7.8%\n",
      "episode: 1100 | score: 9.8 | memory lengh: 10713 | eps: 7.8%\n",
      "episode: 1120 | score: 10.4 | memory lengh: 10922 | eps: 7.8%\n",
      "episode: 1140 | score: 9.6 | memory lengh: 11113 | eps: 7.8%\n",
      "episode: 1160 | score: 9.8 | memory lengh: 11308 | eps: 7.8%\n",
      "episode: 1180 | score: 9.4 | memory lengh: 11497 | eps: 7.8%\n",
      "episode: 1200 | score: 10.2 | memory lengh: 11700 | eps: 7.8%\n",
      "episode: 1220 | score: 9.4 | memory lengh: 11889 | eps: 7.8%\n",
      "episode: 1240 | score: 10.4 | memory lengh: 12098 | eps: 7.8%\n",
      "episode: 1260 | score: 9.9 | memory lengh: 12297 | eps: 7.7%\n",
      "episode: 1280 | score: 9.7 | memory lengh: 12491 | eps: 7.7%\n",
      "episode: 1300 | score: 9.2 | memory lengh: 12675 | eps: 7.7%\n",
      "episode: 1320 | score: 10.0 | memory lengh: 12875 | eps: 7.7%\n",
      "episode: 1340 | score: 9.8 | memory lengh: 13070 | eps: 7.7%\n",
      "episode: 1360 | score: 10.2 | memory lengh: 13275 | eps: 7.7%\n",
      "episode: 1380 | score: 9.8 | memory lengh: 13471 | eps: 7.7%\n",
      "episode: 1400 | score: 10.0 | memory lengh: 13671 | eps: 7.7%\n",
      "episode: 1420 | score: 10.1 | memory lengh: 13872 | eps: 7.7%\n",
      "episode: 1440 | score: 9.8 | memory lengh: 14067 | eps: 7.7%\n",
      "episode: 1460 | score: 9.7 | memory lengh: 14261 | eps: 7.7%\n",
      "episode: 1480 | score: 9.9 | memory lengh: 14460 | eps: 7.7%\n",
      "episode: 1500 | score: 9.8 | memory lengh: 14655 | eps: 7.7%\n",
      "episode: 1520 | score: 10.2 | memory lengh: 14858 | eps: 7.7%\n",
      "episode: 1540 | score: 10.0 | memory lengh: 15058 | eps: 7.7%\n",
      "episode: 1560 | score: 10.1 | memory lengh: 15260 | eps: 7.7%\n",
      "episode: 1580 | score: 10.2 | memory lengh: 15464 | eps: 7.7%\n",
      "episode: 1600 | score: 9.5 | memory lengh: 15654 | eps: 7.7%\n",
      "episode: 1620 | score: 9.6 | memory lengh: 15846 | eps: 7.7%\n",
      "episode: 1640 | score: 9.4 | memory lengh: 16034 | eps: 7.7%\n",
      "episode: 1660 | score: 9.9 | memory lengh: 16233 | eps: 7.7%\n",
      "episode: 1680 | score: 9.5 | memory lengh: 16423 | eps: 7.7%\n",
      "episode: 1700 | score: 9.7 | memory lengh: 16617 | eps: 7.7%\n",
      "episode: 1720 | score: 9.8 | memory lengh: 16812 | eps: 7.7%\n",
      "episode: 1740 | score: 10.0 | memory lengh: 17012 | eps: 7.7%\n",
      "episode: 1760 | score: 9.4 | memory lengh: 17200 | eps: 7.6%\n",
      "episode: 1780 | score: 9.7 | memory lengh: 17393 | eps: 7.6%\n",
      "episode: 1800 | score: 10.1 | memory lengh: 17595 | eps: 7.6%\n",
      "episode: 1820 | score: 9.8 | memory lengh: 17790 | eps: 7.6%\n",
      "episode: 1840 | score: 10.0 | memory lengh: 17990 | eps: 7.6%\n",
      "episode: 1860 | score: 9.2 | memory lengh: 18173 | eps: 7.6%\n",
      "episode: 1880 | score: 10.2 | memory lengh: 18377 | eps: 7.6%\n",
      "episode: 1900 | score: 9.4 | memory lengh: 18566 | eps: 7.6%\n",
      "episode: 1920 | score: 9.8 | memory lengh: 18762 | eps: 7.6%\n",
      "episode: 1940 | score: 10.2 | memory lengh: 18965 | eps: 7.6%\n",
      "episode: 1960 | score: 9.9 | memory lengh: 19163 | eps: 7.6%\n",
      "episode: 1980 | score: 9.4 | memory lengh: 19352 | eps: 7.6%\n",
      "episode: 2000 | score: 9.7 | memory lengh: 19545 | eps: 7.6%\n",
      "episode: 2020 | score: 9.5 | memory lengh: 19735 | eps: 7.6%\n",
      "episode: 2040 | score: 10.0 | memory lengh: 19935 | eps: 7.6%\n",
      "episode: 2060 | score: 9.9 | memory lengh: 20134 | eps: 7.6%\n",
      "episode: 2080 | score: 10.0 | memory lengh: 20334 | eps: 7.6%\n",
      "episode: 2100 | score: 10.1 | memory lengh: 20535 | eps: 7.6%\n",
      "episode: 2120 | score: 9.9 | memory lengh: 20733 | eps: 7.6%\n",
      "episode: 2140 | score: 9.8 | memory lengh: 20928 | eps: 7.6%\n",
      "episode: 2160 | score: 9.4 | memory lengh: 21117 | eps: 7.6%\n",
      "episode: 2180 | score: 9.4 | memory lengh: 21306 | eps: 7.6%\n",
      "episode: 2200 | score: 9.3 | memory lengh: 21493 | eps: 7.6%\n",
      "episode: 2220 | score: 9.8 | memory lengh: 21688 | eps: 7.6%\n",
      "episode: 2240 | score: 10.2 | memory lengh: 21891 | eps: 7.6%\n",
      "episode: 2260 | score: 9.7 | memory lengh: 22085 | eps: 7.5%\n",
      "episode: 2280 | score: 9.6 | memory lengh: 22277 | eps: 7.5%\n",
      "episode: 2300 | score: 10.2 | memory lengh: 22481 | eps: 7.5%\n",
      "episode: 2320 | score: 9.2 | memory lengh: 22666 | eps: 7.5%\n",
      "episode: 2340 | score: 9.8 | memory lengh: 22862 | eps: 7.5%\n",
      "episode: 2360 | score: 9.7 | memory lengh: 23055 | eps: 7.5%\n",
      "episode: 2380 | score: 9.8 | memory lengh: 23251 | eps: 7.5%\n",
      "episode: 2400 | score: 10.0 | memory lengh: 23451 | eps: 7.5%\n",
      "episode: 2420 | score: 9.6 | memory lengh: 23642 | eps: 7.5%\n",
      "episode: 2440 | score: 9.8 | memory lengh: 23838 | eps: 7.5%\n",
      "episode: 2460 | score: 9.8 | memory lengh: 24034 | eps: 7.5%\n",
      "episode: 2480 | score: 9.4 | memory lengh: 24223 | eps: 7.5%\n",
      "episode: 2500 | score: 9.4 | memory lengh: 24411 | eps: 7.5%\n",
      "episode: 2520 | score: 9.3 | memory lengh: 24598 | eps: 7.5%\n",
      "episode: 2540 | score: 9.7 | memory lengh: 24792 | eps: 7.5%\n",
      "episode: 2560 | score: 10.0 | memory lengh: 24992 | eps: 7.5%\n",
      "episode: 2580 | score: 10.3 | memory lengh: 25199 | eps: 7.5%\n",
      "episode: 2600 | score: 9.5 | memory lengh: 25389 | eps: 7.5%\n",
      "episode: 2620 | score: 9.8 | memory lengh: 25585 | eps: 7.5%\n",
      "episode: 2640 | score: 9.7 | memory lengh: 25779 | eps: 7.5%\n",
      "episode: 2660 | score: 10.2 | memory lengh: 25983 | eps: 7.5%\n",
      "episode: 2680 | score: 9.7 | memory lengh: 26177 | eps: 7.5%\n",
      "episode: 2700 | score: 9.8 | memory lengh: 26373 | eps: 7.5%\n",
      "episode: 2720 | score: 9.6 | memory lengh: 26564 | eps: 7.5%\n",
      "episode: 2740 | score: 9.9 | memory lengh: 26762 | eps: 7.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2760 | score: 9.6 | memory lengh: 26954 | eps: 7.4%\n",
      "episode: 2780 | score: 9.6 | memory lengh: 27145 | eps: 7.4%\n",
      "episode: 2800 | score: 10.1 | memory lengh: 27347 | eps: 7.4%\n",
      "episode: 2820 | score: 9.7 | memory lengh: 27541 | eps: 7.4%\n",
      "episode: 2840 | score: 9.7 | memory lengh: 27734 | eps: 7.4%\n",
      "episode: 2860 | score: 10.0 | memory lengh: 27934 | eps: 7.4%\n",
      "episode: 2880 | score: 10.2 | memory lengh: 28139 | eps: 7.4%\n",
      "episode: 2900 | score: 9.6 | memory lengh: 28331 | eps: 7.4%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1949f139f3f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mtrain_start\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mepisode\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mSHOW_EVERY\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mepisode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-b7b22f4a2eec>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m# 모든 원소를 [ min, max ]의 범위로 clamp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclamp_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight_decay'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m                    \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m                    )\n\u001b[0;32m    121\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for episode in range(HM_EPISODES):            \n",
    "    epsilon = max(0.01, 0.08 - 0.01*(episode/5000))  \n",
    "    state = env.reset()         \n",
    "    state = torch.tensor([state], device=device, dtype =torch.float) # state에 차원하나 추가 필요\n",
    "    done = False\n",
    "\n",
    "    while not done:        \n",
    "\n",
    "        action = select_action(state, epsilon)    # action result >> tensor([[0]]) or tensor([[1]])\n",
    "\n",
    "        # 선택한 action을 대입하여 reward와 done을 얻어낸다. \n",
    "        # env.step(action.item())의 예시  \n",
    "        # >> (array([-0.008956, -0.160571,  0.005936,  0.302326]), 1.0, False, {})\n",
    "        next_state, reward, done, _ = env.step(action.item())     \n",
    "        score += reward\n",
    "\n",
    "        reward = torch.tensor([reward], device=device, dtype = torch.float)\n",
    "        next_state = torch.tensor([next_state], device=device, dtype =torch.float)                \n",
    "\n",
    "        # 얻어낸 transition set을 memory에 저장\n",
    "        memory.push(state, action, next_state, reward)\n",
    "        # (policy network에서) 최적화 한단계 수행\n",
    "\n",
    "\n",
    "\n",
    "        # 다음 상태로 이동\n",
    "        state = next_state\n",
    "        steps += 1\n",
    "\n",
    "\n",
    "        # 마찬가지로 done이 True 라면,\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    if len(memory) >= train_start:\n",
    "        train_model()\n",
    "        \n",
    "    if episode % SHOW_EVERY==0 and episode != 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())        \n",
    "        print('episode: {:3d} | score: {:.1f} | memory lengh: {:4d} | eps: {:.1f}%'.format(\n",
    "            episode, score/SHOW_EVERY, len(memory), epsilon*100))\n",
    "        \n",
    "        scores.append(score_avg)\n",
    "        episodes.append(episode)\n",
    "        plt.plot(episodes, scores, 'b')\n",
    "        plt.xlabel('episode')\n",
    "        plt.ylabel('score')\n",
    "        score = 0        \n",
    "env.close()\n",
    "\n",
    "# 학습 마무리. \n",
    "print('Complete')\n",
    "scores.clear\n",
    "episodes.clear\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2bb72b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a30220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4a0c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
